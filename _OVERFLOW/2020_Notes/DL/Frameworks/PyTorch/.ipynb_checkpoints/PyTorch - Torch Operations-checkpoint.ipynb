{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Operations\n",
    "https://jhui.github.io/2018/02/09/PyTorch-Basic-operations/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.6284e-06, 5.2945e+22, 6.6471e+22],\n",
      "        [6.6757e-07, 3.4014e+21, 1.3235e-08]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeors(2,3)\n",
    "x = torch.ones(2,3)\n",
    "x = torch.empty(2,3)\n",
    "x = torch.Tensor(2,3)\n",
    "x = torch.tensor()\n",
    "print(x) #float tensor of zeros size=(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[True, True, True],\n",
      "        [True, True, True]])\n"
     ]
    }
   ],
   "source": [
    "#OPERATION SYNTAX\n",
    "y = torch.rand(2,3)\n",
    "z1 = x + y  #operator overloading\n",
    "z2 = torch.add(x,y) #same as above\n",
    "print(z1==z2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.4634e-01, 5.2945e+22, 6.6471e+22],\n",
      "        [6.2352e-01, 3.4014e+21, 4.4754e-01]])\n"
     ]
    }
   ],
   "source": [
    "#INPLACE OPERATIONS\n",
    "#followed by \"_\"\n",
    "x.add_(y)  #add y to x in-place\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1463, 0.6235])\n",
      "tensor([1.4634e-01, 5.2945e+22, 6.6471e+22])\n"
     ]
    }
   ],
   "source": [
    "print(x[:, 0]) #all rows, first column \n",
    "print(x[0, :]) #all columns, first row\n",
    "\n",
    "#the first position in a slice is the outtermost dimension in\n",
    "# vector format (dim1, dim2, dim3) [dim1[dim2[dim3]],[dim2[dim3]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "#METADATA\n",
    "print(x.size()) #size of x\n",
    "print(torch.numel(x)) #num elements in x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.1019,  1.5297, -1.3579],\n",
      "        [ 0.2959,  0.3765,  0.7293]])\n",
      "tensor([[-1.1019,  1.5297, -1.3579,  0.2959,  0.3765,  0.7293]])\n",
      "tensor([[-1.1019,  1.5297],\n",
      "        [-1.3579,  0.2959],\n",
      "        [ 0.3765,  0.7293]])\n"
     ]
    }
   ],
   "source": [
    "#RESHAPING A TENSOR ~ .VIEW()\n",
    "x = torch.randn(2,3)\n",
    "y = x.view(1,6)\n",
    "z = x.view(3,-1)\n",
    "print(x)\n",
    "print(y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1019,  1.5297, -1.3579,  0.2959,  0.3765,  0.7293]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.reshape(1,6)  # can also use reshape instead of view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identity Matrix Fill Tensor w/ 0, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n",
      "tensor([[[[1.],\n",
      "          [1.]]],\n",
      "\n",
      "\n",
      "        [[[1.],\n",
      "          [1.]]]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [2., 2., 2.],\n",
      "        [3., 3., 3.]])\n"
     ]
    }
   ],
   "source": [
    "#IDENTITY MATRIX ~ torch.eye()\n",
    "identity = torch.eye(3) #3x3 identity\n",
    "print(identity)\n",
    "\n",
    "#Vector of ones ~ torch.ones()\n",
    "v = torch.ones(2,1,2,1)\n",
    "print(v)\n",
    "v = torch.ones_like(identity) #ones w same shape as identity\n",
    "print(v)\n",
    "\n",
    "#FILL ~ .fill_()\n",
    "v[1].fill_(2) #FILL Second row with 2's\n",
    "v[2].fill_(3)\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Tensors with Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4])\n",
      "tensor([0, 2, 4])\n",
      "tensor([ 0.0000,  0.9091,  1.8182,  2.7273,  3.6364,  4.5455,  5.4545,  6.3636,\n",
      "         7.2727,  8.1818,  9.0909, 10.0000])\n",
      "tensor([1.0000e+00, 8.1113e+00, 6.5793e+01, 5.3367e+02, 4.3288e+03, 3.5112e+04,\n",
      "        2.8480e+05, 2.3101e+06, 1.8738e+07, 1.5199e+08, 1.2328e+09, 1.0000e+10])\n"
     ]
    }
   ],
   "source": [
    "# torch.ARANGE()  Returns type LONG\n",
    "v = torch.arange(0,5)\n",
    "print(v)\n",
    "v = torch.arange(0,5,2) #range(0,5,step=2)\n",
    "print(v)\n",
    "\n",
    "# torch.LINSPACE()   #returns type FLOAT\n",
    "v = torch.linspace(0,10,12) #Split [0,10] in 12 linear steps\n",
    "print(v)\n",
    "v = torch.logspace(0,10,12) #split [0,10] in 12 log steps\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing, Slicing, Joining, Mutating\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recombining Data\n",
    "- CONCAT join data on an existing dim\n",
    "- STACK join data on a new dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]]) \n",
      "\n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8],\n",
      "        [0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8],\n",
      "        [0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]]) torch.Size([9, 3]) \n",
      "\n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8],\n",
      "        [0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8],\n",
      "        [0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]]) torch.Size([9, 3]) \n",
      "\n",
      "tensor([[[0, 1, 2],\n",
      "         [3, 4, 5],\n",
      "         [6, 7, 8]],\n",
      "\n",
      "        [[0, 1, 2],\n",
      "         [3, 4, 5],\n",
      "         [6, 7, 8]]]) torch.Size([2, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "v = torch.arange(0,9).reshape(3, 3)\n",
    "print(v, '\\n')\n",
    "\n",
    "#CONCATENATE, STACK\n",
    "\"\"\"\n",
    "Both cat and stack require tensors of the same shape.\n",
    "CAT - combines on a given EXISTING dimension\n",
    "STACK - combines tensors on a new dimension\n",
    "\"\"\"\n",
    "#torch.CAT()\n",
    "cat = torch.cat((v,v,v), dim=0) #dim=0 -> columns\n",
    "print(cat, cat.shape,'\\n')\n",
    "\n",
    "cat = torch.cat((v,v,v), dim=0) #dim=1 -> rows\n",
    "print(cat, cat.shape, '\\n')\n",
    "\n",
    "#torch.STACK()\n",
    "stack = torch.stack((v, v),dim=0)\n",
    "print(stack, stack.shape)#stacks array on a new dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]]) \n",
      "\n",
      "tensor([[0, 1, 2],\n",
      "        [5, 4, 3],\n",
      "        [8, 7, 8]])\n"
     ]
    }
   ],
   "source": [
    "#GATHER: Reorganize Data Elements\n",
    "print(v,'\\n')\n",
    "out = torch.gather(v, 1, torch.LongTensor([[0,1,2],[2,1,0],[2,1,2]]))\n",
    "print(out)\n",
    "# torch.gather(input, dim, index, out=None)\n",
    "# out[i][j][k] = input[index[i][j][k]][j][k]  # if dim == 0\n",
    "# out[i][j][k] = input[i][index[i][j][k]][k]  # if dim == 1\n",
    "# out[i][j][k] = input[i][j][index[i][j][k]]  # if dim == 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seperate a Tensor into multiple.\n",
    "- CHUNK a tensor into N distinct Tensors\n",
    "- SPLIT a tensor every N rows/columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[0, 1, 2],\n",
      "        [3, 4, 5]]), tensor([[6, 7, 8]])) \n",
      "\n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]]) \n",
      "\n",
      "(tensor([[0, 1],\n",
      "        [3, 4],\n",
      "        [6, 7]]), tensor([[2],\n",
      "        [5],\n",
      "        [8]])) \n",
      "\n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]])\n"
     ]
    }
   ],
   "source": [
    "#CHUNK A TENSOR, -> Choost the NUMBER OF OUTPUT TENSORS\n",
    "\"\"\"chunk(input, chunks, dim=0)\n",
    "Splits a tensor into a specific number of chunks.\n",
    "Last chunk will be smaller if the tensor size along the given \n",
    "dimension`dim` is not divisible by `chunks`.\"\"\"\n",
    "\n",
    "#Split the tensor into N chunks on dimension 'dim'\n",
    "\n",
    "#Chunk by rows (2D) ~torch.CHUNK()\n",
    "r = torch.chunk(v, 2, dim=0) #2 Chunks, shape (2,3), (1,3)\n",
    "print(r, '\\n')\n",
    "\n",
    "#Recombine\n",
    "print( torch.cat((r[0],r[1]), dim = 0) ,'\\n')\n",
    "\n",
    "#Chunk by columns (2D)\n",
    "r = torch.chunk(v, 2, 1) # 2 tensors, shape (3,2), (3,1)\n",
    "print(r, '\\n')\n",
    "\n",
    "#Recombine\n",
    "print( torch.cat((r[0],r[1]), dim = 1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8,  9],\n",
      "        [10, 11, 12, 13, 14],\n",
      "        [15, 16, 17, 18, 19],\n",
      "        [20, 21, 22, 23, 24]]) \n",
      "\n",
      "(tensor([[0, 1, 2, 3, 4]]), tensor([[5, 6, 7, 8, 9]]), tensor([[10, 11, 12, 13, 14]]), tensor([[15, 16, 17, 18, 19]]), tensor([[20, 21, 22, 23, 24]])) \n",
      "\n",
      "(tensor([[0, 1, 2, 3, 4],\n",
      "        [5, 6, 7, 8, 9]]), tensor([[10, 11, 12, 13, 14],\n",
      "        [15, 16, 17, 18, 19]]), tensor([[20, 21, 22, 23, 24]])) \n",
      "\n",
      "(tensor([[ 0,  1],\n",
      "        [ 5,  6],\n",
      "        [10, 11],\n",
      "        [15, 16],\n",
      "        [20, 21]]), tensor([[ 2,  3],\n",
      "        [ 7,  8],\n",
      "        [12, 13],\n",
      "        [17, 18],\n",
      "        [22, 23]]), tensor([[ 4],\n",
      "        [ 9],\n",
      "        [14],\n",
      "        [19],\n",
      "        [24]]))\n"
     ]
    }
   ],
   "source": [
    "# SPLIT A TENSOR -> choose the SIZE OF OUTPUT TENSORS\n",
    "\"\"\"\n",
    "torch.split(tensor, split_size_or_sections, dim=0)\n",
    "\"\"\"\n",
    "#Split the tensor every N rows/columns on dimension 'dim'\n",
    "v = torch.arange(0,25).view(5,5)\n",
    "print(v,'\\n')\n",
    "\n",
    "\n",
    "#split every 1 rows \n",
    "r = torch.split(v, 1, 0)\n",
    "print(r,'\\n')\n",
    "\n",
    "#Split every 2 rows\n",
    "r = torch.split(v, 2, 0)\n",
    "print(r,'\\n')\n",
    "\n",
    "#Split every 2 columns\n",
    "r = torch.split(v, 2, 1)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 2., 2.]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(1,4)\n",
    "y = torch.ones(1,4)*2\n",
    "\n",
    "a = torch.arange(1,5)\n",
    "torch.where(a<3,x,y) #where true: x, else: y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index Select, Mask Select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  2],\n",
      "        [ 5,  7],\n",
      "        [10, 12],\n",
      "        [15, 17],\n",
      "        [20, 22]]) \n",
      "\n",
      "tensor([[ 0,  2],\n",
      "        [ 5,  7],\n",
      "        [10, 12],\n",
      "        [15, 17],\n",
      "        [20, 22]]) \n",
      "\n",
      "tensor([[ 0,  1,  2,  3,  4],\n",
      "        [10, 11, 12, 13, 14]])\n"
     ]
    }
   ],
   "source": [
    "#INDEX SELECT\n",
    "\"\"\"\n",
    "index_select(input, dim, index, out=None) -> Tensor\n",
    "\n",
    "Returns a new tensor which indexes the :attr:`input` tensor \n",
    "along dimension :attr:`dim` using the entries in :attr:`index` \n",
    "which is a `LongTensor`.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#torch.INDEX_SELECT(tensor, dim, index)\n",
    "indx = torch.LongTensor([0,2])\n",
    "r = torch.index_select(v, 1, indx) #Same as v[:,[0,2]] (columns)\n",
    "\n",
    "print(v[:,[0,2]], '\\n')\n",
    "print(r,'\\n')\n",
    "\n",
    "r = torch.index_select(v, 0, indx)\n",
    "print(r) # same as v[[0,2],:]   (rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[False, False, False, False, False],\n",
      "        [False, False, False, False,  True],\n",
      "        [ True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True]]) \n",
      "\n",
      "tensor([ 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24])\n"
     ]
    }
   ],
   "source": [
    "#MASK SELECT\n",
    "\"\"\"\n",
    "masked_select(input, mask, out=None) -> Tensor\n",
    "\n",
    "Returns a new 1-D tensor which indexes the :attr:`input` tensor \n",
    "according to the boolean mask :attr:`mask` which is a `BoolTensor`.\n",
    "\"\"\"\n",
    "\n",
    "mask = v.ge(9) #same as v>=3\n",
    "print(mask, '\\n')\n",
    "r = torch.masked_select(v, mask) # same as v[mask]\n",
    "\n",
    "\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQUEEZE ~ REMOVE UNNECESSARY DIMENSIONS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1., 1.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1.]]]]) torch.Size([2, 1, 1, 2]) \n",
      "\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]]) torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "t = torch.ones(2,1,1,2)\n",
    "print(t, t.shape,'\\n')\n",
    "\n",
    "\"\"\"\n",
    "squeeze(input, dim=None, out=None) -> Tensor\n",
    "\n",
    "Returns a tensor with all the dimensions of `input` \n",
    "of size `1` removed.\n",
    "\"\"\"\n",
    "\n",
    "t = torch.squeeze(t)\n",
    "print(t, t.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNSQUEEZE ~ X dimension tensor to X+1 dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.]) torch.Size([3])\n",
      "tensor([[1., 2., 3.]]) torch.Size([1, 3])\n",
      "tensor([[1.],\n",
      "        [2.],\n",
      "        [3.]]) torch.Size([3, 1])\n"
     ]
    }
   ],
   "source": [
    "#ADD EXTRA DIMENSIONS\n",
    "t = torch.Tensor([1,2,3])\n",
    "print(t, t.shape)\n",
    "\n",
    "\"\"\"\n",
    "unsqueeze(input, dim, out=None) -> Tensor\n",
    "\n",
    "Returns a new tensor with a dimension of size one inserted at the\n",
    "specified position.\n",
    "\"\"\"\n",
    "\n",
    "#current dim is (3)\n",
    "#can insert a dimension at 0 -> (1,3)\n",
    "r = torch.unsqueeze(t,0)\n",
    "print(r, r.shape)\n",
    "\n",
    "#or insert dimension at 1 -> (3,1)\n",
    "r = torch.unsqueeze(t,1)\n",
    "print(r, r.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRANSPOSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8,  9],\n",
      "        [10, 11, 12, 13, 14],\n",
      "        [15, 16, 17, 18, 19],\n",
      "        [20, 21, 22, 23, 24]]) \n",
      "\n",
      "tensor([[ 0,  5, 10, 15, 20],\n",
      "        [ 1,  6, 11, 16, 21],\n",
      "        [ 2,  7, 12, 17, 22],\n",
      "        [ 3,  8, 13, 18, 23],\n",
      "        [ 4,  9, 14, 19, 24]]) \n",
      "\n",
      "tensor([[ 0,  5, 10, 15, 20],\n",
      "        [ 1,  6, 11, 16, 21],\n",
      "        [ 2,  7, 12, 17, 22],\n",
      "        [ 3,  8, 13, 18, 23],\n",
      "        [ 4,  9, 14, 19, 24]])\n"
     ]
    }
   ],
   "source": [
    "print(v,'\\n')\n",
    "\n",
    "\"\"\"\n",
    "transpose(input, dim0, dim1) -> Tensor\n",
    "\n",
    "Returns a tensor that is a transposed version of :attr:`input`.\n",
    "The given dimensions :attr:`dim0` and :attr:`dim1` are swapped.\n",
    "\n",
    "The resulting :attr:`out` tensor shares it's underlying storage with the\n",
    ":attr:`input` tensor, so changing the content of one would change the content\n",
    "of the other.\n",
    "\"\"\"\n",
    "\n",
    "print(torch.transpose(v, 0, 1),'\\n')\n",
    "print(v.T) #SAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNBIND ~ Remove a Tensor Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4366, 0.8218, 0.5861],\n",
      "        [0.9404, 0.6289, 0.4013],\n",
      "        [0.6643, 0.1367, 0.5621]]) torch.Size([3, 3]) \n",
      "\n",
      "(tensor([0.4366, 0.9404, 0.6643]), tensor([0.8218, 0.6289, 0.1367]), tensor([0.5861, 0.4013, 0.5621])) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "unbind(input, dim=0) -> seq\n",
    "\n",
    "Removes a tensor dimension.\n",
    "\n",
    "Returns a tuple of all slices along a given dimension, \n",
    "already without it.\n",
    "\"\"\"\n",
    "r = torch.rand(3,3)\n",
    "\n",
    "print(r, r.shape, '\\n')\n",
    "r = torch.unbind(r,1)\n",
    "print(r, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3])\n",
      "torch.Size([1, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.4366, 0.9404, 0.6643],\n",
       "        [0.8218, 0.6289, 0.1367],\n",
       "        [0.5861, 0.4013, 0.5621]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(r[0].shape)\n",
    "#UNSQUEEZE (3)->(1,3)\n",
    "r = [torch.unsqueeze(i,0) for i in r]\n",
    "print(r[0].shape)\n",
    "\n",
    "#RECOMBINE ONF NEW DIMENSION\n",
    "torch.cat(r,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4032, 0.6109, 0.4447],\n",
      "        [0.3165, 0.3961, 0.2899],\n",
      "        [0.1884, 0.5292, 0.9387]]) \n",
      "\n",
      "tensor([0.4032, 0.3165, 0.1884, 0.6109, 0.3961, 0.5292, 0.4447, 0.2899, 0.9387])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.4032, 0.3165, 0.1884],\n",
       "        [0.6109, 0.3961, 0.5292],\n",
       "        [0.4447, 0.2899, 0.9387]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = torch.rand(3,3)\n",
    "print(r,'\\n')\n",
    "r = torch.unbind(r, 1) #unbind columns\n",
    "\n",
    "print(torch.cat(r)) #stack columns\n",
    "\n",
    "r = [torch.unsqueeze(i, 0) for i in r]\n",
    "torch.cat(r) #same as transpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribution\n",
    "\n",
    "## Fill a Tensor with randomized values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNIFORM:  tensor([[0.7576, 0.2793, 0.4031],\n",
      "        [0.7347, 0.0293, 0.7999],\n",
      "        [0.3971, 0.7544, 0.5695]]) \n",
      "\n",
      "UNIFORM (discrete):  tensor([[2., 8., 9.],\n",
      "        [6., 3., 3.],\n",
      "        [0., 2., 1.]]) \n",
      "\n",
      "BERNOULLI:  tensor([[1., 1., 1.],\n",
      "        [0., 1., 1.],\n",
      "        [1., 1., 0.]]) \n",
      "\n",
      "NORMAL:  tensor([[ 0.0436,  1.3240, -0.1005],\n",
      "        [ 0.6443,  0.5244,  1.0157],\n",
      "        [ 0.2571, -0.9013,  0.8138]]) \n",
      "\n",
      "EXPONENTIAL:  tensor([[0.1522, 0.3676, 0.0485],\n",
      "        [0.0577, 0.1941, 0.8243],\n",
      "        [0.0975, 0.0281, 0.2311]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#SET SEED\n",
    "torch.manual_seed(1)\n",
    "\n",
    "#Fill w/ UNIFORM CONTINUOUS random variables (range 0,1)\n",
    "r = torch.Tensor(3,3).uniform_(0, to=1) #torch.rand\n",
    "r = torch.rand(3,3) #SAME\n",
    "print(\"UNIFORM: \",r,'\\n')\n",
    "\n",
    "#Fill w/ UNIFORM DISCRETE rv\n",
    "r= torch.Tensor(3,3).random_(0,10)\n",
    "r = torch.randint(low=0, 10, (3,3)) #SAME\n",
    "print(\"UNIFORM (discrete): \",r,'\\n')\n",
    "\n",
    "## Size: 2x2. BERNOUILLI with probability p stored in elements of r\n",
    "r = torch.Tensor(3,3).bernoulli_(p=0.5)\n",
    "r = torch.rand(3,3)>0.5 #SAME\n",
    "print(\"BERNOULLI: \",r,'\\n')\n",
    "\n",
    "#NORMAL   torch.randn()\n",
    "r = torch.Tensor(3,3).normal_(mean=0, std=1)\n",
    "r = torch.randn(3,3) #SAME\n",
    "print(\"NORMAL: \",r,'\\n')\n",
    "\n",
    "#EXPONENTIAL\n",
    "r = torch.Tensor(3,3).exponential_(lambd=1)\n",
    "print(\"EXPONENTIAL: \",r,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pointwise (Elementwise) Operations"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Pointwise Ops\n",
    "~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    ".. autofunction:: abs\n",
    ".. autofunction:: acos           - arc cosine\n",
    ".. autofunction:: add\n",
    ".. autofunction:: addcdiv        - element wise: t1 + s * t2/t3\n",
    ".. autofunction:: addcmul        - element wise: t1 + s * t2 * t3\n",
    ".. autofunction:: asin           - arc sin\n",
    ".. autofunction:: atan\n",
    ".. autofunction:: atan2\n",
    ".. autofunction:: ceil           - ceiling\n",
    ".. autofunction:: clamp          - clamp elements into a range\n",
    ".. autofunction:: cos\n",
    ".. autofunction:: cosh\n",
    ".. autofunction:: div            - divide\n",
    ".. autofunction:: erf            - Gaussian error functiom\n",
    ".. autofunction:: erfinv         - Inverse\n",
    ".. autofunction:: exp\n",
    ".. autofunction:: expm1          - exponential of each element minus 1\n",
    ".. autofunction:: floor          \n",
    ".. autofunction:: fmod           - element wise remainder of division\n",
    ".. autofunction:: frac           - fraction part 3.4 -> 0.4\n",
    ".. autofunction:: lerp           - linear interpolation\n",
    ".. autofunction:: log            - natural log\n",
    ".. autofunction:: log1p          - y = log(1 + x)\n",
    ".. autofunction:: mul            - multiple\n",
    ".. autofunction:: neg \n",
    ".. autofunction:: pow\n",
    ".. autofunction:: reciprocal     - 1/x\n",
    ".. autofunction:: remainder      - remainder of division\n",
    ".. autofunction:: round\n",
    ".. autofunction:: rsqrt          - the reciprocal of the square-root \n",
    ".. autofunction:: sigmoid        - sigmode(x)\n",
    ".. autofunction:: sign\n",
    ".. autofunction:: sin\n",
    ".. autofunction:: sinh\n",
    ".. autofunction:: sqrt\n",
    ".. autofunction:: tan\n",
    ".. autofunction:: tanh\n",
    ".. autofunction:: trunc          - truncated integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4973,  0.4084,  0.5321],\n",
      "        [ 0.6542,  0.1545,  0.2159],\n",
      "        [ 0.7338, -0.3888, -0.3899]]) torch.Size([3, 3]) \n",
      "\n",
      "ABS\n",
      "tensor([[0.4973, 0.4084, 0.5321],\n",
      "        [0.6542, 0.1545, 0.2159],\n",
      "        [0.7338, 0.3888, 0.3899]]) torch.Size([3, 3]) \n",
      "\n",
      "ADD SCALAR\n",
      "tensor([[ 9.5027, 10.4084, 10.5321],\n",
      "        [10.6542, 10.1545, 10.2159],\n",
      "        [10.7338,  9.6112,  9.6101]]) torch.Size([3, 3]) \n",
      "\n",
      "CLAMP [-.5,.5]\n",
      "tensor([[-0.4973,  0.4084,  0.5000],\n",
      "        [ 0.5000,  0.1545,  0.2159],\n",
      "        [ 0.5000, -0.3888, -0.3899]]) torch.Size([3, 3]) \n",
      "\n",
      "RECIPROCAL\n",
      "tensor([[-2.0109,  2.4489,  1.8793],\n",
      "        [ 1.5286,  6.4713,  4.6320],\n",
      "        [ 1.3628, -2.5723, -2.5645]]) torch.Size([3, 3]) \n",
      "\n",
      "EXPONENTIAL\n",
      "tensor([[0.6082, 1.5043, 1.7025],\n",
      "        [1.9236, 1.1671, 1.2410],\n",
      "        [2.0829, 0.6779, 0.6771]]) torch.Size([3, 3]) \n",
      "\n",
      "LN\n",
      "tensor([[    nan, -0.8956, -0.6309],\n",
      "        [-0.4243, -1.8674, -1.5330],\n",
      "        [-0.3096,     nan,     nan]]) torch.Size([3, 3]) \n",
      "\n",
      "POWER\n",
      "tensor([[0.2473, 0.1668, 0.2831],\n",
      "        [0.4280, 0.0239, 0.0466],\n",
      "        [0.5384, 0.1511, 0.1521]]) torch.Size([3, 3]) \n",
      "\n",
      "SIGMOID\n",
      "tensor([[0.3782, 0.6007, 0.6300],\n",
      "        [0.6580, 0.5386, 0.5538],\n",
      "        [0.6756, 0.4040, 0.4037]]) torch.Size([3, 3]) \n",
      "\n",
      "SQRT\n",
      "tensor([[   nan, 0.6390, 0.7295],\n",
      "        [0.8088, 0.3931, 0.4646],\n",
      "        [0.8566,    nan,    nan]]) torch.Size([3, 3]) \n",
      "\n",
      "TRUNC\n",
      "tensor([[-0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., -0., -0.]]) torch.Size([3, 3]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def _print(tensor):\n",
    "    print(tensor, tensor.shape,'\\n')\n",
    "\n",
    "r = torch.randn(3,3)\n",
    "_print(r)\n",
    "\n",
    "#ABS VALUES\n",
    "print(\"ABS\")\n",
    "_print(torch.abs(r))\n",
    "\n",
    "#ADD SCALAR\n",
    "print(\"ADD SCALAR\")\n",
    "_print(torch.add(r, 10))\n",
    "\n",
    "#CLAMP TO RANGE [min, max] #will round up\n",
    "print(\"CLAMP [-.5,.5]\")\n",
    "_print(torch.clamp(r,-0.5,0.5))\n",
    "\n",
    "#RECIPROCAL\n",
    "print(\"RECIPROCAL\")\n",
    "_print(torch.reciprocal(r))\n",
    "\n",
    "#EXPONENTIAL\n",
    "print(\"EXPONENTIAL\")\n",
    "_print(torch.exp(r))\n",
    "\n",
    "#NATURAL LOG\n",
    "print(\"LN\")\n",
    "_print(torch.log(r))\n",
    "\n",
    "#Take power of each element in tensor\n",
    "print(\"POWER\")\n",
    "_print(torch.pow(r, 2))\n",
    "\n",
    "#SIGMOID\n",
    "print(\"SIGMOID\")\n",
    "_print(torch.sigmoid(r))\n",
    "\n",
    "#SQRT\n",
    "print(\"SQRT\")\n",
    "_print(torch.sqrt(r))\n",
    "\n",
    "#TRUNCATE TO INTEGER\n",
    "print(\"TRUNC\")\n",
    "_print(torch.trunc(r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduction Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 1.1250, 2.2500],\n",
      "        [3.3750, 4.5000, 5.6250],\n",
      "        [6.7500, 7.8750, 9.0000]]) \n",
      "\n",
      "SUM tensor([[ 3.3750],\n",
      "        [13.5000],\n",
      "        [23.6250]]) \n",
      "\n",
      "CUMSUM tensor([[ 0.0000,  1.1250,  3.3750],\n",
      "        [ 3.3750,  7.8750, 13.5000],\n",
      "        [ 6.7500, 14.6250, 23.6250]]) \n",
      "\n",
      "PRODUCT tensor([[  0.0000],\n",
      "        [ 85.4297],\n",
      "        [478.4062]]) \n",
      "\n",
      "MEAN tensor([[1.1250],\n",
      "        [4.5000],\n",
      "        [7.8750]]) \n",
      "\n",
      "VARIANCE tensor([[1.2656],\n",
      "        [1.2656],\n",
      "        [1.2656]]) \n",
      "\n",
      "tensor(1.5099) torch.Size([]) \n",
      "\n",
      "tensor(15.3452) torch.Size([]) \n",
      "\n",
      "tensor(15.3452) torch.Size([]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "v = torch.linspace(0,9,9).reshape(3,3)\n",
    "print(v,'\\n')\n",
    "\n",
    "#Sum along dimension\n",
    "print(\"SUM\", torch.sum(v,1,keepdim=True),'\\n') #sum rows\n",
    "\n",
    "#Adds at each element in tensor.\n",
    "print(\"CUMSUM\", torch.cumsum(v, 1),'\\n')\n",
    "\n",
    "#product across dimension\n",
    "print(\"PRODUCT\", torch.prod(v, 1, keepdim=True),'\\n')\n",
    "\n",
    "#mean of rows\n",
    "print(\"MEAN\", torch.mean(v,1,keepdim=True),'\\n')\n",
    "\n",
    "#variance\n",
    "print(\"VARIANCE\", torch.var(v,1,keepdim=True),'\\n')\n",
    "\n",
    "j = torch.rand(3,3)\n",
    "#P-NORM calculate the L-p norm of a matrix vectors\n",
    "#p=2 -> y=sqrt(sum(sum(wij^2)))\n",
    "_print(torch.norm(j,p=2)) #L-2 MATRIX NORM\n",
    "\n",
    "\n",
    "#L-2 DISTANCE between matrices\n",
    "# ~L2 norm of v-j\n",
    "_print(torch.dist(v,j,p=2))\n",
    "_print(torch.norm(v-j,p=2)) #SAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2],\n",
      "        [ 3,  4,  5],\n",
      "        [ 6,  7,  8],\n",
      "        [ 9, 10, 11]]) torch.Size([4, 3]) \n",
      "\n",
      "tensor([2, 2, 2, 2]) torch.Size([4]) \n",
      "\n",
      "tensor([0, 0, 0, 0]) torch.Size([4]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    " function:: argmax(input, dim, keepdim=False) -> LongTensor\n",
    "\n",
    "Returns the indices of the maximum values of a tensor \n",
    "across a dimension\n",
    "\"\"\"\n",
    "\n",
    "x = torch.arange(12).reshape(4,-1)\n",
    "_print(x)\n",
    "\n",
    "_print(torch.argmax(x, 1)) # max across rows\n",
    "_print(torch.argmin(x, 1)) # min across rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix - Vector Mutiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiplying two vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1937, 0.7519, 0.8946]) torch.Size([3]) \n",
      "\n",
      "tensor([0.1123, 0.3854, 0.6063]) torch.Size([3]) \n",
      "\n",
      "0.853891134262085\n",
      "0.853891134262085\n"
     ]
    }
   ],
   "source": [
    "#Dot product of 2 tensors\n",
    "\"\"\"\n",
    "dot(input, tensor) -> Tensor\n",
    "\n",
    "Computes the dot product (inner product) of two tensors. 1D\n",
    "\"\"\"\n",
    "a = torch.rand((3,))\n",
    "b = torch.rand((3,))\n",
    "r = torch.dot(a,b)\n",
    "_print(a)\n",
    "_print(b)\n",
    "print(r.item())\n",
    "print(torch.sum(a*b).item()) #SAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiplying a Matrix and a Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2, 3],\n",
      "        [4, 5, 6, 7]]) torch.Size([2, 4]) \n",
      "\n",
      "tensor([0, 1, 2, 3]) torch.Size([4]) \n",
      "\n",
      "tensor([14, 38]) \n",
      "\n",
      "tensor([14, 38])\n"
     ]
    }
   ],
   "source": [
    "## Matrix - Vector Products\n",
    "\"\"\"\n",
    "sum(input, dim, keepdim=False, dtype=None) -> Tensor\n",
    "\n",
    "Returns the sum of each row of the :attr:`input` tensor in the given\n",
    "dimension :attr:`dim`. If :attr:`dim` is a list of dimensions,\n",
    "reduce over all of them.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "mat = torch.arange(8).view(2,4)\n",
    "vec = torch.arange(4)\n",
    "print(mat, mat.shape, '\\n')\n",
    "print(vec, vec.shape,'\\n')\n",
    "\n",
    "r = torch.mv(mat, vec) #similar to dot product shapes must align (j,k)o(k,)\n",
    "print(r,'\\n')\n",
    "print(torch.sum(mat*vec, 1, keepdim=False).T) #SAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  4,  9],\n",
       "        [ 0,  5, 12, 21]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat*vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.1096, -2.0003, -0.0264],\n",
      "        [ 0.6379, -0.6062, -1.8777]]) torch.Size([2, 3]) \n",
      "\n",
      "tensor([-1.0850,  1.6142,  0.9615]) torch.Size([3]) \n",
      "\n",
      "tensor([-0.2191, -0.1808]) torch.Size([2]) \n",
      "\n",
      "tensor([-4.6772, -3.6570]) \n",
      "\n",
      "tensor([-4.6772, -3.6570]) torch.Size([2]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "addmv(beta=1, input, alpha=1, mat, vec, out=None) -> Tensor\n",
    "\n",
    "Performs a matrix-vector product of the matrix :attr:`mat` and\n",
    "the vector :attr:`vec`.\n",
    "The vector :attr:`input` is added to the final result.\n",
    "\n",
    "\"\"\"\n",
    "b=torch.randn(2)\n",
    "mat = torch.randn(2,3)\n",
    "W = torch.randn(3)\n",
    "print(mat, mat.shape, '\\n')\n",
    "print(W, vec.shape,'\\n')\n",
    "_print(b)\n",
    "\n",
    "r = torch.addmv(b, mat, W) #similar to dot product\n",
    "print(r,'\\n')\n",
    "\n",
    "# MATRIX o VECT0R + b\n",
    "_print(torch.mv(mat,W)+b) #SAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6662, -0.4810, -0.5533, -0.3532],\n",
      "        [ 0.7259,  0.2279,  0.2494,  0.4749],\n",
      "        [ 1.0690,  0.6485, -2.2632, -0.0804]]) torch.Size([3, 4]) \n",
      "\n",
      "tensor([[-0.1629, -0.8798],\n",
      "        [-1.4802,  0.4517],\n",
      "        [-1.0937, -1.5502],\n",
      "        [ 2.1056,  1.3680]]) torch.Size([4, 2]) \n",
      "\n",
      "tensor([[ 0.6820,  0.7434],\n",
      "        [ 0.2715, -0.2728],\n",
      "        [ 1.1720,  2.7508]]) torch.Size([3, 2]) \n",
      "\n",
      "tensor([[ 0.6820,  0.7434],\n",
      "        [ 0.2715, -0.2728],\n",
      "        [ 1.1720,  2.7508]]) torch.Size([3, 2]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "mm(input, mat2, out=None) -> Tensor\n",
    "\n",
    "Performs a matrix multiplication of the matrices :attr:`input` and :attr:`mat2`.\n",
    "\n",
    "If :attr:`input` is a :math:`(n \\times m)` tensor, :attr:`mat2` is a\n",
    ":math:`(m \\times p)` tensor, :attr:`out` will be a :math:`(n \\times p)` tensor.\n",
    "\n",
    ".. note:: This function does not :ref:`broadcast <broadcasting-semantics>`.\n",
    "          For broadcasting matrix products, see :func:`torch.matmul`.\n",
    "\"\"\"\n",
    "\n",
    "mat1 = torch.randn(3,4)\n",
    "mat2 = torch.randn(4,2)\n",
    "\n",
    "_print(mat1)\n",
    "_print(mat2)\n",
    "\n",
    "r = torch.mm(mat1, mat2) #similar to dot product\n",
    "_print(r)\n",
    "\n",
    "a = torch.unbind(mat1)\n",
    "b = torch.unbind(mat2.T)\n",
    "x = [[torch.sum(j*i).item() for j in b] for i in a]\n",
    "_print(torch.Tensor(x))  #SAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outer Product of Vectors\n",
    "<img src=https://wikimedia.org/api/rest_v1/media/math/render/svg/583d2f9f02f2644aa0acd092a29a9d0e49df1b4a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0747, 0.0069, 0.0605],\n",
      "        [0.7886, 0.0730, 0.6384],\n",
      "        [0.7984, 0.0739, 0.6463],\n",
      "        [0.4672, 0.0433, 0.3782]]) torch.Size([4, 3]) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0747, 0.0069, 0.0605],\n",
       "        [0.7886, 0.0730, 0.6384],\n",
       "        [0.7984, 0.0739, 0.6463],\n",
       "        [0.4672, 0.0433, 0.3782]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1D tensors\n",
    "v1 = torch.rand(4,)\n",
    "v2 = torch.rand(3,)  #generates a vector of size (4,3)\n",
    "\n",
    "_print(torch.ger(v1,v2))\n",
    "\n",
    "torch.unsqueeze(v1,1)*v2 #SAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Product\n",
    "\n",
    "\n",
    "The cross product a Ã— b is defined as a vector c that is perpendicular (orthogonal) to both a and b, with a direction given by the right-hand rule and a magnitude axb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = torch.ones(3,4)\n",
    "m2 = torch.ones(3,4)\n",
    "torch.cross(m1,m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expand Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5757, -0.5757, -0.5757, -0.5757],\n",
       "        [ 0.4786,  0.4786,  0.4786,  0.4786],\n",
       "        [-0.3600, -0.3600, -0.3600, -0.3600]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(3,1)\n",
    "x.expand(3,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DIagonal Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0],\n",
       "        [0, 2, 0],\n",
       "        [0, 0, 3]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1 = torch.arange(1,4)\n",
    "torch.diag(v1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 3, 4, 5]) torch.Size([4]) \n",
      "\n",
      "tensor([1., 1., 1.]) torch.Size([3]) \n",
      "\n",
      "tensor([2, 3, 4, 5]) torch.Size([4]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "torch.save(\n",
    "    obj,\n",
    "    f,\n",
    "    pickle_module=<module 'pickle' from 'c:\\\\program files\\\\python36\\\\lib\\\\pickle.py'>,\n",
    "    pickle_protocol=2,\n",
    ")\n",
    "Docstring:\n",
    "Saves an object to a disk file.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "v1 = torch.arange(2,6)\n",
    "_print(v1)\n",
    "torch.save(v1,\"vector1.pkl\")\n",
    "v1 = torch.ones(3)\n",
    "_print(v1)\n",
    "v1 = torch.load('vector1.pkl')\n",
    "_print(v1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallelism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "None\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "#Returns the number of threads used for parallelizing \n",
    "#CPU operations\n",
    "print(torch.get_num_threads())\n",
    "\n",
    "print(torch.set_num_threads(8))\n",
    "\n",
    "\"\"\"\n",
    "torch.set_num_threads(int)\n",
    "Sets the number of threads used for parallelizing \n",
    "CPU operations. WARNING: To ensure that the correct \n",
    "number of threads is used, set_num_threads must be \n",
    "called before running eager, JIT or autograd code\n",
    "\"\"\"\n",
    "\n",
    "print(torch.get_num_threads())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(100)\n",
    "x.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disabling gradient computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "X = torch.ones(4,4, requires_grad=True)\n",
    "with torch.no_grad():\n",
    "    y = X * 2\n",
    "print(y.requires_grad)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "trainable = True\n",
    "with torch.set_grad_enabled(trainable):\n",
    "    y = X*2\n",
    "print(y.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor Object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torch.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([True, True, True, True, True, True]) torch.Size([6]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "t = torch.float16\n",
    "t = torch.float32\n",
    "t = torch.float64\n",
    "t = torch.uint8\n",
    "t = torch.int16\n",
    "t = torch.int32\n",
    "t = torch.int64\n",
    "t = torch.bool\n",
    "\n",
    "x = torch.tensor([4,2,33,4,21,3], dtype = t)\n",
    "_print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5757],\n",
      "        [ 0.4786],\n",
      "        [-0.3600]]) torch.Size([3, 1]) \n",
      "\n",
      "tensor([[0],\n",
      "        [0],\n",
      "        [0]], dtype=torch.int8) torch.Size([3, 1]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "_print(x)\n",
    "_print(x.to(torch.int8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.device('cuda', 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu', index=0)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.device('cpu', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([34234,   234,  2431,    14], dtype=torch.int32) torch.Size([4]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([34234,234,2431,14], \n",
    "             dtype = torch.int32,\n",
    "             device = 'cpu:0')\n",
    "_print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
