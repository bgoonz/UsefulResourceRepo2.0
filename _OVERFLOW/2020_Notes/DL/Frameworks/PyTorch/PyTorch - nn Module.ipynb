{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch NN Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T18:29:41.567278Z",
     "start_time": "2019-10-19T18:29:40.608625Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "# F is usually used for stateless functions.\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def _print(val):\n",
    "    print(val, val.shape, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T02:02:32.988593Z",
     "start_time": "2019-10-18T02:02:32.759958Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "DATA_PATH = Path(\"data\")\n",
    "PATH = DATA_PATH / \"mnist\"\n",
    "\n",
    "PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "URL = \"http://deeplearning.net/data/mnist/\"\n",
    "FILENAME = \"mnist.pkl.gz\"\n",
    "\n",
    "if not (PATH / FILENAME).exists():\n",
    "        content = requests.get(URL + FILENAME).content\n",
    "        (PATH / FILENAME).open(\"wb\").write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T02:02:35.113811Z",
     "start_time": "2019-10-18T02:02:34.013033Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "\n",
    "with gzip.open((PATH / FILENAME).as_posix(), 'rb') as f:\n",
    "    ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T02:02:35.137787Z",
     "start_time": "2019-10-18T02:02:34.724Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 784)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T02:02:36.034830Z",
     "start_time": "2019-10-18T02:02:35.307318Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.imshow(x_train[0].reshape(-1,28,28).squeeze(), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T02:02:43.437644Z",
     "start_time": "2019-10-18T02:02:43.339871Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50000, 784])\n",
      "tensor([5, 0, 4,  ..., 8, 4, 8]) tensor(0) tensor(9)\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_valid, y_valid = map(torch.tensor, \n",
    "                                       (x_train, y_train, x_valid, y_valid))\n",
    "print(x_train.shape)\n",
    "print(y_train, y_train.min(), y_train.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Nets from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation log_softmax\n",
    "\n",
    "LogSoftMax works better than regular SoftMax? [link](https://discuss.pytorch.org/t/logsoftmax-vs-softmax/21386/2)\n",
    "\n",
    "The point is, even though logsoftmax and softmax are monotonic, their effect on the relative values of the loss function changes. Using the log-softmax will punish bigger mistakes in likelihood space higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T02:04:43.458613Z",
     "start_time": "2019-10-18T02:04:43.449664Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50000, 784])\n",
      "torch.Size([784, 10])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "#Activation function Outputs log-probabilities\n",
    "def log_softmax(x):\n",
    "    return x - x.exp().sum(-1).log().unsqueeze(-1)\n",
    "\n",
    "def model(xb):\n",
    "    return log_softmax(xb.mm(weights) + bias)\n",
    "\n",
    "#Xavier Initialization\n",
    "weights = torch.randn(784,10) / math.sqrt(784)\n",
    "weights.requires_grad_()\n",
    "bias = torch.zeros(10)\n",
    "bias.requires_grad_()\n",
    "\n",
    "print(x_train.shape)\n",
    "print(weights.shape)\n",
    "print(bias.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T02:04:42.999850Z",
     "start_time": "2019-10-18T02:04:42.985333Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: torch.Size([3, 784])\n",
      "mm Shape:  torch.Size([3, 10]) \n",
      "\n",
      "tensor([-0.5272,  0.0963,  0.0887, -0.0125, -0.1122, -0.2317, -0.3209, -0.2690,\n",
      "         0.1451,  0.1168], grad_fn=<SelectBackward>) \n",
      "\n",
      "tensor([-0.5272,  0.0963,  0.0887, -0.0125, -0.1122, -0.2317, -0.3209, -0.2690,\n",
      "         0.1451,  0.1168], grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor([[2.2223],\n",
      "        [2.4680],\n",
      "        [2.3355]], grad_fn=<UnsqueezeBackward0>) \n",
      "\n",
      "tensor([-2.7495, -2.1260, -2.1336, -2.2348, -2.3345, -2.4539, -2.5432, -2.4913,\n",
      "        -2.0772, -2.1055], grad_fn=<SelectBackward>)\n",
      "tensor([8, 1, 8])\n",
      "tensor([5, 0, 4])\n"
     ]
    }
   ],
   "source": [
    "xb = x_train[:3]\n",
    "yb = y_train[:3]\n",
    "print(\"shape:\",xb.shape)\n",
    "print(\"mm Shape: \",xb.mm(weights).shape,'\\n')\n",
    "print(xb.mm(weights)[0],'\\n')\n",
    "print(xb.mm(weights)[0]+bias,'\\n')\n",
    "xb = xb.mm(weights)+bias\n",
    "print(xb.exp().sum(-1).log().unsqueeze(-1),'\\n')\n",
    "print((xb - xb.exp().sum(-1).log().unsqueeze(-1))[0])\n",
    "pred = xb - xb.exp().sum(-1).log().unsqueeze(-1)\n",
    "print(torch.argmax(pred, 1))\n",
    "print(yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative log loss\n",
    "\n",
    "__Log loss__ (related to cross entropy measures performance of classification where prediction input is a prob value between 0 and 1. Perfect model should have log loss 0. \n",
    "\n",
    "Log loss increases as predicted prob diverges from actual label.\n",
    "\n",
    "<img src=http://wiki.fast.ai/images/math/8/a/a/8aa1e513366a2046bee816f7a0f8dd1c.png>\n",
    "\n",
    "Note that y=0 if incorrect class\n",
    "\n",
    "Since the activation function was log_softmax, we do not have to take the log of the activation again. Just take the negative activation of the True class for each example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T02:05:41.707654Z",
     "start_time": "2019-10-18T02:05:41.701757Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.)\n",
      "tensor(2.7102, grad_fn=<NegBackward>)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "def nll(input, target):\n",
    "    return -input[range(target.shape[0]),target].mean()\n",
    "\n",
    "def accuracy(input, target):\n",
    "    p = torch.argmax(input, dim=1)\n",
    "    return (p==target).float().mean()\n",
    "\n",
    "#yb = y_train[:batch_size]\n",
    "print(accuracy(pred,yb))\n",
    "print(nll(pred,yb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T02:05:44.827621Z",
     "start_time": "2019-10-18T02:05:44.792303Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.4539, 3.2070, 2.4697], grad_fn=<NegBackward>)\n",
      "tensor(2.7102, grad_fn=<NegBackward>)\n"
     ]
    }
   ],
   "source": [
    "# grab the log-prob of correct class\n",
    "print(-pred[range(yb.shape[0]),yb])\n",
    "#this is neg_log_loss for each example -> \n",
    "#average them for cost\n",
    "print(-pred[range(yb.shape[0]),yb].mean())\n",
    "#want to maximize this number -> make correct class as\n",
    "#large as possible\n",
    "\n",
    "#How does this work? seems like signs are wrong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then set the gradients to zero, so that we are ready for the next loop. Otherwise, our gradients would record a running tally of all the operations that had happened (i.e. loss.backward() adds the gradients to whatever is already stored, rather than replacing them).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T02:07:14.341333Z",
     "start_time": "2019-10-18T02:06:36.033495Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "#Xavier Initialization\n",
    "weights = torch.randn(784,10) / math.sqrt(784)\n",
    "weights.requires_grad_()\n",
    "bias = torch.zeros(10)\n",
    "bias.requires_grad_()\n",
    "\n",
    "\n",
    "epochs = 10 # each epoch goes over the entire training set\n",
    "batch_size = 64\n",
    "lr = 0.01\n",
    "n = x_train.shape[0]\n",
    "\n",
    "loss_hist = []\n",
    "for epoch in range(epochs):\n",
    "    for i in range((n-1)//batch_size): # // ~ int division\n",
    "        start = i * batch_size\n",
    "        end = (i + 1) * batch_size\n",
    "\n",
    "        xb, yb = x_train[start:end], y_train[start:end]\n",
    "        pred = model(xb)\n",
    "        loss = nll(pred, yb)\n",
    "        loss.backward()\n",
    "\n",
    "        with torch.no_grad(): #no_grad so we can do an in-place operation on a leaf node\n",
    "            weights -= lr*weights.grad\n",
    "            bias -= lr*bias.grad\n",
    "            weights.grad.zero_()\n",
    "            bias.grad.zero_()\n",
    "    loss_hist.append(loss.data.item())\n",
    "\n",
    "plt.title(\"Training Loss\")\n",
    "plt.plot(range(len(loss_hist)),loss_hist) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T02:07:14.656565Z",
     "start_time": "2019-10-18T02:07:14.640503Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3372, grad_fn=<NegBackward>)\n",
      "tensor(0.9093)\n"
     ]
    }
   ],
   "source": [
    "pred = model(x_valid)\n",
    "print(nll(pred, y_valid))\n",
    "print(accuracy(pred, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factoring with torch.nn\n",
    "Either make your code shorter, more understandable, or more flexible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T02:07:14.888290Z",
     "start_time": "2019-10-18T02:07:14.882742Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "#combines neg-log-likelihood loss and log-softmax\n",
    "loss_func = F.cross_entropy\n",
    "def model(xb):\n",
    "    return xb.mm(weights)+bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package the model into a Class\n",
    "Use `nn.Module` and `nn.Parameter` . Create a class that holds weights and methods for forward and backward prop.\n",
    "\n",
    "`nn.Module` class has a number of attributes and methods (such as `.parameters()` and `.zero_grad()`) which we will be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T02:07:15.061285Z",
     "start_time": "2019-10-18T02:07:15.056039Z"
    }
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weights = nn.Parameter(torch.randn(784,10) / math.sqrt(784))\n",
    "        self.bias = nn.Parameter(torch.zeros(10))\n",
    "        return None\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        return xb.mm(self.weights) + self.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with model.parameters() and model.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T02:07:36.390875Z",
     "start_time": "2019-10-18T02:07:36.382867Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0038,  0.0605, -0.0201,  ...,  0.0187,  0.0035,  0.0011],\n",
      "        [ 0.0449, -0.0991, -0.0366,  ..., -0.0118, -0.0203,  0.0033],\n",
      "        [-0.0556,  0.0002, -0.0154,  ...,  0.0077,  0.0253,  0.0694],\n",
      "        ...,\n",
      "        [-0.0340, -0.0125,  0.0073,  ...,  0.0392,  0.0326,  0.0563],\n",
      "        [-0.0217,  0.0066, -0.0273,  ..., -0.0443,  0.0208,  0.0057],\n",
      "        [ 0.0183, -0.0655, -0.0350,  ...,  0.0460,  0.0087,  0.0110]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "for param in model.parameters():\n",
    "        print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T02:08:07.018247Z",
     "start_time": "2019-10-18T02:07:36.669418Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Model()\n",
    "loss_func = F.cross_entropy\n",
    "\n",
    "def fit():\n",
    "    loss_hist = []\n",
    "    for epoch in range(epochs):\n",
    "        for i in range((n-1)//batch_size): # // ~ int division\n",
    "            start = i * batch_size\n",
    "            end = (i + 1) * batch_size\n",
    "\n",
    "            xb, yb = x_train[start:end], y_train[start:end]\n",
    "            pred = model(xb)\n",
    "            loss = loss_func(pred, yb)\n",
    "            \n",
    "            loss.backward()\n",
    "            with torch.no_grad():\n",
    "                for p in model.parameters(): #Update all weights at once\n",
    "                    p -= lr*p.grad\n",
    "                model.zero_grad()   #zero out gradients for all parameters\n",
    "        loss_hist.append(loss.data.item())\n",
    "        \n",
    "    return loss_hist\n",
    "    \n",
    "loss_hist = fit()\n",
    "\n",
    "plt.title(\"Training Loss\")\n",
    "plt.plot(range(len(loss_hist)),loss_hist) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With nn.Linear\n",
    "[link](https://pytorch.org/tutorials/beginner/nn_tutorial.html#refactor-using-nn-linear)\n",
    "Instead of `self.bias = nn.Parameter(torch.zeros(10))` instantiate with `nn.Linear`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T02:08:07.390280Z",
     "start_time": "2019-10-18T02:08:07.385292Z"
    }
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lin = nn.Linear(784,10)  #no need to initialize weights\n",
    "    def forward(self, xb):\n",
    "        return self.lin(xb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With optim\n",
    "instead of `p -= p.grad * lr`, use `torch.optim` to calculate an optimal step for rach batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T02:08:12.732212Z",
     "start_time": "2019-10-18T02:08:07.574101Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "epochs = 10\n",
    "bs = 64\n",
    "lr = 0.01\n",
    "\n",
    "model = Model()\n",
    "loss_func = F.cross_entropy\n",
    "#choose the right optimizer, SQG ~ fixed steps\n",
    "opt = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range((n - 1) // bs + 1):\n",
    "        start_i = i * bs\n",
    "        end_i = start_i + bs\n",
    "        xb = x_train[start_i:end_i]\n",
    "        yb = y_train[start_i:end_i]\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        #update parameters automatically based on gradients\n",
    "        opt.step()  \n",
    "        opt.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Dataset\n",
    "\n",
    "PyTorchs `TensorDataset` is a Dataset wrapping tensors. By defining a length and way of indexing, this also gives us a way to iterate, index, and slice along the first dimension of a tensor. This will make it easier to access both the independent and dependent variables in the same line as we train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T02:12:59.964668Z",
     "start_time": "2019-10-18T02:12:54.814885Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "train_ds = TensorDataset(x_train, y_train) #smoosh that data together\n",
    "model = Model()\n",
    "loss_func = F.cross_entropy\n",
    "opt = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range((n - 1) // bs + 1):\n",
    "        xb, yb = train_ds[i * bs: i * bs + bs] #iterate in one line\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T02:13:18.365462Z",
     "start_time": "2019-10-18T02:13:00.233821Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "model = Model()\n",
    "loss_func = F.cross_entropy\n",
    "opt = optim.SGD(model.parameters(), lr=lr)\n",
    "#####################################################\n",
    "\n",
    "train_ds = TensorDataset(x_train, y_train)\n",
    "#automatic iterator over Dataset object\n",
    "train_dl = DataLoader(train_ds, \n",
    "                      batch_size=bs,\n",
    "                     shuffle=True)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for xb,yb in train_dl: #easy iteration through your dataset\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Validation\n",
    "\n",
    "In section 1, we were just trying to get a reasonable training loop set up for use on our training data. In reality, you always should also have a __validation set__, in order to identify if you are overfitting.\n",
    "\n",
    "__Shuffling the training data__ is important to prevent correlation between batches and overfitting. On the other hand, the validation loss will be identical whether we shuffle the validation set or not. Since shuffling takes extra time, it makes no sense to shuffle the validation data.\n",
    "\n",
    "Well use a batch size for the validation set that is twice as large as that for the training set. This is because the __validation set does not need backpropagation and thus takes less memory__ (it doesnt need to store the gradients). We take advantage of this to use a larger batch size and compute the loss more quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T02:14:19.161730Z",
     "start_time": "2019-10-18T02:13:18.649954Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "valid_ds = TensorDataset(x_valid, y_valid)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=bs * 2)\n",
    "\n",
    "epochs = 10\n",
    "model = Model()\n",
    "loss_func = F.cross_entropy\n",
    "opt = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "train_loss =[]\n",
    "val_loss = []\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for xb,yb in train_dl:\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "        \n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    \n",
    "    train_loss.append(loss.item())\n",
    "    model.eval() #call this to keep models like batchnorm and dropout \n",
    "    with torch.no_grad():\n",
    "        valid = sum(loss_func(model(xb), yb) for xb, yb in valid_dl)/(y_valid.shape[0]//bs)\n",
    "        val_loss.append(valid.item())\n",
    "\n",
    "plt.title(\"Training-Validation Loss\")\n",
    "plt.plot(range(len(train_loss)),train_loss) \n",
    "plt.plot(range(len(val_loss)),val_loss) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create helper functions\n",
    "\n",
    "[link](https://pytorch.org/tutorials/beginner/nn_tutorial.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T02:20:49.842145Z",
     "start_time": "2019-10-18T02:19:47.182704Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.3389158097743988\n",
      "1 0.3067798109531403\n",
      "2 0.29315096558332443\n",
      "3 0.28442450717687606\n",
      "4 0.2801130482196808\n",
      "5 0.2775348304629326\n",
      "6 0.27625955839157107\n",
      "7 0.27282633156776426\n",
      "8 0.2709454197406769\n",
      "9 0.2699028342008591\n",
      "10 0.2673029819011688\n",
      "11 0.26685731422901154\n",
      "12 0.26715501942634584\n",
      "13 0.26514497152566907\n",
      "14 0.2663704557955265\n",
      "15 0.26351123942136767\n",
      "16 0.26445348378419875\n",
      "17 0.26294642906188964\n",
      "18 0.26230059801340105\n",
      "19 0.26210777661800383\n",
      "20 0.2611381888628006\n",
      "21 0.26052178966403006\n",
      "22 0.26141355090141294\n",
      "23 0.2642173074483872\n",
      "24 0.26045167765021326\n",
      "25 0.2590922660529614\n",
      "26 0.26138583382368086\n",
      "27 0.2592720721840858\n",
      "28 0.26183348557949065\n",
      "29 0.25875099403262136\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_model():\n",
    "    model = Model()\n",
    "    return model, optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "\n",
    "def loss_batch(model, loss_func, xb, yb, opt=None):\n",
    "    loss = loss_func(model(xb), yb)\n",
    "\n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    return loss.item(), len(xb)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for xb, yb in train_dl:\n",
    "            loss_batch(model, loss_func, xb, yb, opt)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            losses, nums = zip(\n",
    "                *[loss_batch(model, loss_func, xb, yb) for xb, yb in valid_dl]\n",
    "            )\n",
    "        val_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
    "\n",
    "        print(epoch, val_loss)\n",
    "        \n",
    "        \n",
    "def get_data(train_ds, valid_ds, bs):\n",
    "    return (\n",
    "        DataLoader(train_ds, batch_size=bs, shuffle=True),\n",
    "        DataLoader(valid_ds, batch_size=bs * 2),\n",
    "    )\n",
    "\n",
    "\n",
    "train_dl, valid_dl = get_data(train_ds, valid_ds, bs)\n",
    "model, opt = get_model()\n",
    "fit(epochs, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ConvNets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T02:47:28.780977Z",
     "start_time": "2019-10-18T02:47:28.774792Z"
    }
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1,16, kernel_size=3,stride=2,padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1)\n",
    "    def forward(self, xb):\n",
    "        xb = xb.view(-1, 1, 28, 28)\n",
    "        xb = F.relu(self.conv1(xb))\n",
    "        xb = F.relu(self.conv2(xb))\n",
    "        xb = F.relu(self.conv3(xb))\n",
    "        xb = F.avg_pool2d(xb, 4)\n",
    "        return xb.view(-1, xb.size(1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T02:49:04.833706Z",
     "start_time": "2019-10-18T02:47:29.387859Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.5522479145050049\n",
      "1 0.3980927963256836\n",
      "2 0.2782034362077713\n",
      "3 0.21448879919052125\n",
      "4 0.22370268186330794\n"
     ]
    }
   ],
   "source": [
    "model=CNN()\n",
    "opt=optim.SGD(model.parameters(), lr=0.03, momentum=0.9)\n",
    "fit(epochs, model, loss_func, opt, train_dl, valid_dl)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T02:49:35.291544Z",
     "start_time": "2019-10-18T02:49:35.286586Z"
    }
   },
   "outputs": [],
   "source": [
    "#create a custom layer\n",
    "\n",
    "class Lambda(nn.Module):\n",
    "    def __init__(self, func):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.func(x)\n",
    "\n",
    "\n",
    "def preprocess(x):\n",
    "    return x.view(-1, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T02:51:10.965413Z",
     "start_time": "2019-10-18T02:49:35.817193Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6595972821235657\n",
      "1 0.3279928419113159\n",
      "2 0.2508931781232357\n",
      "3 0.21666518794894218\n",
      "4 0.27602433536946774\n",
      "tensor([3, 0, 4])\n",
      "tensor([5, 0, 4])\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "lr=0.03\n",
    "model = nn.Sequential(\n",
    "    Lambda(preprocess),\n",
    "    nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.AvgPool2d(4),\n",
    "    Lambda(lambda x: x.view(x.size(0), -1)),\n",
    ")\n",
    "\n",
    "opt = optim.SGD(model.parameters(), lr=lr, momentum=0.3)\n",
    "fit(epochs,model,loss_func,opt,train_dl,valid_dl)\n",
    "\n",
    "print(torch.argmax(model(x_train[:3]), dim=1))\n",
    "print(y_train[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrapping DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T03:01:09.225633Z",
     "start_time": "2019-10-18T03:01:09.219432Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess(x, y): # the iterator gives X and y\n",
    "    return x.view(-1,1,28,28), y\n",
    "\n",
    "class WrappedDataLoader():\n",
    "    \"\"\"\n",
    "    Create a custom iterator that processes your dataset.\n",
    "    \"\"\"\n",
    "    def __init__(self, dl, func):\n",
    "        self.dl = dl\n",
    "        self.func = func\n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n",
    "    def __iter__(self):\n",
    "        batches = iter(self.dl)\n",
    "        for b in batches:\n",
    "            yield (self.func(*b))\n",
    "            \n",
    "train_dl, valid_dl = get_data(train_ds, valid_ds, bs)\n",
    "train_dl = WrappedDataLoader(train_dl, preprocess)\n",
    "valid_dl = WrappedDataLoader(valid_dl, preprocess)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T03:02:45.355518Z",
     "start_time": "2019-10-18T03:01:09.478952Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.9293505615234375\n",
      "1 0.333184059882164\n",
      "2 0.2696040114879608\n",
      "3 0.2218672159910202\n",
      "4 0.231476465600729\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.AdaptiveAvgPool2d(1), #adapts to the size of the image, outputs 1 dim\n",
    "    Lambda(lambda x: x.view(x.size(0), -1)),\n",
    ")\n",
    "\n",
    "opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "fit(epochs, model, loss_func, opt, train_dl, valid_dl)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using your GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T03:02:45.860208Z",
     "start_time": "2019-10-18T03:02:45.855221Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T03:02:46.155115Z",
     "start_time": "2019-10-18T03:02:46.151293Z"
    }
   },
   "outputs": [],
   "source": [
    "#create a device object to represent your GPU\n",
    "dev = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T03:11:49.660616Z",
     "start_time": "2019-10-18T03:11:08.113317Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.2595356033325196\n",
      "1 1.642110375213623\n",
      "2 1.2932282413482665\n",
      "3 0.8977149812698364\n",
      "4 0.7996481155395507\n",
      "5 0.8012100366592407\n",
      "6 0.707154974269867\n",
      "7 0.5995462689399719\n",
      "8 0.7608398029327392\n",
      "9 0.4844808643341064\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.AdaptiveAvgPool2d(1), #adapts to the size of the image, outputs 1 dim\n",
    "    Lambda(lambda x: x.view(x.size(0), -1)),\n",
    ")\n",
    "\n",
    "\n",
    "def preprocess(x, y):\n",
    "    return x.view(-1,1,28,28).to(dev), y.to(dev)\n",
    "\n",
    "train_dl = DataLoader(train_ds,batch_size=bs,shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=bs)\n",
    "train_dl = WrappedDataLoader(train_dl, preprocess)\n",
    "valid_dl = WrappedDataLoader(valid_dl, preprocess)\n",
    "\n",
    "model.to(dev)\n",
    "opt = optim.SGD(model.parameters(),lr=0.03)\n",
    "fit(10, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Closing thoughts\n",
    "We now have a general data pipeline and training loop which you can use for training many types of models using Pytorch. To see how simple training a model can now be, take a look at the mnist_sample sample notebook.\n",
    "\n",
    "Of course, there are many things youll want to add, such as data augmentation, hyperparameter tuning, monitoring training, transfer learning, and so forth. These features are available in the fastai library, which has been developed using the same design approach shown in this tutorial, providing a natural next step for practitioners looking to take their models further.\n",
    "\n",
    "We promised at the start of this tutorial wed explain through example each of torch.nn, torch.optim, Dataset, and DataLoader. So lets summarize what weve seen:\n",
    "\n",
    "torch.nn\n",
    "\n",
    "Module: creates a callable which behaves like a function, but can also contain state(such as neural net layer weights). It knows what Parameter (s) it contains and can zero all their gradients, loop through them for weight updates, etc.\n",
    "\n",
    "Parameter: a wrapper for a tensor that tells a Module that it has weights that need updating during backprop. Only tensors with the requires_grad attribute set are updated\n",
    "\n",
    "functional: a module(usually imported into the F namespace by convention) which contains activation functions, loss functions, etc, as well as non-stateful versions of layers such as convolutional and linear layers.\n",
    "\n",
    "torch.optim: Contains optimizers such as SGD, which update the weights of Parameter during the backward step\n",
    "\n",
    "Dataset: An abstract interface of objects with a __len__ and a __getitem__, including classes provided with Pytorch such as TensorDataset\n",
    "\n",
    "DataLoader: Takes any Dataset and creates an iterator which returns batches of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and Loading Modules\n",
    "[link](https://pytorch.org/tutorials/beginner/saving_loading_models.html)\n",
    "\n",
    "### Three core functionalities\n",
    "1. `torch.save` - serialize an object to disk using pickle.\n",
    "2. `torch.load` - deserialize a file into an object\n",
    "3. `torch.nn.Module.load_save_dict` -Model has a parameter dictionary, this loads that parameter dict with a deserialized state_dict.\n",
    "\n",
    "### What is a `state dict`?\n",
    "Parameters are stored and can be accessed `model.parameters()`. State_dict is a Python dictionary that maps each layer to its parameter tensor. Only layers with learnable parameters are present in the state_dict. `torch.optim` objects also have a `state_dict`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T19:07:25.156276Z",
     "start_time": "2019-10-19T19:07:25.143795Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state dict\n",
      "conv1.weight \t torch.Size([6, 3, 5, 5])\n",
      "conv1.bias \t torch.Size([6])\n",
      "conv2.weight \t torch.Size([16, 6, 5, 5])\n",
      "conv2.bias \t torch.Size([16])\n",
      "fc1.weight \t torch.Size([100, 400])\n",
      "fc1.bias \t torch.Size([100])\n",
      "fc2.weight \t torch.Size([84, 100])\n",
      "fc2.bias \t torch.Size([84])\n",
      "fc3.weight \t torch.Size([10, 84])\n",
      "fc3.bias \t torch.Size([10])\n",
      "\n",
      "Optiimizer state dict\n",
      "param_groups \t [{'nesterov': False, 'weight_decay': 0, 'lr': 0.001, 'dampening': 0, 'momentum': 0.9, 'params': [1965805366008, 1965805478248, 1965805478320, 1965805478104, 1965805367016, 1965805478896, 1965805478752, 1965805478680, 1965805478464, 1965805478968]}]\n",
      "state \t {}\n"
     ]
    }
   ],
   "source": [
    "class Model(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3,6,5)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.conv2 = nn.Conv2d(6,16, 5)\n",
    "        self.fc1 = nn.Linear(5*5*16,100)\n",
    "        self.fc2 = nn.Linear(100,84)\n",
    "        self.fc3 = nn.Linear(84,10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "model = Model()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum = 0.9)\n",
    "\n",
    "print(\"Model's state dict\")\n",
    "for param in model.state_dict():\n",
    "    print(param, '\\t', model.state_dict()[param].size())\n",
    "print()\n",
    "\n",
    "print(\"Optiimizer state dict\")\n",
    "for param in optimizer.state_dict():\n",
    "    print(param, '\\t', optimizer.state_dict()[param])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T19:09:51.591378Z",
     "start_time": "2019-10-19T19:09:51.563334Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parameter containing:\n",
      "tensor([[[[-0.0677,  0.0495, -0.1024, -0.0288,  0.0150],\n",
      "          [ 0.0089,  0.0648, -0.0243, -0.1149, -0.0608],\n",
      "          [-0.0073,  0.0856,  0.0961,  0.0575, -0.0908],\n",
      "          [ 0.0819, -0.0539, -0.0713, -0.0717, -0.1135],\n",
      "          [ 0.0187, -0.0606, -0.0438,  0.0182,  0.1140]],\n",
      "\n",
      "         [[-0.0478,  0.0610,  0.1071,  0.0622,  0.0474],\n",
      "          [-0.0730,  0.1031,  0.0523, -0.1106,  0.0753],\n",
      "          [ 0.0329,  0.0756, -0.0991, -0.0225,  0.0712],\n",
      "          [ 0.0546,  0.0377, -0.1027, -0.0913,  0.0827],\n",
      "          [-0.1059,  0.1057,  0.0868,  0.0855, -0.0582]],\n",
      "\n",
      "         [[ 0.0763, -0.0679, -0.0913,  0.0349,  0.0207],\n",
      "          [-0.0685, -0.0617,  0.0178,  0.0948,  0.0173],\n",
      "          [-0.0272, -0.0427, -0.0233, -0.0380,  0.1089],\n",
      "          [ 0.0600, -0.0861,  0.0348, -0.0092, -0.0611],\n",
      "          [-0.0331,  0.0114, -0.0381,  0.1013,  0.0244]]],\n",
      "\n",
      "\n",
      "        [[[-0.0183,  0.0002,  0.0252,  0.0493,  0.1008],\n",
      "          [ 0.1019,  0.1145,  0.0533, -0.0264, -0.0061],\n",
      "          [ 0.0525,  0.0838, -0.0589, -0.0818, -0.0882],\n",
      "          [ 0.0589, -0.0496,  0.0184,  0.1043,  0.0401],\n",
      "          [ 0.0805, -0.0861,  0.0942,  0.1091,  0.0974]],\n",
      "\n",
      "         [[ 0.0051, -0.0517,  0.0830, -0.0182,  0.0161],\n",
      "          [ 0.0405,  0.0920,  0.1044, -0.0109, -0.0623],\n",
      "          [ 0.0793, -0.0589,  0.0848, -0.0030, -0.0935],\n",
      "          [-0.0187,  0.0164,  0.0856,  0.0457,  0.0779],\n",
      "          [-0.0371, -0.0902, -0.0427, -0.1045, -0.0164]],\n",
      "\n",
      "         [[-0.0627, -0.0032, -0.0109, -0.0624, -0.0141],\n",
      "          [ 0.0293, -0.0453, -0.0561,  0.0284, -0.0869],\n",
      "          [ 0.0944, -0.0003, -0.0312,  0.0227, -0.0571],\n",
      "          [ 0.0801,  0.0366,  0.0655, -0.0944, -0.0213],\n",
      "          [-0.0137,  0.0252,  0.0397,  0.1100,  0.0105]]],\n",
      "\n",
      "\n",
      "        [[[-0.1099, -0.0535,  0.0056,  0.0513,  0.0099],\n",
      "          [ 0.0263,  0.0530, -0.0942, -0.0076, -0.0445],\n",
      "          [-0.0140, -0.0776,  0.0016, -0.1138, -0.0575],\n",
      "          [ 0.0886, -0.0986, -0.0267,  0.0300,  0.0383],\n",
      "          [-0.0226, -0.0444, -0.0706,  0.0969,  0.0489]],\n",
      "\n",
      "         [[-0.1101, -0.0540, -0.0375,  0.0541,  0.0799],\n",
      "          [ 0.0127, -0.0872,  0.0028,  0.0450, -0.0909],\n",
      "          [ 0.0355,  0.0117, -0.0119, -0.1005, -0.0240],\n",
      "          [-0.0632,  0.1091,  0.0540,  0.0001, -0.0891],\n",
      "          [ 0.0351, -0.0787,  0.0255, -0.0296,  0.1114]],\n",
      "\n",
      "         [[-0.0378, -0.0160,  0.0241,  0.0410,  0.0435],\n",
      "          [-0.0041,  0.0081,  0.0613,  0.0843, -0.0107],\n",
      "          [-0.0574,  0.1138,  0.0793,  0.0532, -0.0779],\n",
      "          [ 0.0719,  0.0569,  0.0875, -0.1127,  0.0943],\n",
      "          [ 0.0488,  0.0376, -0.0003, -0.0778,  0.0572]]],\n",
      "\n",
      "\n",
      "        [[[-0.0435,  0.0551,  0.0299, -0.0950, -0.0882],\n",
      "          [ 0.0527, -0.1051, -0.0035, -0.0343, -0.0459],\n",
      "          [ 0.1141,  0.0854,  0.1088, -0.0967,  0.0412],\n",
      "          [-0.0148,  0.0918,  0.0274,  0.1118, -0.0290],\n",
      "          [ 0.0862,  0.0996, -0.0650, -0.0802,  0.0623]],\n",
      "\n",
      "         [[-0.1128, -0.0129,  0.0975,  0.0956, -0.1096],\n",
      "          [-0.0404,  0.0453, -0.0062,  0.0635, -0.0200],\n",
      "          [ 0.0618, -0.0542, -0.0357, -0.1058, -0.1030],\n",
      "          [-0.0066,  0.1043, -0.0870, -0.0504, -0.0115],\n",
      "          [-0.0958, -0.0311,  0.0929, -0.1138, -0.0809]],\n",
      "\n",
      "         [[ 0.0477,  0.0633,  0.0313, -0.0580, -0.1102],\n",
      "          [-0.0353, -0.0650,  0.0518,  0.0291, -0.1095],\n",
      "          [-0.1146,  0.1151,  0.0644, -0.0883,  0.0020],\n",
      "          [-0.0515, -0.1086, -0.0821, -0.1019, -0.0097],\n",
      "          [ 0.0531,  0.0028, -0.0414, -0.0179,  0.1133]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0247, -0.0193,  0.0508, -0.0298, -0.0135],\n",
      "          [-0.0706, -0.1116,  0.0903, -0.0337, -0.0800],\n",
      "          [-0.1048, -0.0352, -0.0935,  0.0349,  0.1108],\n",
      "          [ 0.0704,  0.0522,  0.0402,  0.0724, -0.0194],\n",
      "          [ 0.0384,  0.0965,  0.0536, -0.0888, -0.0669]],\n",
      "\n",
      "         [[ 0.0215,  0.0564,  0.0973,  0.0736,  0.0222],\n",
      "          [-0.0414,  0.0227, -0.0771, -0.0450,  0.0592],\n",
      "          [ 0.0565, -0.0721,  0.0455, -0.0593, -0.0346],\n",
      "          [ 0.0490,  0.0318,  0.0067, -0.0965,  0.0933],\n",
      "          [ 0.0809,  0.0577,  0.0323, -0.0659,  0.0120]],\n",
      "\n",
      "         [[ 0.0388,  0.0307, -0.0260,  0.0541, -0.0375],\n",
      "          [ 0.0206, -0.0408, -0.0297, -0.0725, -0.0679],\n",
      "          [-0.0004,  0.0602, -0.0323, -0.0770, -0.0787],\n",
      "          [ 0.0428,  0.0183,  0.0716, -0.0009, -0.1043],\n",
      "          [-0.0257,  0.0359,  0.0734, -0.0499, -0.0208]]],\n",
      "\n",
      "\n",
      "        [[[-0.0617,  0.0079, -0.0380, -0.0305,  0.0946],\n",
      "          [-0.0045,  0.0835, -0.0842, -0.1050,  0.0358],\n",
      "          [ 0.0427, -0.0116,  0.1103,  0.0045,  0.0512],\n",
      "          [ 0.0916,  0.1074,  0.1009,  0.0173,  0.1001],\n",
      "          [ 0.0250,  0.0994, -0.0152,  0.0182, -0.0531]],\n",
      "\n",
      "         [[ 0.0145, -0.0267, -0.0792, -0.1118, -0.0600],\n",
      "          [-0.0504, -0.0199,  0.0320,  0.0730,  0.0647],\n",
      "          [ 0.0168, -0.0371, -0.0312, -0.0868,  0.1067],\n",
      "          [ 0.0197, -0.0408,  0.0284,  0.0649, -0.0301],\n",
      "          [ 0.0167,  0.0773, -0.1147,  0.0989, -0.0410]],\n",
      "\n",
      "         [[ 0.0086,  0.0629, -0.0226, -0.0522,  0.0201],\n",
      "          [-0.0048, -0.0743,  0.0506, -0.0271, -0.0113],\n",
      "          [-0.0662, -0.1096,  0.0228,  0.0245,  0.0919],\n",
      "          [ 0.1045,  0.0505, -0.0263,  0.0540, -0.0089],\n",
      "          [ 0.0331,  0.0226, -0.0386, -0.1130,  0.0732]]]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "#print(model.state_dict()) dictionary with all parameters\n",
    "print()\n",
    "#print(model.parameters()) #python generator with \n",
    "start = True\n",
    "for i in model.parameters():\n",
    "    if start:\n",
    "        print(i)\n",
    "        start=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving a model for inference\n",
    "Remember that you must call `model.eval()` to set dropout and batch normalization layers to evaluation mode before running inference. Failing to do this will yield inconsistent inference results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T19:12:57.196100Z",
     "start_time": "2019-10-19T19:12:57.155528Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=100, bias=True)\n",
       "  (fc2): Linear(in_features=100, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(model.state_dict(), 'model_state_dict.pkl')\n",
    "taco = Model()\n",
    "\n",
    "#takes dictionary object\n",
    "taco.load_state_dict(torch.load('model_state_dict.pkl'))\n",
    "taco.eval()   #ets the module in evaluation mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save load entire model\n",
    "This save/load process uses the most intuitive syntax and involves the least amount of code. Saving a model in this way will save the entire module using Pythons pickle module. The disadvantage of this approach is that the serialized data is bound to the specific classes and the exact directory structure used when the model is saved. The reason for this is because pickle does not save the model class itself. Rather, __it saves a path to the file containing the class, which is used during load time. Because of this, your code can break__ in various ways when used in other projects or after refactors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, PATH)\n",
    "# Model class must be defined somewhere\n",
    "model = torch.load(PATH)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving a general checkpoint for inference and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH='model_state_dict.pkl'\n",
    "\n",
    "state = {\n",
    "    'epoch':epoch+1,\n",
    "    'state_dict':model.state_dict(),\n",
    "    'optim_dict':optimizer.state_dict(),\n",
    "}\n",
    "\n",
    "torch.save(state, PATH)\n",
    "\n",
    "\n",
    "model = TheModelClass(*args, **kwargs)\n",
    "optimizer = TheOptimizerClass(*args, **kwargs)\n",
    "\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "\n",
    "model.eval()\n",
    "# or\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Multiple Models in One File\n",
    "When saving a model comprised of multiple torch.nn.Modules, such as a GAN, a sequence-to-sequence model, or an ensemble of models, you follow the same approach as when you are saving a general checkpoint. In other words, save a dictionary of each models state_dict and corresponding optimi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'modelA_state_dict': modelA.state_dict(),\n",
    "            'modelB_state_dict': modelB.state_dict(),\n",
    "            'optimizerA_state_dict': optimizerA.state_dict(),\n",
    "            'optimizerB_state_dict': optimizerB.state_dict(),\n",
    "            ...\n",
    "            }, PATH)\n",
    "\n",
    "checkpoint = torch.load(PATH)\n",
    "modelA.load_state_dict(checkpoint['modelA_state_dict'])\n",
    "modelB.load_state_dict(checkpoint['modelB_state_dict'])\n",
    "optimizerA.load_state_dict(checkpoint['optimizerA_state_dict'])\n",
    "optimizerB.load_state_dict(checkpoint['optimizerB_state_dict'])\n",
    "\n",
    "modelA.eval()\n",
    "modelB.eval()\n",
    "# - or -\n",
    "modelA.train()\n",
    "modelB.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warmstarting with params from a trained model\n",
    "\n",
    "Whether you are loading from a partial state_dict, which is missing some keys, or loading a state_dict with more keys than the model that you are loading into, you can set the strict argument to False in the `load_state_dict()` function to ignore non-matching keys.\n",
    "\n",
    "If you want to load parameters from one layer to another, but some keys do not match, simply change the name of the parameter keys in the state_dict that you are loading to match the keys in the model that you are loading into."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(modelA.state_dict(), PATH)\n",
    "\n",
    "\n",
    "modelB = TheModelBClass(*args, **kwargs)\n",
    "modelB.load_state_dict(torch.load(PATH), strict=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save on GPU, Load on GPU\n",
    "\n",
    "When loading a model on a GPU that was trained and saved on GPU, simply convert the initialized model to a CUDA optimized model using `model.to(torch.device('cuda'))`. Also, be sure to use the `.to(torch.device('cuda'))` function __on all model inputs__ to prepare the data for the model. Note that calling `my_tensor.to(device)` __returns a new copy of my_tensor on GPU__. It does NOT overwrite my_tensor. __Therefore, remember to manually overwrite tensors__: `my_tensor = my_tensor.to(torch.device('cuda'))`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVE\n",
    "torch.save(model.state_dict(), PATH)\n",
    "\n",
    "\n",
    "#LOAD\n",
    "device = torch.device('cuda')\n",
    "model = Model()\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.save_checkpoint(state,\n",
    "                     isbest=True,\n",
    "                     checkpoint='filepath')\n",
    "utils.load_checkpoint(restore_path, \n",
    "                      model, \n",
    "                      optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 16, 50, 100])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 33, 26, 100])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = nn.Conv2d(16,33,(3,5), \n",
    "              stride=(2,1), \n",
    "              padding = (4,2), \n",
    "              dilation=(3,1))\n",
    "input = Variable(torch.randn(20,16,50,100))\n",
    "print(input.shape)\n",
    "m(input).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.,  1.,  2.,  3.],\n",
      "         [ 4.,  5.,  6.,  7.],\n",
      "         [ 8.,  9., 10., 11.],\n",
      "         [12., 13., 14., 15.]]], dtype=torch.float64) torch.Size([1, 4, 4]) \n",
      "\n",
      "tensor([[[ 5.,  7.],\n",
      "         [13., 15.]]], dtype=torch.float64) torch.Size([1, 2, 2]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Max Pooling - cuts the size in have by retaining only the max \n",
    "value in a subset of a matrix. Outputs a smaller matrix with\n",
    "the combined max values for the subcells.\n",
    "\n",
    "Reduces the number of parameters to learn and provides basic \n",
    " translation invariance to the internal representation.\n",
    "\"\"\"\n",
    "m = nn.MaxPool2d((2,2))\n",
    "x = torch.arange(16, dtype = torch.float64).reshape(-1,4).unsqueeze(0)\n",
    "pooled= m(x)\n",
    "_print(x)\n",
    "_print(pooled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 2.5000,  4.5000],\n",
      "         [10.5000, 12.5000]]], dtype=torch.float64) torch.Size([1, 2, 2]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "m = nn.AvgPool2d(2)\n",
    "_print(m(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-Linear Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6745,  0.9691,  1.0134],\n",
      "        [-0.3971,  0.3070, -0.0195],\n",
      "        [ 0.0943, -0.8966,  0.7574]]) torch.Size([3, 3]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = Variable(torch.randn(3,3))\n",
    "_print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.9691, 1.0134],\n",
      "        [0.0000, 0.3070, 0.0000],\n",
      "        [0.0943, 0.0000, 0.7574]]) torch.Size([3, 3]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "m = nn.ReLU()\n",
    "_print(m(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-6.7450e-03,  9.6910e-01,  1.0134e+00],\n",
      "        [-3.9710e-03,  3.0700e-01, -1.9512e-04],\n",
      "        [ 9.4303e-02, -8.9660e-03,  7.5740e-01]]) torch.Size([3, 3]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "m = nn.LeakyReLU()\n",
    "_print(m(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3375, 0.7249, 0.7337],\n",
      "        [0.4020, 0.5762, 0.4951],\n",
      "        [0.5236, 0.2897, 0.6808]]) torch.Size([3, 3]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "m = nn.Sigmoid()\n",
    "_print(m(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2234, 0.5986, 0.4695],\n",
      "        [0.2948, 0.3087, 0.1671],\n",
      "        [0.4819, 0.0927, 0.3634]]) torch.Size([3, 3]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "m = nn.Softmax(dim=0)\n",
    "_print(m(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "nn.BatchNorm1d(\n",
    "    num_features,\n",
    "    eps=1e-05,\n",
    "    momentum=0.1,\n",
    "    affine=True,\n",
    "    track_running_stats=True,\n",
    ")\n",
    "Docstring:     \n",
    "Applies Batch Normalization over a 2D or 3D input (a mini-batch of 1D\n",
    "inputs with optional additional channel dimension) as described in the paper\n",
    "`Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift`_ .\n",
    "\"\"\"\n",
    "\n",
    "nn.BatchNorm1d(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 20])\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "\"\"\"\n",
    "Applies a multi-layer Elman RNN with :math:`tanh` or :math:`ReLU` non-linearity to an\n",
    "input sequence.\n",
    "\n",
    "\n",
    "For each element in the input sequence, each layer computes the following\n",
    "function:\n",
    "\n",
    ".. math::\n",
    "    h_t = \\text{tanh}(W_{ih} x_t + b_{ih} + W_{hh} h_{(t-1)} + b_{hh})\n",
    "\n",
    "where :math:`h_t` is the hidden state at time `t`, :math:`x_t` is\n",
    "the input at time `t`, and :math:`h_{(t-1)}` is the hidden state of the\n",
    "previous layer at time `t-1` or the initial hidden state at time `0`.\n",
    "If :attr:`nonlinearity` is ``'relu'``, then `ReLU` is used instead of `tanh`.\n",
    "\n",
    "Args:\n",
    "    input_size: The number of expected features in the input `x`\n",
    "    hidden_size: The number of features in the hidden state `h`\n",
    "    num_layers: Number of recurrent layers. E.g., setting ``num_layers=2``\n",
    "        would mean stacking two RNNs together to form a `stacked RNN`,\n",
    "        with the second RNN taking in outputs of the first RNN and\n",
    "        computing the final results. Default: 1\n",
    "    nonlinearity: The non-linearity to use. Can be either ``'tanh'`` or ``'relu'``. Default: ``'tanh'``\n",
    "    bias: If ``False``, then the layer does not use bias weights `b_ih` and `b_hh`.\n",
    "        Default: ``True``\n",
    "    batch_first: If ``True``, then the input and output tensors are provided\n",
    "        as `(batch, seq, feature)`. Default: ``False``\n",
    "    dropout: If non-zero, introduces a `Dropout` layer on the outputs of each\n",
    "        RNN layer except the last layer, with dropout probability equal to\n",
    "        :attr:`dropout`. Default: 0\n",
    "    bidirectional: If ``True``, becomes a bidirectional RNN. Default: ``False``\n",
    "\n",
    "Inputs: input, h_0\n",
    "    - **input** of shape `(seq_len, batch, input_size)`: tensor containing the features\n",
    "      of the input sequence. The input can also be a packed variable length\n",
    "      sequence. See :func:`torch.nn.utils.rnn.pack_padded_sequence`\n",
    "      or :func:`torch.nn.utils.rnn.pack_sequence`\n",
    "      for details.\n",
    "    - **h_0** of shape `(num_layers * num_directions, batch, hidden_size)`: tensor\n",
    "      containing the initial hidden state for each element in the batch.\n",
    "      Defaults to zero if not provided. If the RNN is bidirectional,\n",
    "      num_directions should be 2, else it should be 1.\n",
    "\n",
    "Outputs: output, h_n\n",
    "    - **output** of shape `(seq_len, batch, num_directions * hidden_size)`: tensor\n",
    "      containing the output features (`h_t`) from the last layer of the RNN,\n",
    "      for each `t`.  If a :class:`torch.nn.utils.rnn.PackedSequence` has\n",
    "      been given as the input, the output will also be a packed sequence.\n",
    "\n",
    "      For the unpacked case, the directions can be separated\n",
    "      using ``output.view(seq_len, batch, num_directions, hidden_size)``,\n",
    "      with forward and backward being direction `0` and `1` respectively.\n",
    "      Similarly, the directions can be separated in the packed case.\n",
    "    - **h_n** of shape `(num_layers * num_directions, batch, hidden_size)`: tensor\n",
    "      containing the hidden state for `t = seq_len`.\n",
    "\n",
    "      Like *output*, the layers can be separated using\n",
    "      ``h_n.view(num_layers, num_directions, batch, hidden_size)``.\n",
    "\n",
    "Shape:\n",
    "    - Input1: :math:`(L, N, H_{in})` tensor containing input features where\n",
    "      :math:`H_{in}=\\text{input\\_size}` and `L` represents a sequence length.\n",
    "    - Input2: :math:`(S, N, H_{out})` tensor\n",
    "      containing the initial hidden state for each element in the batch.\n",
    "      :math:`H_{out}=\\text{hidden\\_size}`\n",
    "      Defaults to zero if not provided. where :math:`S=\\text{num\\_layers} * \\text{num\\_directions}`\n",
    "      If the RNN is bidirectional, num_directions should be 2, else it should be 1.\n",
    "    - Output1: :math:`(L, N, H_{all})` where :math:`H_{all}=\\text{num\\_directions} * \\text{hidden\\_size}`\n",
    "    - Output2: :math:`(S, N, H_{out})` tensor containing the next hidden state\n",
    "      for each element in the batch\n",
    "\n",
    "Attributes:\n",
    "    weight_ih_l[k]: the learnable input-hidden weights of the k-th layer,\n",
    "        of shape `(hidden_size, input_size)` for `k = 0`. Otherwise, the shape is\n",
    "        `(hidden_size, num_directions * hidden_size)`\n",
    "    weight_hh_l[k]: the learnable hidden-hidden weights of the k-th layer,\n",
    "        of shape `(hidden_size, hidden_size)`\n",
    "    bias_ih_l[k]: the learnable input-hidden bias of the k-th layer,\n",
    "        of shape `(hidden_size)`\n",
    "    bias_hh_l[k]: the learnable hidden-hidden bias of the k-th layer,\n",
    "        of shape `(hidden_size)`\n",
    "\n",
    ".. note::\n",
    "    All the weights and biases are initialized from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})`\n",
    "    where :math:`k = \\frac{1}{\\text{hidden\\_size}}`\n",
    "\n",
    ".. include:: cudnn_persistent_rnn.rst\n",
    "\n",
    "Examples::\n",
    "\n",
    "    >>> rnn = nn.RNN(10, 20, 2)\n",
    "    >>> input = torch.randn(5, 3, 10)\n",
    "    >>> h0 = torch.randn(2, 3, 20)\n",
    "    >>> output, hn = rnn(input, h0)\n",
    "\"\"\"\n",
    "#nn.RNN(input_size, hidden_size, num_recurrent_layers, nonlinearity,)\n",
    "x = Variable(torch.randn(5,3,10))\n",
    "rnn = nn.RNN(10,20,2)\n",
    "h0 = Variable(torch.randn(2,3,20))\n",
    "out, hn = rnn(x, h0)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 20])\n"
     ]
    }
   ],
   "source": [
    "lstm = nn.LSTM(10,20,2)\n",
    "c0 = Variable(torch.randn(2,3,20))\n",
    "out, hn = lstm(x,(h0,c0))\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 20])\n"
     ]
    }
   ],
   "source": [
    "gru = nn.GRU(10,20,2)\n",
    "out,hnn = gru(x, h0)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 2])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "nn.Linear(in_features, out_features, bias=True)\n",
    "Docstring:     \n",
    "Applies a linear transformation to the incoming data: :math:`y = xA^T + b`\n",
    "\n",
    "Args:\n",
    "    in_features: size of each input sample\n",
    "    out_features: size of each output sample\n",
    "\"\"\"\n",
    "x = Variable(torch.randn(128,20))\n",
    "m = nn.Linear(20,2)\n",
    "print(m(x).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0000, -0.0000],\n",
       "        [-1.4435, -0.1157],\n",
       "        [ 0.0000, -2.5524],\n",
       "        [ 0.0000, -0.0000],\n",
       "        [ 2.6681, -1.1160]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#zeroes out some of the values in the input tensor\n",
    "m = nn.Dropout(p=0.5)\n",
    "input = Variable(torch.randn(5, 2))\n",
    "output = m(input)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.0281, -0.1043, -0.9801],\n",
       "         [ 0.0454,  1.2075, -0.5769],\n",
       "         [ 0.0454,  1.2075, -0.5769]],\n",
       "\n",
       "        [[ 0.7194,  1.8701, -0.5869],\n",
       "         [ 0.8274,  0.9918,  0.6741],\n",
       "         [-1.0281, -0.1043, -0.9801]]], grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the input is an integer that selects the embedding\n",
    "embedding = nn.Embedding(10,3)\n",
    "x = torch.tensor([[2,1,1],[3,5,2]], dtype = torch.long)\n",
    "embedding(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "input1 = Variable(torch.randn(100, 128))\n",
    "input2 = Variable(torch.randn(100, 128))\n",
    "cos = nn.CosineSimilarity()\n",
    "print(cos(input1,input2).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1297, grad_fn=<L1LossBackward>)\n"
     ]
    }
   ],
   "source": [
    "loss = nn.L1Loss()\n",
    "pred = Variable(torch.randn(1,10), requires_grad=True)\n",
    "target = Variable(torch.randn(1,10))\n",
    "print(loss(pred,target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.8602, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "loss = nn.MSELoss()\n",
    "print(loss(pred,target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.7376, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "target = Variable(torch.LongTensor(1).random_(5))\n",
    "target = Variable(torch.randint(5, (1,),dtype=torch.long))\n",
    "print(loss(pred,target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1021, -2.0721, -1.0736, -0.4213,  1.4890],\n",
       "        [-0.1656, -0.0502, -1.2592, -0.7588, -0.2377],\n",
       "        [ 0.2969,  0.1076,  0.6622,  0.1856, -0.0085]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.empty(3,5)\n",
    "nn.init.normal(w) #operates inplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
