<!DOCTYPE html>
<html>

<head>
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Autonomus Guitar Effects Activation Platform</title>

</head>

<body>
  
  <a src="./directory.html">NAVIGATION</a>
  <h1 align="center">Triggered Guitar Effects Platform</h1>
  <p>&nbsp;</p>
  <p>DTW Audio Sub Sequence Matching for Autonomus Audio Control Actions</p>
  <p>&nbsp;</p>
  <p>&nbsp;</p>

  <video tabindex="-1" class="video-stream html5-main-video" webkit-playsinline="" playsinline=""
    controlslist="nodownload" style="width: 383px; height: 215px; left: 0px; top: 36px;"
    src="https://r3---sn-ab5sznlk.c.drive.google.com/videoplayback?expire=1615855768&amp;ei=WMhPYKj6MIX4hgbrlpGYCg&amp;ip=173.70.97.51&amp;cp=QVRGV0lfVFdUSVhPOkc0NUVmYTkzanJhVnd2XzUzQ1JmR0RjbEtaZlhad0V5dVo2VXBENXRqazc&amp;id=687e1db58ddc11f3&amp;itag=18&amp;source=webdrive&amp;requiressl=yes&amp;mh=XG&amp;mm=32&amp;mn=sn-ab5sznlk&amp;ms=su&amp;mv=m&amp;mvi=3&amp;pl=17&amp;sc=yes&amp;ttl=transient&amp;susc=dr&amp;driveid=1xvDbJUrsZiOqP90orbz2YzFZ8HaGTQm_&amp;app=explorer&amp;mime=video/mp4&amp;vprv=1&amp;prv=1&amp;dur=30.789&amp;lmt=1512330408021036&amp;mt=1615840829&amp;sparams=expire,ei,ip,cp,id,itag,source,requiressl,ttl,susc,driveid,app,mime,vprv,prv,dur,lmt&amp;sig=AOq0QJ8wRgIhAIel-iFXlLdcQyUMLzx9uboZdMaIPrlyaD_TOxFu4a5SAiEAyHNc3Vis2LHwIgG-N4DI1TefKSduRfLMErKBL3gp4iM=&amp;lsparams=mh,mm,mn,ms,mv,mvi,pl,sc&amp;lsig=AG3C_xAwRgIhAJ24whyJyxmqvcye5IVbEsVVpqv906Yt78_DrRJC-tLlAiEAkU5MRkH9BLZifnlFqI6X4iPLDTaM70iiLbeQFpCzDQE=&amp;cpn=LayGSmmIdBXry8qO&amp;c=WEB_EMBEDDED_PLAYER&amp;cver=1.20210310.3.0"></video>



  <iframe src="SR Project II Presentation.pdf" height="1000px" width="100%" scrolling="yes" frameborder="yes"
    allowtransparency="true" allowfullscreen="true"
    sandbox="allow-forms allow-pointer-lock allow-popups allow-same-origin allow-scripts allow-modals"></iframe>
    
    
  <iframe src="Triggered Guitar Effects Platform Design Review.pdf" height="1000px" width="100%" scrolling="yes"
    frameborder="yes" allowtransparency="true" allowfullscreen="true"
    sandbox="allow-forms allow-pointer-lock allow-popups allow-same-origin allow-scripts allow-modals"></iframe>
  
  
  <iframe src="sudo apt-get install python-numpy" height="1000px" width="100%" scrolling="yes" frameborder="yes"
    allowtransparency="true" allowfullscreen="true"
    sandbox="allow-forms allow-pointer-lock allow-popups allow-same-origin allow-scripts allow-modals"></iframe>



  <h2>Team Members:</h2>>
    <h2>Bryan Guner</p>
      <h2>Haley Scott</p>
        <h2>Ralph Quinto</p>
          <p>&nbsp;</p>
          <p>Primary Advisor: Dr. Ambrose Adegbege</p>
          <p>May, 2018</p>
          <p>&nbsp;</p>
          <p>Acknowledgements</p>
          <p>
            The team would like to thank Dr. Ambrose Adegbege for his input and enthusiasm towards tackling our design
            challenges. We would also like thank Dr. Larry Pearlstein for his guidance and suggestion of Dynamic Time
            Warping.
            In addition, our team thanks Mihir Beg for his consultation on MIDI transcription and suggestion of Pure
            Data.
          </p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
          <hr>
          <h2>Abstract</h2>
          <p>
            <b> In live performance, guitar effect pedals are a versatile yet limiting asset. They require presence of
              mind on the
              part of the performer, and restrict the performer to the area of the stage in which the pedal board is
              located.
              These constraints limit the performance quality and stage presence by splitting the performers focus. This
              project
              proposes an automatic solution to the restrictions that guitar effect pedals present. The performer will
              record the
              primary performances into the proposed software, which will analyze and store the sequential frequencies.
              The
              performer will then utilize the software during a subsequent live performance, to trigger effects when
              preceding
              frequencies of the live performance are recognized against the first performance. This platform is
              realized through
              the use of Pure Data, a GUI (Graphical User Interface) for audio manipulation applications. Our team has
              designed an
              application that implements dynamic time warping (DTW) in order to compare the first performances against
              the live
              performance. The system compares MIDI data using the dynamic time warping distance threshold, opposed to
              the
              Euclidean distance threshold, making it a robust approach to mitigating live performance error.</b>
          </p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
          <p>
            <strong>Keywords: Pure Data, Dynamic Time Warping</strong>
          </p>
          <hr>
          <p>&nbsp;</p>
          <h1>Contents</h1>
          <p>Abstract........2</p>
          <p>Introduction......5</p>
          <p>Specifications...........7</p>
          <p>1.0 Chapter 1: Background......8</p>
          <p>1.1 How the Electric Guitar Works...........8</p>
          <p>1.2 How the Pedal Board Works...................8</p>
          <p>1.3 Guitar Signal Analysis............9</p>
          <p>1.4 Why Transcription Might Not Be Important............10</p>
          <p>2.0 Chapter 2: The Counting Method...12</p>
          <p>2.1 Concept.....12</p>
          <p>2.1.1 Primary Recording......12</p>
          <p>2.1.2 Primary Analysis.....13</p>
          <p>2.1.3 Live Performance........13</p>
          <p>2.1.4 Live Analysis.......13</p>
          <p>2.1.5 Method Expansion...14</p>
          <p>2.2 Pure Data Effects...........14</p>
          <p>2.2.1 Digital Effect Design in Pure Data..14</p>
          <p>2.2.2 Delay Effect in Pure Data........15</p>
          <p>2.2.3 Fuzz Effect in Pure Data..15</p>
          <p>2.2.4 Reverb Effect in Pure Data..........16</p>
          <p>2.2.5 Spectral Delay Effect in Pure Data..17</p>
          <p>3.0 Chapter 3: Dynamic Time Warping Method19</p>
          <p>3.1. Dynamic Time Warping19</p>
          <p>3.2 Why Dynamic Time Warping is a good choice for effects triggering...20</p>
          <p>4.0 Chapter 4: Pure Data and Method Implementation.22</p>
          <p>4.1 Introduction....22</p>
          <p>= 4.2 First Approach....22</p>
          <p>4.3 Python Implementation...23</p>
          <p>4.4 Pure Data Design.....23</p>
          <p>4.5 DTW Implementation of Java......26</p>
          <p>4.6 DTW in Pure Data............29</p>
          <p>5.0 Chapter 5: Testing and Validation Execution.........33</p>
          <p>5.1 Methods of Functionality Testing.........33</p>
          <p>5.2 Methods of Specification Testing.....35</p>
          <p>5.3 Realistic Constraints Testing....36</p>
          <p>6.0 Chapter 6: Conclusion....37</p>
          <p>6.1 Core Intent........37</p>
          <p>6.2 Results Achieved..37</p>
          <p>6.3 Expectations and Modifications.......38</p>
          <p>&nbsp;</p>
          <p>Appendices:</p>
          <p>Appendix A: Project Overview</p>
          <p>Appendix B: Project Management</p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
          <p>Nomenclature</p>
          <p>
            <strong>Primary performances</strong>
            : Guitar signal data recorded at home or in studio, before the live
            performance
          </p>
          <p>Introduction</p>
          <p>
            A musicians desire to deliver inspired live performances would derive great utility from automatic effect
            triggering. This concept will allow users to focus on their performance rather than the management of their
            sound
            effects. The value of the automatic triggering arises not only in convenience, but also in economic expense.
            Guitar
            effect pedals are far more costly than digital effects, as there are significantly less points of failure in
            digital
            effects. This idea serves to minimize distractions and cost to the performer, while maximizing the
            experience of
            live performance for the audience. This task will be achieved through the methods of dynamic time warping,
            and
            frequency counting.
          </p>
          <p>
            Dynamic time warping provides a stronger solution for the issue of performance error. This algorithm uses a
            comparison method to find the most optimal correlation between live performance and pre-recorded
            performance. Here,
            the performer would record four primary performances. The dynamic time warping algorithm is applied using
            the first
            performance against each subsequent performance, producing a sum of distances between these three sets of
            recordings. This sum is then padded with a tolerance, and used to compare with the sum of distances between
            the
            fifth (live) performance and the first primary performance. This method is applied to smaller sections of
            the
            performance, providing the knowledge of when to trigger the desired effect. The implementation of this
            algorithm
            proves to be highly tolerant to error, but fairly complex.
          </p>
          <p>
            The alternate approach is the implementation of a frequency counting algorithm. Here, the user will only
            record one
            primary performance. This performance will be used to create a sequence of frequencies, with a given
            tolerance. The
            number of changes in frequency are counted and stored. The frequencies from the live performance are then
            verified
            against the pre-recorded frequencies. The number of changes in frequency are stored and checked against the
            pre-recorded sum of changes. Once the separate sums from each performance are equal, the effect will be
            triggered.
            This method proves to be extremely straightforward, yet offers few solutions to the problem of live
            performance
            error.
          </p>
          <p>
            Throughout this report, our team presents the methods instated in our current project, as well as the next
            steps in
            the design and modification process. A more in-depth description of the two aforementioned methods is given,
            including both the pros and cons of each.
          </p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
          <p>Specifications</p>
          <p>
            The project was designed to make integration as seamless as possible with current guitar setups. Minimizing
            the
            delay between the performance and effect triggering is crucial so that musicians are not thrown off by the
            offset.
            Based on the research that our team has completed, the threshold of our system was set to have a maximum
            trigger
            latency of 1 second. Anything longer would be too disruptive to the performance. Another crucial
            specification is
            having a sampling rate twice as large as the fundamental frequencies of the guitar. For electric guitars,
            frequencies range from 80 Hz to nearly 400Hz. The software utilized in this project has a default sampling
            rate of
            44,100 Hz, which is more than enough to satisfy the Nyquist criteria. In addition, having many guitar
            effects offers
            great versatility to a performance. The group has set a goal to implement three different guitar effects
            along with
            the completion of our system.
          </p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
          <p>1.0 Chapter 1: Background</p>
          <p>1.1 How The Electric Guitar Works</p>
          <p>
            An electric guitar is a stringed instrument that uses a device called a pickup to electrify and subsequently
            amplify the guitar signal. The majority of guitar pickups are permanent magnets wrapped with a coil of
            insulated
            wire. This means the pickup in most cases is a passive element that generates a voltage via electromagnetic
            induction. Most pickups have greater sensitivity to higher frequency notes. This is because with higher
            frequency
            comes higher string velocity, which is in proportion with the output of the pickup. An engineer who is not
            musically
            inclined can think of the pickup as a transducer functioning as an inductor.
          </p>
          <p>1.2 How The Pedal Board Works</p>
          <p>
            A pedal board is usually comprised of a power source and a mechanical housing for what are called stomp
            boxes. Also
            known as effect pedals, stompboxes are activated by the guitarist manually during a performance and proceed
            to alter
            the content of the guitar signal in some form. Some may be as simple as an EQ sweep that produce the famous
            wah tone
            popularized by artists such as Jimi Hendrix and Slash, while other effects like delays and harmonizers are
            more
            complex and contain multiple internal stages of effect processing. A guitarists pedal board usually houses
            anywhere
            from three to twenty effects pedals, and can contain tens of thousands of dollars worth of gear.
            Conventionally, the
            guitar is run through the effects pedals and then into an amplifier, however higher quality amplifiers may
            provide
            an effects loop that allows for different configurations of pre and post effect amplification. While this
            method is
            effective enough to be the go to setup for practically all gigging guitarists, there are some fundamental
            limitations to this configuration. The pedal board is usually power hungry, expensive, and stationary.
          </p>
          <p>1.3 Guitar Signal Analysis</p>
          <p>
            In order to accurately trigger effects based on an audio signal, one must accurately catalog the content of
            said
            signal. There are many approaches used in the analysis of guitar signals, but in order to make sense of
            them, first
            one must understand what is is they are measuring. A musical signal can be broken into different musical
            feature
            representations. To simplify, one can assume there are only four features contained in any signal. The
            guitar signal
            will contain dynamic features, that is, the volume of different notes and sections of the music in relation
            to the
            others. It will also contain pitch information, which reveals the frequency or the notes being played at any
            given
            time. Further, one may examine the timbre, which relates to the variation from ideal integer multiples of
            the
            fundamental frequency that the harmonics of the note occupy, as well as the energy contained within them.
            Finally,
            one may record the tempo or speed that the performance and subsections of it were played at. There are
            countless
            analysis techniques for each musical feature and various schemes to combine and compare them. Below, we will
            describe a few of the more robust analyses, however, note that our current approach uses a Pure Data object
            named
            Fiddle that roughly approximates the guitar signal into MIDI data which only records pitch and tempo. In
            terms of
            dynamics, one may take the mean squared amplitude of segments of a sound file. Alternatively, one may try to
            remove
            the issue of variable note amplitude entirely by classifying chords in order to mask out the notes
            hypothesized to
            be in a given sound segment by a chord template bit mask. In terms of pitch, there are nearly countless
            algorithms
            because this is the most important feature to accurately transcribe music. Almost all of these approaches
            fall into
            either time domain analysis (which are usually some variation of autocorrelation) or frequency domain
            analysis
            (which is often performed on the results of a FFT (Fast Fourier Transform)). Some notable variations are
            SNAC
            Autocorrelation, (utilized by the Pd object helmholtz) or Chroma-vector or pitch class profile transcription
            (bit
            mask approximations of the performance based on predefined FFT spectrum content of various chords) or
            Cepstrum
            (which is the magnitude spectrum of the log of the magnitude spectrum of a window of the audio signal which
            can be
            used to determine the frequency of its peaks). Timbre has analysis techniques similar to Spectral Centroid,
            however,
            it does not matter much in the context of transcription because the only information it may extrapolate is
            what
            instrument the piece was played on. In terms of tempo, the most promising approach to accurate transcription
            is the
            separation of the signal into transient and steady state sections.The transient sections would then signify
            note
            onset and therefore yield tempo. This separation would be performed by looking at the variance of phase
            information
            extrapolated from the frequency bins of the signals wavelet transformation in relation to the previous few
            bins.
            While the approaches here are only a small fraction of all material on the subject, it turns out that effect
            triggering does not require accurate transcription of the audio file but rather consistent recording and
            comparison
            from one performance to another.
          </p>
          <p>1.4 Why Transcription Might Not Be That Important</p>
          <p>
            Preliminary research on this project focused on accurate transcription techniques that could be used to
            create a
            profile for each song that was so accurate that subsequent performances could be compared within certain
            tolerances
            on a nearly note-for-note basis. Eventually, it became apparent that this methodology was fraught with
            pitfalls. The
            most obvious is that these analysis techniques are complex and computationally expensive. The next challenge
            was
            that even if the features could be accurately extrapolated, how could they be combined in real time for a
            comparison? It became apparent that most techniques did not account for large differences in tempo between
            performances or even moments of silence in the guitar signal. While solutions for the integration of some of
            these
            techniques were available or even obvious, it appeared that there would be many challenges to overcome.
            Further,
            even if accurate transcription were achievable, would the comparison from one performance to another be
            reliable
            with the introduction of human error? Taking into account all of the following hurdles, the most economic
            approach
            would be to focus on the comparison of two recordings rather than deciphering the information contained
            within them.
            This mentality on effect triggering has proven to be not only immeasurably more efficient, but also more
            robust. The
            efficiency is gained through the simplistic spectral analysis employed, and the obsolescence of combining
            different
            analyses. The strength of this approach is gained in the fact that focusing on a comparison technique allows
            for
            much more variance in the timing of the performances of a given song. Further, if transcription-centric
            effect
            triggering was at the forefront of consideration, a comparison technique would still be necessary, and so
            focusing
            on comparison first allows for redesign and reconsideration later on. The only consideration this
            methodology is
            hinging upon is that less precise transcription techniques are consistently misrepresenting the information
            in the
            audio signal the same way every time.
          </p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
          <p>2.0 Chapter 2: The Counting Method</p>
          <p>2.1 Concept</p>
          <p>
            The initial material researched by each team member contributed greatly to the original concepts of the
            design
            plan. The team studied various topics that relate to this project, including speech processing techniques,
            gesture
            recognition techniques, and audio transcription techniques. This material allowed our team to define the
            design
            requirements and functionalities of our proposed system. The concept involves a pre-recorded performance,
            which is
            to be compared to the live performance. Through the user interface, the performer will mark the first on
            trigger
            point, and subsequently the first off trigger point for the effect. With the knowledge of which part of the
            song the
            performer is playing, the device will be able to trigger effects automatically during the live performance.
          </p>
          <p>2.1.1 Primary Recording</p>
          <p>
            In order to compare a live performance, the device would need to be able to accurately count and threshold a
            pre-recorded performance. Our team proceeded by developing an algorithm to accurately and precisely map the
            pre-recorded performance. After completing research on windowing and frequency bins, we agreed that a
            straightforward approach would be applied. The guitar signal would enter the computer as a bit stream, and
            would be
            analyzed using a windowed Fast Fourier Transform (FFT). This data describes the song in a sequential
            frequency
            representation. Essentially, this information defines the song in terms of the notes being played, as each
            note
            represents a unique frequency.
          </p>
          <p>&nbsp;</p>
          <p>2.1.2 Primary Analysis</p>
          <p>
            In order to make sense of this recorded performance map, our team conceived the idea of an algorithm to
            recognize
            the change in frequencies, and record them. The system would only register a change in frequency should the
            change
            exceed the instated tolerance. The system would record the first value that exceeds this tolerance,
            subsequently
            producing a list of notes in the order they are played. The user would manually select the first on trigger
            point by
            entering the numeric value of how many notes preceed the trigger point. This system would trigger an effect
            if and
            only if the number of the specified note entered by the user is equal to the number of notes recognized in
            the live
            performance.
          </p>
          <p>2.1.3 Live Recording</p>
          <p>
            The live performance presents an interesting obstacle for this implementation. Not only do the exact number
            of
            notes need to be monitored, but also the accuracy of the notes. Here, the performer would play the same song
            that
            was pre-recorded. The notes would again enter into the computer as a bit steam, and would be analyzed in a
            similar
            manner as the primary recording. Here, the frequencies are sequentially recorded every time a change greater
            than
            the previous notes tolerance occurs.
          </p>
          <p>2.1.4 Primary and Live Comparison</p>
          <p>
            The analysis of the live performance involves the comparison of the two recordings. If the initial live
            performance
            frequency matches the initial recorded frequency within the given tolerance, a 1, or bang will be recorded.
            This
            pattern continues, marking a 1 or bang every time a frequency outputs a match. These 1s recorded from the
            live
            performance are compared to the sum of the number of frequencies before the trigger point marked by the
            user. When
            these two numbers are equal, the effect will trigger.
          </p>
          <p>2.1.5 Method Expansion</p>
          <p>
            This process can be expanded to account for the off trigger points, as well as multiple effects throughout
            the
            song. The same concept would be used to mark different points in the primary recording, instead of simply
            the
            initial on trigger. The main drawback of this method is the lack of tolerance to error. This problem could
            be
            addressed with a simple solution, one would first need to modify the Pd patch to have subpatches for all 12
            tempered
            scale notes instead of just one of them. If one note is missed, but the next three are correct, the system
            will fill
            in a 1 or bang in place of the missed note.
          </p>
          <p>2.2 Pure Data Effects</p>
          <p>
            Pure Data (Pd) is the software platform our team utilized to design a simplified counting method described
            in
            section 2.1. Pd is a visual programming language and environment for creating interactive computer and
            multimedia
            works. Its most promising attributes are its visual simplicity and its abilities to process audio in real
            time.
          </p>
          <p>2.2.1 Digital Effect Design in Pure Data</p>
          <p>
            The visual interface provided by pure data makes the creation of digital effects relatively simple. Basic
            effects
            can be designed solely through the use of object blocks. Object blocks can contain various controls, such as
            ADC,
            DAC, read signal, write signal, or even simple numeric inputs. Using these controls, our team created three
            different digital effects.
          </p>
          <p>2.2.2 Delay Effect in Pure Data</p>
          <p>
            Our team designed a guitar delay effect to play back the delayed signal into the recording. This effect
            creates the
            sound of a repeating, decaying echo. First, the guitar signal enters an ADC object, and continues to a delay
            write
            block which allocates memory for a delay line and writes the guitar signal into it. The signal is then
            attenuated by
            a factor of .6 in order to create the delayed sound. Next, the signal is read from the delay line using a
            delay read
            block. Finally, the delayed guitar signal passes through a DAC object, which allows for the production of
            the audio
            output.
          </p>
          <p>
            <img width="334" height="214" src="Final%20Report%20SP2_files/image002.gif" alt="image002">
          </p>
          <p>
            <i>Figure 1: Delay Effect Pd</i>
          </p>
          <p>2.2.3 Fuzz Effect in Pure Data</p>
          <p>
            Our team designed a guitar fuzz effect to implement a distortion effect on the guitar signal. This effect
            creates
            the sound of a more processed or artificial guitar. Here, the guitar signal is passed through an ADC object,
            and
            continues on to a gain to be multiplied by a factor of 40. Next, the signal is passed through a clip object,
            which
            restricts the signal to lie between two limits, -0.5 and .05. The signal is finally converted back to an
            analog
            signal through the DAC object.
          </p>
          <p>
            <h3>Demonstrated here!</h3>
            <iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/krRVGoK9NcA" frameborder="0"
              allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
              allowfullscreen></iframe>
            <img width="344" height="184" src="Final%20Report%20SP2_files/image003.gif" alt="image003">
          </p>
          <p>
            <i>Figure 2: Fuzz Effect Pd</i>
          </p>
          <p>2.2.4 Reverb Effect in Pure Data</p>
          <p>
            Our team designed a reverb guitar effect, which mirrors a large number of reflections of the signal to build
            up and
            then decay. The guitar signal is first sent through an ADC object, and subsequently sent to a freeverb~
            block which
            uses the Schroeder and Moorer model for reverb. The guitar signal is finally sent to both outputs of the DAC
            object,
            which allows for the production of the reverberated sound. There are many controls associated with the
            reverb that
            allow users to manipulate the sound of the effect. The roomsize block allows the user to slide from a range
            of 0 to
            1, creating a smaller or larger simulated room size. The damping block slides from 0 to 1, affecting the
            dampness of
            the objects within the simulated room. The wet to dry slider controls the amount of reverb applied to the
            dry, or
            untouched signal. The freeze toggle allows the user to grab the real time tail of the reverb and apply the
            sound
            continuously. The bypass toggle allows the user to turn the effect off, and pass through a completely dry
            guitar
            signal. These toggles serve as a convenient aid throughout the testing process.
          </p>
          <p>
            <img width="366" height="274" src="Final%20Report%20SP2_files/image004.gif" alt="image004">
          </p>
          <p>
            <i>Figure 3: Reverb Effect Pd</i>
          </p>
          <p>2.2.5 Spectral Delay Effect in Pure Data</p>
          <p>
            Our team designed a spectral delay effect to scatter the original guitar sound, allowing one to hear all the
            partials (harmonics) ringing at different times. This effect creates the sound of a repeated, echoed guitar
            signal.
            In this patch, the fft of the incoming guitar signal is calculated and used to cut the sound into very thin
            frequency bands. A different, user controlled delay is then applied to each of these bands before
            resynthesis. If
            the length of the delay lines vary greatly from one frequency band to another, the ringing effect of each
            harmonic
            becomes more apparent. Here, the guitar signal is passed through an ADC object, and continues on to a Pd
            block
            containing user controlled sliders. Each slider allows the user to specify the amount of delay, feedback,
            and gain
            instated. The user is also able to control the cutoff of the low pass filter applied, as well as how wet or
            dry the
            signal should be. Next, the signal is passed through an equal power crossfade object, which allows the
            overall
            volume to be maintained through the crossfade. The signal is finally converted back to an analog signal
            through the
            DAC object.
          </p>
          <p>
            <img width="406" height="315" src="Final%20Report%20SP2_files/image005.gif" alt="image005">
          </p>
          <p>
            <i>Figure 4: Spectral Delay Effect Pd</i>
          </p>
          <p>
            <i>&nbsp;</i>
          </p>
          <p>
            <i>&nbsp;</i>
          </p>
          <p>
            <i>&nbsp;</i>
          </p>
          <p>
            <i>&nbsp;</i>
          </p>
          <p>
            <i>&nbsp;</i>
          </p>
          <p>
            <i>&nbsp;</i>
          </p>
          <p>
            <i>&nbsp;</i>
          </p>
          <p>
            <i>&nbsp;</i>
          </p>
          <p>
            <i>&nbsp;</i>
          </p>
          <p>
            <i>&nbsp;</i>
          </p>
          <p>
            <i>&nbsp;</i>
          </p>
          <p>
            <i>&nbsp;</i>
          </p>
          <p>
            <i>&nbsp;</i>
          </p>
          <p>
            <i>&nbsp;</i>
          </p>
          <p>3.0 Chapter 3: Dynamic Time Warping</p>
          <p>
            3.1 Dynamic Time Warping (DTW) Dynamic Time Warping is an algorithm for the measurement of similarity
            between two
            temporal sequences, which may vary in speed. The algorithm calculates an optimal match between two given
            sequences
            in the form of a distance that is the sum of localized cost functions. The process can be thought of
            conceptually as
            arranging the two sequences on the sides of a grid. Each cell within the grid will be filled in with a
            distance
            measure comparing the corresponding elements of the two sequences. This measure can be just subtraction of
            one
            sequence from another, but more often each cell is computed by more symmetric measures like the square of
            the
            difference. In order to find the best path through the grid, we search for a path that minimizes the total
            distance
            between them. The procedure for finding an overall distance measure is to find all the possible routes
            through the
            grid and calculate the total distance for each. Note that because we are looking for a minimum length path,
            each
            routes total distance is the minimum of the sum of distances between individual elements on the path divided
            by the
            sum of the warping function. Most instances of the DTW algorithm share common optimizations. The most
            obvious is
            known as the monotonic condition, which simply stated is the rule that the path will not turn back on itself
            and
            therefore the indexes of the matrix must either remain the same or increase during each subsequent
            iteration.
            Further, examining the literal definition of a path, the elements selected must to some degree border each
            other,
            and so the indexes may only increase by 1 from each element of the path to the next. Another commonality in
            DTW
            algorithms is the boundary condition, which requires that the path must begin at the intersection of each
            sequences
            respective first elements and end on the intersection of each sequences respective last elements. Some other
            optimizations are common but not integral, for example, the adjustment window condition postulates
            optimizations to
            keep the path from wandering too far from a diagonal through the grid, which while sometimes a critical
            flaw,
            usually results in huge computational efficiency gains. Another such optimization is a slope constraint
            which
            ensures that particularly long sequences arent matched with short sequences, but this can result in
            inaccuracies if
            one of the signals was particularly dilated or contracted in time. Since this technique has been at the
            forefront of
            comparing temporal signals since the 1980s, the list of variations on the classic algorithm is extensive.
            3.2 Why
            Dynamic Time Warping is a Good Choice for Effect Triggering In the more simplistic counting approach
            employed, the
            guitarist is required to replicate the performance both faithfully in time and in accuracy. Small
            inaccuracies in
            either metric could easily cause the triggering scheme to miscount out of our predetermined range. DTW is a
            suitable
            alternative because it is relatively insensitive to time-scale contraction or dilation in either the
            database or
            query signals. Further, even if the performer makes numerous mistakes in the performance, as long as the
            section is
            the closest match to the database sequence the program will consider it a match. This robust algorithm can
            be proven
            time in and time out by any speech dictation software where the tolerance for difference between the two
            signals is
            astounding. Moreover, when considering different musical feature measures, the methods of comparison differ
            depending on the musical feature with some necessitating convoluted applications such as neural networks.
            Even more
            demanding is the need to combine different features in a useful way. Dynamic Time Warping works as an
            accurate
            comparison between features so long as they are structured in time (even if the information they convey is
            in
            frequency). In addition, because the features considered for a DTW algorithm are set in time, if one were to
            choose
            to track multiple features concurrently, (no longer necessary in the context of DTW) it would likely be
            simple to
            correlate detected matches between different features by a simple timing threshold. Following this train of
            thought,
            one could set the effects platform to trigger on or shortly after the occurrence of the secondary detection,
            allowing the system to virtually guarantee the absence of preemptive triggering. As if these arguments were
            not
            persuasive enough, another benefit of DTW is that if the system were to require multiple database
            performances, then
            section specific DTW-distance thresholds could be set for each part of a song as to ensure accuracy for
            multiple
            trigger events or different effects triggered on different instances of specific recurring parts of a song.
            Most
            importantly, because of the extensive resources already invested into the DTW algorithm, there is a wealth
            of
            optimization options and configurations that enable computationally efficient approaches to be selected
            based on the
            needs of a specific application.
          </p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
          <p>4.0 Chapter 4 Implementation</p>
          <p>
            4.1 Introduction When designing the system for the project, the group learned that there were many different
            methods to approach the problem. Hardware, software platforms, and analysis methods were components that had
            to be
            carefully chosen to meet the full demands of the system. When designing the structure for the project, the
            group
            went through many approaches before settling on the final architecture. The various criterion that needed to
            be met
            entailed challenges such as mobility, robustness, speed, and usability. 4.2 First Approach The first
            approach
            consisted of using a physical component that would offset and amplify the guitar signal, an external ADC,
            and a
            raspberry pi. The physical component was required because the signal of an electric guitar fell within the
            millivolt
            range, and the external ADC operated with a minimum of 1 volt. Signals coming to the electric guitar would
            be fed
            through the component and then onto the ADC. The raspberry pi would then read the discretized signal through
            a
            python program. When the system detects a trigger event, it would output a signal through the built in DAC
            and
            trigger a physical guitar pedal. This approach was dismissed due to the unnecessary use of a microcontroller
            and
            physical effect pedals. To perform signal analysis, it is important to use a CPU with a fast enough
            processing
            speed. Although the raspberry pi has one of the fastest processing speeds on the market, it still falls
            short to the
            speed a laptop can provide.
          </p>
          <p>
            4.3 Python Implementation For the next approach of the system, a laptop and a quarter-inch to USB adapter
            was to be
            used in lieu of the raspberry pi and external components. Python, due to the large number of available
            libraries,
            was chosen for this implementation. Numpy, Scipy, and Matplotlib, are mathematical libraries that allow
            Python to
            perform MATLAB like operations. To test the speed at which Python performed analysis on a live signal, a
            test module
            was created to read in input from a microphone. Using the aforementioned data science libraries, various
            audio
            analysis techniques were performed on the signal. The incoming signals were first stored in arrays of size
            4096
            samples. The data was then converted from bytes to integers so that operations could be performed on the
            signal. To
            visualize the operations, we plotted the live signal, the real time Fast Fourier transform, and the zero
            crossings
            on the same window. While running the program, the group noticed many issues, the first being the latency
            between
            the plots. This was to be expected due to the sequential nature of Python. Another pitfall to this approach
            was the
            low resolution of the signal. An approach to amend this issue was to increase the sample size. However, once
            the
            sample size was increased, there was an increased drop in the frames per second of the plot. All in all,
            while
            python was able to perform analysis on the signal, the team did not view this system to be an adequate
            approach. 4.4
            Pure Data Design Pure Data (pd) is an open source visual programming language designed for audio and music
            manipulations. It was first released in the mid 1990s by Miller Puckette with simple audio manipulation
            objects.
            Since then, many iterations of the program have released along with dozens of complex modules contributed by
            open
            source users. With its modular design, users can create their own pure data objects or externals with the
            programming language of their choice. Pure Data was chosen as the platform to build the system on because of
            the
            simple visualization of data flow, processing capabilities, as well as the large library of pure data
            objects.
          </p>
          <p>
            A block diagram of the groups first implementation can be seen on Figure 5 below. The approach for the basic
            system
            was to read signals coming from the quarter inch to USB adapter using the ADC object of Pd. It was decided
            that
            digital effects would be used in lieu of a physical guitar pedal as the costs were above the project budget.
            A low
            pass filter is applied to the signal because the fundamental frequencies of an electric guitar do not extend
            beyond
            400 Hz. The signal is then fed through the fiddle object. Fiddle converts the pitch of the audio signal to
            MIDI.
            This is a useful feature as it allows the ease use of mathematical operations. Using comparator operators,
            the
            system can count the instances of a specific note and trigger an effect once it reaches a predefined
            threshold. In
            testing the program, Mary Had a Little Lamb was tested as it does not contain any complex chords. The MIDI
            value of
            76 was verified with comparators. A counter was built and attached to count the number of times the
            comparators
            returned a true statement. Once the count had reached a value of 12, the delay effect was triggered. This
            was
            accomplished by using the moses object. Moses acts like an if else statement. If the incoming value is below
            the
            threshold, it sends a trigger to the left, or dry output. When the value is greater than or equal to the
            threshold,
            it sends a trigger to the right, or effect output. In the design, when the value is below the threshold, the
            input
            goes straight to the DAC. When the trigger conditions are met, the signal is first fed through the delay
            effect
            before the signal is passed through the DAC. Upon testing our system with Mary Had a Little Lamb, we were
            able to
            successfully trigger the guitar effect.
            <img width="626" height="240" src="Final%20Report%20SP2_files/image006.jpg" alt="image006">
          </p>
          <p>
            <i>Figure 6: Block Diagram of Basic Trigger PD Patch</i>
          </p>
          <p>
            After evaluating the test results, the group noticed several issues with the implementation. The first of
            which was
            that the system was sensitive to performance speed and articulation. When the the user articulated a note
            for too
            long, the counter block would continue to count up even though the note was played only once. This lead to
            inconsistencies in count accuracy. In testing our system, the group found that the system would trigger at
            the
            correct timing 60% of the time. One of the goals of this project was that the system should handle up to 10
            note
            onsets per second. Currently, the system is capable of handling up to 10 notes albeit there are
            inconsistencies due
            to sensitivity issues. To resolve this issue, the group plans on narrowing the range of MIDI values to check
            for.
            Another issue with this implementation is that similar songs may trigger an effect configured for a specific
            song.
            For example, if the program is configured for Mary Had a Little Lamb, playing London Bridge is Falling Down
            may
            trigger the system. This is due to the fact that London Bridge is Falling Down contains many of the same
            notes as
            Mary Had a Little Lamb. One final issue is that this system is geared towards handling 1 note at a time as
            opposed
            to chords. The reason for this is that the fiddle object looks at the highest peak when looking at the FFT
            of the
            signal. When fiddle reads in a chord, it finds the highest peak of the signal in the frequency domain and
            uses that
            point to convert to MIDI. The group decided to resolve these issues with the implementation of Dynamic Time
            Warping.
          </p>
          <p>4.5 Dynamic Time Warping Implementation</p>
          <p>
            In order to gain a better understanding of Dynamic Time Warping, the group created its own implementation of
            DTW
            based on a source found in the research phase. The way the proposed system works is that the system takes in
            the
            points of stored signal and places them on the leftmost column. The points of the incoming signal being
            compared to
            are then placed on the bottom most row. A matrix is then generated based on the symmetrical distance of the
            2
            signals. The symmetrical distance is the difference squared of the points of the two signals. An example can
            be seen
            in Figure 6 below.
          </p>
          <p>
            <img width="423" height="274" src="Final%20Report%20SP2_files/image007.gif" alt="image007">
          </p>
          <p>
            <i>Figure 7: Dynamic Time Warping</i>
          </p>
          <p>
            For each cell, the cost of arriving at the cell from the bottom, left, and bottom-left is calculated. On the
            point
            (2,2) of Figure 7 below, it costs 2 units to arrive from the bottom cell because the bottom cells lowest
            value plus
            the current cell value is 2. It costs 1 to arrive from the left because 2 + 0 = 2. It costs 1 to arrive from
            the
            bottom left because 1 + ()*0 = 1. After calculating the costs for each cell, the least cost path can be
            determined.
            To find the least cost path, one must make three assumptions. The first is that the path always begins at
            point
            (1,1) and end at the upper right most cell. Secondly, it is assumed that the least cost path should lie
            along the
            diagonal of the matrix, so diagonal movement should be favored over lateral movement. The group handled this
            in the
            implementation by reducing the cost of diagonal movement by 50%. Finally, the third assumption is that
            because time
            moves forward, one should never move backwards to find the least cost path. Calculating the least cost path
            involves
            starting at the upper right most cell and working backwards to the starting cell. The path chosen should be
            the cell
            with the lowest cost of arrival.
          </p>
          <p>
            <i>
              <img width="624" height="145" src="Final%20Report%20SP2_files/image008.gif" alt="image008">
            </i>
          </p>
          <p>
            <i>Figure 8: Cost Arrival Per Cell</i>
          </p>
          <p>
            The java implementation of this approach and the corresponding code can be seen in the appendix below.
            Figure 8
            below displays the two example test cases that were processed into the system and tested.
          </p>
          <p>
            <img width="614" height="226" src="Final%20Report%20SP2_files/image009.gif" alt="image009">
          </p>
          <p>&nbsp;</p>
          <p>
            <i>Figure 9: Signals Tested for DTW Implementation</i>
          </p>
          <p>
            The first scenario tested involved two identical signals being compared against each other. Since the points
            being
            checked are exactly the same, a least cost path of zero can be expected. The second test scenario involved
            two
            different signals of the same length. This test case should result in a non-zero value. Manually calculating
            the
            least cost path of this test case, the group determined a least cost path value of 5. After running the
            program, the
            system printed the results shown in Figure 9 below.
          </p>
          <p>
            <img width="282" height="51" src="Final%20Report%20SP2_files/image010.gif" alt="image010">
          </p>
          <p>
            <i>Figure 10: Java Implementation Results</i>
          </p>
          <p>
            Comparing the actual results with the expected, it can be seen that the group was successful in the
            implementation
            of dynamic time warping.
          </p>
          <p>&nbsp;</p>
          <p>4.6 DTW in Pure Data</p>
          <p>
            Since Pure Data does not have a dynamic time warping pure data object, the group had to create its own. The
            tools
            needed to accomplish this task was CodeBlocks (IDE) and the pure data source code. C was the programming
            language of
            choice as it was the industry standard. The basis algorithm for the system would consist of a learning phase
            and a
            live phase. In the learning phase, the user would feed sub signals of a song and the system would calculate
            the
            dynamic time warping least cost path between the first sub signal against all other sub signals. In the live
            phase,
            the system would listen to an incoming signal, fiddle midi data, and perform dynamic time warping on the
            live
            against one of the recorded signals. Figure 10 below displays the pd patch created in order to record and
            store sub
            signals.
          </p>
          <p>
            <img width="626" height="416" src="Final%20Report%20SP2_files/image011.gif" alt="image011">
          </p>
          <p>
            <i>Figure 11: PD Patch to Save Sub Signal Recordings</i>
          </p>
          <p>
            The first step was to include the pd header file into our CodeBlocks project file. A struct was generated as
            it
            served as the object instance of our external. We defined three inlets, A bang and 2 float inlets. The bang
            inlets
            purpose was to calculate the least cost path of the signal in the recording phase. The first float inlets
            purpose is
            to receive the incoming signal from the adc object. Pure Data has a sample rate of 44,100Hz and the fiddle
            object
            produces a midi value based on the most recent 1024 samples. Effectively, our object should be able to read
            in a
            value every 22ms. The second float inlets purpose is to receive the float value that defines delay
            triggering time.
            An outlet was also defined so that it would send out a bang when a match between the signal works.
          </p>
          <p>
            The first phase of our system is the learning phase. When the bang inlet is pressed, the system reads in 4
            recorded
            signal data files from the path of the project. Input 1 was defined as the reference signal, meaning it is
            the input
            that will be used to compare all other signals. The system was set so that it could handle data of size 300
            samples.
            Calculating the dynamic time warping least cost path, follows a similar approach as to the groups java
            implementation. The only main difference is that it cannot compare signals of different sizes. Once the
            least cost
            path has been calculated 3 times between input 1 and the other recorded signals, the average least cost path
            is
            calculated. This will serve as the threshold to compare the incoming signal to.
          </p>
          <p>
            During the live phase of the system, the incoming signal is read through the first float inlet. When an
            input is
            detected, the incoming float value, is stored in a temp array. The system then checks if the array is filled
            with
            values. If it is not filled, the system changes the index and waits for another float input value. If it is
            filled,
            the system performs dynamic time warping against the signal stored in the temp array and input 1. Should the
            least
            cost path be equal or less to the average least cost path, the system outputs a bang signaling a match. That
            would
            then in turn trigger the guitar effect. If the lcp value is not less than or equal to the avg lcp value,
            then the
            system waits for another input. When the input is received, the temp array shifts all of its value so that
            its
            oldest value is removed and new value is stored. The new temp array is then once again compared against the
            stored
            signal. This process repeats until a match is detected or if the user exits the program.
          </p>
          <p>
            The completed pure data object can be seen in Figure 12 below. In order to test the system, the group
            created a
            pure data patch that would activate the reverb effect when a signal match was detected. Figure 13 below
            displays the
            actual patch used for testing. The group found that the system would trigger very precisely when individual
            notes.
            To verify that the group met the original specification of less than 1 second latency, a timer was added to
            the
            program to record and print the time (seconds) it took to perform dynamic time warping. It was observed that
            the
            actual calculation only took 1 - 2 milliseconds. When chords were used to test the system, the triggering
            produced
            very inconsistent results. In order to alleviate this issue, the threshold was changed so that the effect
            would be
            played if the calculated least cost path was less than or within plus five percent of the original
            threshold.
            Through these testings, the group was able to fine tune the object until results met the groups
            satisfaction.
          </p>
          <p>
            <img width="107" height="54" src="Final%20Report%20SP2_files/image012.gif" alt="image012">
          </p>
          <p>
            <i>Figure 12: Generated Dynamic Time Warping PD Object</i>
          </p>
          <p>
            <i>&nbsp;</i>
          </p>
          <p>
            <i>
              <img width="577" height="305" src="Final%20Report%20SP2_files/image013.gif" alt="image013">
            </i>
          </p>
          <p>
            <i>Figure 12: PD Patch to test dynamicTW object</i>
          </p>
          <p>5.0 Chapter 5: Testing and Validation Execution</p>
          <p>
            <i>&nbsp;</i>
          </p>
          <p>5.1 Methods of Functionality Testing</p>
          <p>
            When the group first started working on this project, the team laid out project goals to accomplish by the
            end of
            the second semester of senior year. The team wanted to develop a software platform to analyze a sequence of
            note
            when instructed. The system should trigger on a designated instance that occurs multiple times throughout a
            song.
            Latency should also be minimized to 1 sec as to not disrupt the performer. In addition, the system must
            process
            sequences up to 10 note onsets per second.
          </p>
          <p>
            In order to validate that the group was successful in creating a software platform that would analyze a
            sequence of
            notes and trigger guitar effects when instructed, the developed a variety of tests. The plan was to feed in
            different types of guitar subsequences. These include sequences of single notes and sequences of chords. The
            tests
            would be deemed successful if the system is able to trigger guitar effect after the sequence instance is
            played.
          </p>
          <p>
            The group also needed to test if the system could trigger on a designated instance rather than just at the
            first
            instance. The plan to test this was to use a subsequence that would be played multiple time throughout a
            song.
            Verifying the latency between signal detection and triggering was trivial. The group used the C library
            time.h in
            order to record the system clock time just before the dynamic time warping function is called and once again
            after
            the triggering occurs. Taking the difference between the two recordings would result in the total latency of
            signal
            detection and latency. Determining if the system is able to handle 10 note onset per second was also simple.
            The
            group would take the sample rate of pd, which was 44,100, and divide it by the number of samples fiddle
            takes in.
          </p>
          <p>
            The first sequence tested was a riff, which is essentially a sequence consisting of single notes. The
            sequence was
            from
            <i>Superstition</i>
            by Stevie Wonder. First the team recorded four sequences of the riff, and the average dtw
            least cost path is then calculated between the first recorded signal and the other three signals. The
            average dtw
            least cost path is then set as the threshold of the system. The dynamicTW object then listened to the
            incoming
            guitar signal. Once enough data had been received, the system began calculating the least cost path of the
            incoming
            signal againsts signal one of the recorded signals. Bryan, the performer for this test, played the specified
            riff.
            It was apparent that the system triggered the guitar effect just as the riff sequence had finished being
            played.
            This proved successful functionality of our system for sequences with one note occuring at a time.
          </p>
          <p>
            The next sequence tested contained chords. The same process as the riff was used in order to validate the
            system.
            On the first playthrough of the sequence, the system was not able to detect the chord sequence. Observing
            the
            console output of the system, it was noted that the calculated dtw least cost path value of the live
            sequence came
            very close to within ten percent of the threshold set by system. The group tried once again to test the
            chord
            sequence, but on this test instance Bryan, played at a slightly slower rate and the system was able to
            detect the
            chord sequence. It was observed that the system is more sensitive to chords and the performer needs to play
            more
            consistently and be in line with the performance of the recorded sequences.This sensitivity to the
            performers attack
            on the guitar strings can be mitigated by a more consistent performance by the performer.
          </p>
          <p>5.2 Methods of Specification Testing</p>
          <p>
            To validate if the system could handle triggering effect at a designated instance, the group chose to use
            the song
            <i>Superstition</i>
            because it contained sequences that occured frequently. Repeating the process of testing as the
            chord and riff sequence, the group found that the system was not able to trigger on the designated instance.
            The
            system was only able to detect the sequence at the first instance, rather than at the designated instance.
            The
            reason for this was because the system was not built to handle this feature. The group, for the majority of
            the
            semester, was heavily involved in getting the detection of the sequence to function. Once the group
            accomplished
            this task, the team attempted to incorporate this feature into the project but ultimately due to time
            constraints,
            the feature was not incorporated.
          </p>
          <p>
            As previously mentioned, determining the latency was trivial with the use of the time.h library. To
            reiterate, the
            group recorded the system clock right before the dynamic time warping function was called and once again
            after the
            triggering of the effect occurred. The difference between the two signals, should result in the latency of
            signal
            detection and triggering. The latency was outputted to console and it was observed that the latency was
            between .001
            to .002 seconds which was far below the project specification. To verify the 10 note onset per second
            specification,
            we utilized the pure data sampling frequency and divided it by the number of samples required by fiddle,
            which was
            1024. This results in a value of approximately 43-44 notes played per second.
          </p>
          <p>5.3 Realistic Constraints Testing</p>
          <p>
            In order for the system to be marketable, none of the effects we create can be allowed to amplify a signal
            to
            amplitudes that might be hazardous to the amplification circuitry. It is for this reason that for example,
            in our
            Fuzz effect, the bounds of the clip are very tight. Another constraint is the volume of the output, which is
            desired
            to be between 20 dB and 65 dB however this is a constraint on the amplification rather than the triggering
            platform.
            Further, our system requires a computer running a windows operating system, limiting the situations in which
            it can
            be utilized. Another constraint is the systems current inability to interface with analog guitar pedals in
            the
            current state of development. This platform is constrained by the trigger latency of 2ms and the minimum
            note onset
            separation which is 43 notes per second, both of which are well within the workable range that our team
            established
            at the onset of this project. These constraints are based on the assumption of a computer with more than
            ample
            processing speed which may become a constraint if a user computer does not have adequate processing power.
            Finally,
            the system is constrained by a tradeoff between query sequence length and computational speed, all of the
            parameters
            provided above are based on the assumption of three second long trigger sequences and windows of 300 feature
            samples
            of the live input shifted by one feature sample per iteration.
          </p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
          <p>6.0 Chapter 6: Conclusion</p>
          <p>6.1 Core Intent</p>
          <p>
            This project serves to automate the process of guitar effect triggering. In order to simplify tasks for the
            performer, our device records the effect trigger points, and executes the procedure with no manual
            interjection. The
            design streamlines the duties of the performer, and creates a more interactive experience for any potential
            audience. Our teams current model successfully achieves the task of automatic on triggering. The methodology
            involves the DTW process defined in Chapter 3.3.
          </p>
          <p>&nbsp;</p>
          <p>6.2 Results Achieved</p>
          <p>
            This semester, the team generated tangible results such as a functional prototype of the final design, as
            well as
            the creation of pure data digital effects. Before settling on the final architecture, there were several
            architectures that were tested. The initial approach of the system called for the use of the Raspberry Pi
            and an
            external guitar pedal. This approach was quickly dismissed as the processing speed of the raspberry pi was
            insufficient. Furthermore, the physical guitar pedals that contained the required interface were beyond the
            project
            budget. Realizing these drawbacks, the team replaced the raspberry pi with a laptop, and opted to use
            digital
            effects over physical effects. This iteration called for the use of Python and several external libraries.
            Python is
            capable of handling various digital signal processing techniques, but the data resolution is insufficient.
            The
            current iteration of the system called for the use Pure Data in lieu of Python. A complex prototype of the
            system
            was generated and tested. Single notes can be read using the fiddle object of Pure Data. Using various
            comparators,
            the team was able to set a trigger to activate an effect if all conditions were met. The song Superstition
            by Stevie
            Wonder was tested for the current implementation of the system. Calculating three DTW distances, finding the
            average
            of the three, and padding this average with a tolerance gave the ability to reliably match the live
            performance to
            the primary performance.Through the testing and project demonstration phases, it is shown that the
            implementation is
            fully functional.
          </p>
          <p>6.3 Possible Modifications (changed from expectations and modifications)</p>
          <p>
            The obstacle of developing a software platform that digitizes the guitar signal, analyzes a sequence of
            notes
            played in time and triggers guitar effects as intended has been overcome. It is important to note, however,
            that the
            current platform is programmed to trigger at the first instance of a calculated match.
          </p>
          <p>
            Due to the prohibitive cost of effects pedals, Pure Data serves as a cost effective alternative to
            preprogram a
            sequence of effects to a pre-recorded guitar signal without the use of a stomp box. Future implementations
            could
            involve a physical guitar pedal effect, where the effects are integrated seamlessly into the system. This
            addition
            could include the ability to control the volume level of different performers in relation both to each other
            and the
            current section of a song.
          </p>
          <p>
            The most promising approach to the aforementioned pitfalls is a technique known as subsequence dynamic time
            warping. For the purposes of signal comparison between performances, the sequences to be compared may have a
            significant difference in length. Instead of aligning these sequences globally, it is imperative to find a
            subsequence within the longer sequence that matches the shorter sequence. For example, assuming that the
            longer
            sequence represents a database to be searched and the shorter sequence an incoming performance, our
            objective is to
            identify the subsequence within the database that is most similar to the incoming signal. Influenced by the
            work of
            [21] (Muller, M), an algorithm for match detection can be reverse engineered from the subsequence list
            generator. It
            is presented below in a combination of mathematical notation and algorithmic pseudocode.
          </p>
          <p>&nbsp;</p>
          <p>
            Let X = (x1,x2,...,xN) and Y = (y1,y2,...,yM) be midi sequences from the Pure Data Fiddle object, where
            M&gt;&gt;N(this means that Y is the database sequence).Next, a local cost function c is assigned to each
            element of
            the DTW grid. At this point the algorithm must find a subsequence Y(a : b) := (ya,ya+1,...,yb) that
            minimizes
            the DTWdistance to our incoming signal over all possible subsequences of the recorded feature sequence.
          </p>
          <p>Algorithmically speaking that is:</p>
          <p>(a* ,b* ):= argmin (DTW (X,Y(a:b) )</p>
          <p>
            The indices a and b in addition to the least cost alignment possible between the incoming signal and the
            subsection Y (a : b) of the stored performance can be computed by a modification of the standard DTW
            algorithm.
          </p>
          <p>
            In order to select a path of least resistance p, naturally one would have to calculate every conceivable
            path
            through the grid. Unfortunately this requires computational complexity that grows exponentially in bounds N
            and M.
            This process can be optimized to an O(NM) complexity computation. In a broad sense, the concept is to
            penalize paths
            between the database and the query that match the query to indices near the beginning or end of the database
            as to
            avoid a one to one match between signals.
          </p>
          <p>Algorithm: (Accumulated cost matrix and DTW-distance)</p>
          <p>Instantiate sequences: X(1:n) = (x1,...xn) and Y (1:m) = (y1,...ym)</p>
          <p>Set</p>
          <p>D(n,m) = DTW(X(1:n),Y (1:m))</p>
          <p>D(n, m) is a N M matrix D called the
            <i>accumulated cost matrix</i>
            . A tuple (n, m) representing a matrix entry of
            the
            <i>cost matrix</i> C or of D will be referred to as a cell.
          </p>
          <p>D satisfies the following:</p>
          <p>D(n,1) = (from k=1 to n) c(xk,y0) " n  [1 : N]</p>
          <p>D(1,m) = c(x0,ym) "m  [1 : M]</p>
          <p>D(n,m) = argmin{D(n1,m1),D(n1,m),D(n,m1)}+c(xn,ym) " n  [2 : N] and m  [2 : N]</p>
          <p>One can also define an extended accumulated cost matrix:</p>
          <p>Setting:</p>
          <p>D(n,0) =  " n  [0 : N]</p>
          <p>D(0,m) := 0 " m  [0 : M].</p>
          <p>The index b can be determined from D :</p>
          <p>b =argmin {D(N,b)}</p>
          <p>
            To determine the starting index of the subsequence a and the optimal warping path between the stored and
            incoming
            signals.
          </p>
          <p>Input: Accumulated cost matrix D.</p>
          <p>Output: Optimal warping path p.</p>
          <p>The optimal path p = (p1, . . . , pL) is computed in reverse order of the indices starting with pL =
            (N,b).</p>
          <p>Suppose pl = (n, m) has been computed. In case (n, m) = (1, 1), one must have l to 1 and we are finished.
          </p>
          <p>Else:</p>
          <p>pl1 =</p>
          <p>"n = 1 : ( 1 , m  1 )</p>
          <p>"m=1 :(n1,1)</p>
          <p>else: argmin{D(n  1, m  1), D(n  1, m), D(n, m  1)}</p>
          <p>a is the maximal index such that pl = (a,1)</p>
          <p>
            All elements of the stored sequence Y left of ya and right of yb are excluded from consideration and do
            not incur
            additional costs.
          </p>
          <p>The optimal warping path between X and Y (a : b) is given by (pl,...,pL)</p>
          <table>
            <tr>
              <td></td>
            </tr>
            <tr>
              <td></td>
              <td>
                <img width="348" height="4" src="Final%20Report%20SP2_files/image014.gif" alt="image014">
              </td>
            </tr>
          </table>
          <p>
            <i>Figure 5: Database Subsequence Match against Incoming Sequence</i>
          </p>
          <p>&nbsp;</p>
          <p>D can be used to generate a list of subsequences of incoming signal that match the recorded trigger point.
          </p>
          <p>Create distance function :</p>
          <p> : [1 : M]  R eal (b) = D(N,b)</p>
          <p>
             assigns to each index b the minimal DTW distance (b) attainable between the stored sequence and the
            subsequence
            of the incoming signal that ends on index b.
          </p>
          <p>"b  [1 : M], the DTW-minimizing a  [1 : M] can be computed starting with pL = (N,b).</p>
          <p>
            If (b) is small $b  [1 : M] and if a  [1 : M] denotes the corresponding DTW-minimizing index, then the
            subsequence Y (a:b) matches the incoming section
          </p>
          <p>Input:
            <i>incoming signal</i> X = (x1,...,xN),
            <i>database sequence</i> = (y1,...,yM),
          </p>
          <p>cost threshold: </p>
          <p>
            Output: Ranked list of matches between incoming signal and subsections of database that have a match to the
            input
            below the threshold 
          </p>
          <p>Algorithm: (Match list tracker)</p>
          <p>1.)Ranked list must initially be empty</p>
          <p>2.)Calculate D</p>
          <p>3.)Calculate distance function  using (b) for each subsequence of the database Y</p>
          <p>4.)Select minimum b of.</p>
          <p>5.)If (b) &gt;  then a
            <i>match has been detected</i> .
          </p>
          <p>6.)Calculate corresponding match-subsequence index a  [1 : M]</p>
          <p>7.)add subsequence Y (a : b ) to ranked list</p>
          <p>8.)Set (b) =  "b within a suitable neighborhood of b</p>
          <p>9.)Continue by calculating the next minimizing index until input ends.</p>
          <p>
            The rule (b) =  is intended to exclude an a region bounded by the nearest local maximums to b from
            computation.
            This prevents a match list that contains many subsequences that differ by only a slight shift.
          </p>
          <p>
            This approach is a feasible solution because rather than scanning the song for a trigger sequence it would
            create a
            database for every user defined section of a song. This would allow the system to track the live status of
            the
            performance in real time rather than waiting for the right input to gauge where in the performance the
            guitarist is.
            Because of the sectionally specific subsequence length matching, this approach would also yield more
            accurate
            matches as the section of music being analized would not be based on hardcoded window lengths. Most
            importantly this
            technique is built entirely on the framework of the algorithm we implemented and therefore would only
            require
            expansion of the code as opposed to a full out overhaul of the system.
          </p>
          <p>
            Potential modifications to this platform include but are not limited to any control action as the result of
            the
            reading in of an audio sequence. For example, one could use the audio signal of virtually any instrument to
            control
            stage lighting, or advance a musical score for a symphony. It is also possible to design a physical hardware
            kill
            switch that temporarily suspends the program, allowing the musician to improvise and then jump back into the
            song
            without throwing off the system. If time permits, this system could even be expanded to include hardware
            effect
            pedals that are integrated seamlessly into the system or to control the volume level of different performers
            in
            relation both to each other and the current section of a song.
          </p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
          <p>List of References:</p>
          <p>
            [1] Rouse, M. (2005, April). What is MIDI (Musical Instrument Digital Interface)? - Definition from
            WhatIs.com.
            Retrieved December 10, 2017, from
            http://whatis.techtarget.com/definition/MIDI-Musical-Instrument-Digital-Interface
          </p>
          <p>
            [2] Fast Fourier Transform Tutorial. Retrieved December 10, 2017, from
            http://w.astro.berkeley.edu/~jrg/ngst/fft/fft.html
          </p>
          <p>[3] Roos, D. (2008, March 18). How MIDI Works. Retrieved December 10, 2017, from
            <a
              href="http://entertainment.howstuffworks.com/midi1.htm">http://entertainment.howstuffworks.com/midi1.htm</a>
          </p>
          <p>
            [4] Benjamin Bengfort, Computer and Data Scientist Follow. (2014, July 18). Beginners Guide to Non-Negative
            Matrix
            Factorization. Retrieved December 10, 2017, from
            <a
              href="https://www.slideshare.net/BenjaminBengfort/non-negative-matrix-factorization">https://www.slideshare.net/BenjaminBengfort/non-negative-matrix-factorization</a>
          </p>
          <p>
            [5] A. Stark and M. Plumbley. Real-time chord recognition for live performance. In Proceedings of
            International
            Computer Music Conference, volume 8, pages 585593. Citeseer, 2009
          </p>
          <p>[6] Nasser Kehtarnavaz. (2008 May). Digital Signal Processing System Design. LabVIEW Based Hybrid
            Programming.</p>
          <p>
            [7] A. Ozerov and C. Fevotte. Multichannel nonnegative matrix factorization in convolutive mixtures for
            audio
            source separation. Audio, Speech, and Language Processing, IEEE Transactions on, 18(3):550563, 2010
          </p>
          <p>
            [8] P. McLeod and G. Wyvill. A smarter way to find pitch. In Proceedings of International Computer Music
            Conference, ICMC, 2005.
          </p>
          <p>
            [9] P. McLeod. Fast, accurate pitch detection tools for music analysis. PhD thesis, PhD thesis, University
            of
            Otago. Department of Computer Science, 2009.
          </p>
          <p>
            [10] E. Larson and R. Maddox. Real-time time-domain pitch tracking using wavelets. Proceedings of the
            University of
            Illinois at Urbana Champaign Research Experience for Undergraduates Program, 2005.
          </p>
          <p>
            [11] E. Larson and R. Maddox. Real-time time-domain pitch tracking using wavelets. Proceedings of the
            University of
            Illinois at Urbana Champaign Research Experience for Undergraduates Program, 2005.
          </p>
          <p>[12] M. Brooks. Developing visualization software for musicians. 2010.</p>
          <p>
            [13] A. Dessein, A. Cont, and G. Lemaitre. Real-time polyphonic music transcription with non-negative matrix
            factorization and beta-divergence. In Proc. 11th International Society for Music Information Retrieval
            Conference
            (IS- MIR2010), page 2, 2010.
          </p>
          <p>
            [14] C. Duxbury, M. Davies, and M. Sandler. Separation of transient information in musical audio using
            multiresolution analysis techniques. In Proceedings of the COST G-6 Conference on Digital Audio Effects
            (DAFX-01),
            Limerick, Ireland, 2001.
          </p>
          <p>[15] An Interactive Guide To The Fourier Transform. (n.d.). Retrieved December 10, 2017</p>
          <p>
            [16] The Scientist and Engineer's Guide toDigital Signal ProcessingBy Steven W. Smith, Ph.D. (n.d.).
            Retrieved
            December 10, 2017
          </p>
          <p>
            [17] Kazuki Yazawa, Katsutoshi Itoyama, Hiroshi G. Okuno, "Automatic transcription of guitar tablature from
            audio
            signals in accordance with player's proficiency", Acoustics Speech and Signal Processing (ICASSP) 2014 IEEE
            International Conference on, pp. 3122-3126, 2014.
          </p>
          <p>
            [18] Introduction to Wavelet Signal Processing (Advanced Signal Processing Toolkit). (n.d.). Retrieved
            December 10,
            2017
          </p>
          <p>
            [19] Rioul, Olivier & Vetterli, Martin. (1991). Wavelets and signal processing. Signal Processing Magazine,
            IEEE.
            8. 14 - 38. 10.1109/79.91217.
          </p>
          <p>[20] K. (n.d.). [helmholtz~] finds the pitch. Retrieved December 10, 2017</p>
          <p>
            [21] Muller, M. (1970, January 01). Dynamic Time Warping (DTW). Retrieved December 10, 2017, from
            https://link.springer.com/referenceworkentry/10.1007%2F978-0-387-73003-5_768
          </p>
          <p>
            [22] Cq2midi Polyphonic MIDI notes from audio for Pure Data. (n.d.). Retrieved December 11, 2017, from
            https://grrrr.org/research/software/cq2midi/
          </p>
          <p>[23] Chordetector_pd. (n.d.). Retrieved December 11, 2017, from https://patchstorage.com/chordetector_pd/
          </p>
          <p>
            [24] K. (n.d.). [Pd~] graphical dsp programming. Retrieved December 10, 2017, from
            http://www.katjaas.nl/puredata/puredata.html
          </p>
          <p>[25] C. (n.d.). Retrieved December 10, 2017, from
            <a
              href="http://www.phon.ox.ac.uk/jcoleman/old_SLP/Lecture_5/DTW_explanation.html">http://www.phon.ox.ac.uk/jcoleman/old_SLP/Lecture_5/DTW_explanation.html</a>
          </p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
          <p>Appendices:</p>
          <p>
            <strong>Appendix A: Project Overview</strong>
          </p>
          <p>
            <strong>Team Members:</strong>
          </p>
          <p>
            <img width="188" height="192" src="Final%20Report%20SP2_files/image015.jpg" alt="image015">
          </p>
          <p>
            Ralph Quinto is a Senior studying Computer Engineering at The College of New Jersey. He is the software
            engineer of
            the group and is tasked to research for possible programming platforms. In addition he is responsible for
            reading
            electric guitar signals, creating the signal analysis patches in pure data, and triggering digital guitar
            effects.
            Post graduation, Ralph plans on entering the industry as a software engineer and eventually obtaining his
            master's
            in Cybersecurity. Ralphs hobbies includes competing in basketball, cooking, and playing video games.
          </p>
          <p>&nbsp;</p>
          <p>
            <img width="171" height="216" src="Final%20Report%20SP2_files/image016.gif" alt="image016">
          </p>
          <p>
            Haley Scott is a senior studying Electrical Engineering at The College of New Jersey. She is the
            architectural
            manager of this design project, handling tasks such as the research of system methods, the design and
            creation of
            digital effects, as well as project and organizational management. She will also ensure the successful
            integration
            of all project components. Upon graduation, Haley plans on entering the water and wastewater industry, and
            furthering her education after gaining experience in the electrical design sector of the field. In her free
            time,
            Haley enjoys playing the piano, spending time with family and friends, and playing golf.
          </p>
          <p>&nbsp;</p>
          <p>
            <img width="176" height="184" src="Final%20Report%20SP2_files/image017.jpg" alt="image017">
          </p>
          <p>
            Bryan Guner is a senior studying Electrical Engineering at The College of New Jersey. He is team leader as
            well as
            being tasked with developing a protocol for digital signal processing of the guitar signal in order to
            create a
            time-sequential record of the frequency content of the guitar signal, and a comparison between pre recorded
            songs
            and live performances. Upon graduation Bryan intends to work in industry hopefully in addition to pursuing a
            masters
            degree. Hobbies include but are not limited to: guitar, music, hockey, physics, philosophy, art, and
            spending time
            with good friends.
          </p>
          <p>&nbsp;</p>
          <p>
            <strong>Engineering Standards:</strong>
          </p>
          <p>
            <strong>
              IEEE STD 730-2014 (Revision of IEEE STD 730-2002) - IEEE Standard for Software Quality Assurance
              Processes
            </strong>
          </p>
          <p>
             &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Software utilized will meet quality requirements according to the
            IEEE
            730-2014 Standard for Software Quality Assurance Processes
          </p>
          <p>&nbsp;</p>
          <p>
            <strong>Realistic Constraints:</strong>
          </p>
          <table>
            <tr>
              <td>
                <p>
                  <strong>Design Requirement</strong>
                </p>
              </td>
              <td>
                <p>
                  <strong>Realistic Constraints</strong>
                </p>
              </td>
            </tr>
            <tr>
              <td>
                <p>Sound output must be loud enough to hear, between 0dB to 65 dB</p>
              </td>
              <td>
                <p>Speakers will not produce sound over 85dB to eliminate chances of permanent hearing damage</p>
              </td>
            </tr>
            <tr>
              <td>
                <p>Guitar must be connected to computer throughout recording phase and live performance phase</p>
              </td>
              <td>
                <p>Cord must only be detached in an idle phase, not during recording or live performance</p>
              </td>
            </tr>
            <tr>
              <td>
                <p>Minimum note onset separation</p>
              </td>
              <td>
                <p>Sampling rate 44.1KHz</p>
              </td>
            </tr>
            <tr>
              <td>
                <p>Trigger latency</p>
              </td>
              <td>
                <p>Processor speed, O(NM) computation, length of segment</p>
              </td>
            </tr>
          </table>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
          <p>
            <strong>Modern Engineering Tools:</strong>
          </p>
          <p> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Pure Data</p>
          <p> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Java</p>
          <p> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; C</p>
          <p> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; CodeBlocks</p>
          <p> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Excel</p>
          <p>
            <strong>Appendix B: Project Management</strong>
          </p>
          <p>
            <strong>Gantt Chart:</strong>
          </p>
          <p>
            <strong>
              <img width="626" height="415" src="Final%20Report%20SP2_files/image018.gif" alt="image018">
            </strong>
          </p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
          <p>
            <strong>&nbsp;</strong>
          </p>
          <p>
            <strong>&nbsp;</strong>
          </p>
          <p>
            <strong>Time Budget</strong>
          </p>
          <p>
            <img width="474" height="301" src="Final%20Report%20SP2_files/image019.gif" alt="image019">
          </p>
          <p>
            <strong>List of Contacts:</strong>
          </p>
          <p> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Ambrose Adegbege</p>
          <p> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; (609) 771-2863</p>
          <p> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Adegebega@tcnj.edu</p>
          <p>&nbsp;</p>
          <p>
            <strong>Material List:</strong>
          </p>
          <p> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Electric Guitar</p>
          <p> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; to USB adapter</p>
          <p> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Computer</p>
          <p> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; PureData</p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
          <p>
            <strong>Financial Budget</strong>
          </p>
          <p> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; to USB adapter ($10)</p>
          <p> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Senior Project Poster ($82)</p>
          <p>
            <img width="471" height="301" src="Final%20Report%20SP2_files/image020.gif" alt="image020">
          </p>
          <p>
            <strong>&nbsp;</strong>
          </p>
          <p>
            <strong>Project Meeting Minutes:</strong>
          </p>
          <p>
            Meeting 1 Date: August 30, 2017 Time: 30 Minutes Present: Bryan, Haley, Ralph, Dr. Adegbege Absent: None
            Discussion
            Items: Possible solutions for project Organizational management for semester Design ideas and concepts
            Meeting 2
            Date: September 6, 2017 Time: 60 Minutes Present: Bryan, Haley, Ralph, Dr. Adegbege Absent: None Discussion
            Items:
            Initial design review ideas Design review 1 Project solutions (Logic, GarageBand, MIDI) Meeting 3 Date:
            September
            11, 2017 Time: 30 Minutes Present: Bryan, Haley, Ralph, Dr. Adegbege Absent: None Discussion Items: Design
            review
            Scheduling Possible candidate platforms Meeting 4 Date: September 27, 2017 Time: 30 minutes Present: Bryan,
            Haley,
            Ralph Absent: Dr. Adegbege Discussion Items: Action items Reviewed individual research Meeting 5 Date:
            October 4,
            2017 Time: 60 Minutes Present: Bryan, Haley, Ralph, Dr. Adegbege Absent: None Discussion Items: System
            architecture
            Adaptive threshold concept Neural network implementation Low pass filter implementation Python
            implementation
            Meeting 6 Date: October 11, 2017 Time: 60 Minutes Present: Bryan, Haley, Ralph, Dr. Adegbege Absent: None
            Discussion
            Items: Feature identification Rhythm (transient) Pitch (steady state) Applying our concepts to other
            projects
            (automatic scoring) Meeting 7 Date: October 18, 2017 Time: 30 Minutes Present: Bryan, Ralph, Dr. Adegbege
            Absent:
            Haley Discussion Items: Fuzzy logic Dynamic Time warping Implementation ideas Meeting 8 Date: November 1,
            2017 Time:
            30 Minutes Present: Bryan, Haley, Ralph, Dr. Adegbege Absent: None Discussion Items: Adaptive filtering
            Dynamic Time
            warping Low pass filtering Pure Data User interface Meeting 9 Date: November 8, 2017 Time: 30 Minutes
            Present:
            Bryan, Haley, Dr. Adegbege Absent: Ralph Discussion Items: LabVIEW Guitar tuner Binary search algorithm in
            matching
            sequences Website/Wordpress Meeting 10 Date: November 15, 2017 Time: 60 Minutes Present: Bryan, Haley, Dr.
            Adegbege
            Absent: Ralph Discussion Items: Baseline functionality Demonstrations and testing Contents of final report
            Importance of abstract Meeting 11 Date: November 29, 2017 Time: 30 Minutes Present: Bryan, Haley, Ralph, Dr.
            Adegbege Absent: None Discussion Items: Realistic constraints Final design review Final report Video
            demonstration
            ideas
          </p>
          <p>
            Meeting 12 Date: January 31, 2018 Time: 60 Minutes Present: Bryan, Haley, Ralph, Dr. Adegbege Absent: None
            Discussion Items: Semester plans and schedules Progress with external for Pd PDR presentation Modify DTW
          </p>
          <p>
            Meeting 13 Date: February 5, 2018 Time: 30 Minutes Present: Bryan, Haley, Ralph Absent: None Discussion
            Items:
            Review PDR Convert pseudocode into C Design more complex effect Research externals
          </p>
          <p>
            Meeting 14 Date: February 7, 2018 Time: 30 Minutes Present: Haley, Ralph, Dr. Adegbege Absent: Bryan
            Discussion
            Items: Progress on effect WAV file research TCF preparation Demonstration preparation
          </p>
          <p>
            Meeting 15 Date: February 14, 2018 Time: 60 Minutes Present: Haley, Bryan, Ralph, Dr. Adegbege Absent:
            Discussion
            Items: Reimbursement for cable Roadblocks with input format Progress on effect Realistic constraint
            discussion
          </p>
          <p>
            Meeting 16 Date: February 26, 2018 Time: 60 Minutes Present: Haley, Ralph Absent: Bryan Discussion Items:
            Code
            manipulation completed Discussion of testing phase Test procedure Reimbursement not yet delivered
          </p>
          <p>
            Meeting 17 Date: February 28, 2018 Time: 120 Minutes Present: Bryan, Haley, Ralph, Dr. Adegbege Absent: None
            Discussion Items: Progress with basic GUI Testing and implementation Effect progress External progress
          </p>
          <p>
            Meeting 18 Date: March 3, 2018 Time: 60 Minutes Present: Bryan, Haley, Ralph Absent: None Discussion Items:
            Poster
            Layout Poster Content Draft report Modify DTW code
          </p>
          <p>
            Meeting 19 Date: March 27, 2018 Time: 60 Minutes Present: Bryan, Haley, Ralph, Dr. Adegbege Absent: None
            Discussion
            Items: Testing of software Celebration preparation Presentation preparation Reimbursement for poster
          </p>
          <p>
            Meeting 20 Date: April 3, 2018 Time: 120 Minutes Present: Bryan, Haley, Ralph Absent: None Discussion Items:
            Software testing Latency testing Triggering testing and adjustments Schedule planning and updates
          </p>
          <p>
            Meeting 21 Date: April 11, 2018 Time: 60 Minutes Present: Bryan, Haley, Ralph Absent: None Discussion Items:
            Software testing Software adjustments Scheduling for time and budget Reimbursement (1) received
          </p>
          <p>
            Meeting 22 Date: April 15, 2018 Time: 60 Minutes Present: Haley, Ralph Absent: Bryan Discussion Items:
            Guitar
            testing with simple sequence Software adjustments Plans for draft, final presentation Planned next meeting
            with Dr.
            Adegbege
          </p>
          <p>
            Meeting 23 Date: April 17, 2018 Time: 60 Minutes Present: Bryan, Haley, Ralph Absent: None Discussion Items:
            Software testing Software adjustments Testing data recorded Testing with different time windows
          </p>
          <p>
            Meeting 24 Date: April 24, 2018 Time: 60 Minutes Present: Haley, Ralph Absent: Bryan Discussion Items: Final
            report
            Packaging of project Demonstration feasibility Reimbursement
          </p>
          <p>
            Meeting 1 Date: April 29, 2018 Time: 120 Minutes Present: Bryan, Haley, Ralph Absent: None Discussion Items:
            Finalization of presentation Organizational management for semester Rehearsal of final presentation
          </p>
          <p>
            <strong>Supporting Figures: Ralph</strong>
          </p>
          <p>
            <img width="349" height="188" src="Final%20Report%20SP2_files/image021.gif" alt="image021">
          </p>
          <p>Figure 1: Fuzz Effect Pd</p>
          <p>&nbsp;</p>
          <p>
            <img width="438" height="279" src="Final%20Report%20SP2_files/image022.gif" alt="image022">
          </p>
          <p>Figure 2: Delay Effect Pd</p>
          <p>&nbsp;</p>
          <p>
            <img width="454" height="339" src="Final%20Report%20SP2_files/image023.gif" alt="image023">
          </p>
          <p>Figure 3: Reverb Effect Pd</p>
          <p>
            <img width="449" height="348" src="Final%20Report%20SP2_files/image024.gif" alt="image024">
          </p>
          <p>Figure 4: Spectral Delay Effect Pd</p>
          <p>&nbsp;</p>
          <p>
            <img width="538" height="385" src="Final%20Report%20SP2_files/image025.gif" alt="image025">
          </p>
          <p>Figure 5: Pd Module</p>
          <p>&nbsp;</p>
          <p>
            <img width="626" height="240" src="Final%20Report%20SP2_files/image026.jpg" alt="image026">
          </p>
          <p>Figure 6: Simplified Pd Block Diagram</p>
          <p>&nbsp;</p>
          <p>
            <img width="94" height="44" src="Final%20Report%20SP2_files/image027.gif" alt="image027">
          </p>
          <p>Figure 7: DTW Pd Object</p>
          <p>&nbsp;</p>
          <p>
            <strong>Java Code of Dynamic Time Warping:</strong>
          </p>

          <p>public class DTW {</p>
          <p>private double [] horizontalInput ;</p>
          <p>private double [] verticalInput ;</p>
          <p>public DTW ( double [] horizontalInput, double [] verticalInput) {</p>
          <p>this . horizontalInput = horizontalInput;</p>
          <p>this . verticalInput = verticalInput;</p>
          <p>}</p>
          <p>
            <i>/*</i>
          </p>
          <p>
            <i>Finds the minimum cost path to reach current value</i>
          </p>
          <p>
            <i>*/</i>
          </p>
          <p>private static double min ( MatrixTriplet matrixTriplet) {</p>
          <p>return Math . min ( Math . min ( matrixTriplet . left , matrixTriplet . bottom ),</p>
          <p>matrixTriplet . bottomLeft );</p>
          <p>}</p>
          <p>&nbsp;</p>
          <p>
            <i>/*</i>
          </p>
          <p>
            <i>This finds the squared difference of the matrix points</i>
          </p>
          <p>
            <i>Generates a 2D array and returns the symmetrical distance measure</i>
          </p>
          <p>
            <i>*/</i>
          </p>
          <p>private double [][] buildDistanceMatrix (){</p>
          <p>int rows = verticalInput.length ;</p>
          <p>int cols = horizontalInput.length ;</p>
          <p>double [][] matrix = new double [rows + 1 ][cols + 1 ] ;</p>
          <p>for ( int i = 1 ; i &lt; matrix[ 0 ]. length ; ++i) {</p>
          <p>matrix[ 0 ][i] = horizontalInput[i- 1 ];</p>
          <p>}</p>
          <p>for ( int i = 1 ; i &lt; matrix . length ; ++i) {</p>
          <p>matrix[i][ 0 ] = verticalInput[i- 1 ];</p>
          <p>}</p>
          <p>for ( int row = 1 ; row &lt;= rows; ++row) {</p>
          <p>for ( int col = 1 ; col &lt;= cols; ++col) {</p>
          <p>matrix[row][col] = ( int ) Math . pow (matrix[ 0 ][col]-matrix[row][ 0 ], 2 );</p>
          <p>}</p>
          <p>}</p>
          <p>return matrix;</p>
          <p>}</p>
          <p>
            <i>/*</i>
          </p>
          <p>
            <i>Finds the left and bottom initial cost values. Initialization phase</i>
          </p>
          <p>
            <i>*/</i>
          </p>
          <p>private static MatrixTriplet [][] buildTripleMatrixWithLeftAndBottomValues ( double [][]distanceMatrix){
          </p>
          <p>int rows = distanceMatrix.length ;</p>
          <p>int cols = distanceMatrix[ 0 ].length ;</p>
          <p>MatrixTriplet [][] leftAndBottomMatrix = new MatrixTriplet [rows][cols] ;</p>
          <p>for ( int row = 0 ; row &lt; rows; ++row) {</p>
          <p>for ( int col = 0 ; col &lt; cols; ++col) {</p>
          <p>leftAndBottomMatrix[row][col] = new MatrixTriplet (distanceMatrix[row][col]);</p>
          <p>}</p>
          <p>}</p>
          <p>leftAndBottomMatrix[ 1 ][ 1 ]. left = distanceMatrix[ 1 ][ 1 ];</p>
          <p>for ( int col = 2 ; col&lt;cols; ++col) {</p>
          <p>leftAndBottomMatrix[ 1 ][col]. left = leftAndBottomMatrix[ 1 ][col- 1 ]. left</p>
          <p>+ distanceMatrix[ 1 ][col];</p>
          <p>leftAndBottomMatrix[ 1 ][col]. bottom = leftAndBottomMatrix[ 1 ][col]. left ;</p>
          <p>}</p>
          <p>leftAndBottomMatrix[ 1 ][ 1 ]. bottom = distanceMatrix[ 1 ][ 1 ];</p>
          <p>for ( int row = 2 ; row&lt;rows; ++row) {</p>
          <p>leftAndBottomMatrix[row][ 1 ]. bottom = leftAndBottomMatrix[row- 1 ][ 1 ]. bottom</p>
          <p>+ distanceMatrix[row][ 1 ];</p>
          <p>leftAndBottomMatrix[row][ 1 ]. left = leftAndBottomMatrix[row][ 1 ]. bottom ;</p>
          <p>}</p>
          <p>return leftAndBottomMatrix;</p>
          <p>}</p>
          <p>
            <i>/*</i>
          </p>
          <p>
            <i>Finds the left/bottom/bottomleft cost values</i>
          </p>
          <p>
            <i>*/</i>
          </p>
          <p>private static MatrixTriplet [][] buildFinalMatrix ( MatrixTriplet [][] leftAndBottomMatrix){</p>
          <p>int rows = leftAndBottomMatrix.length ;</p>
          <p>int cols = leftAndBottomMatrix.length ;</p>
          <p>MatrixTriplet [][] finalMatrix = new MatrixTriplet [rows][cols] ;</p>
          <p>for ( int row = 0 ; row &lt; rows; ++row) {</p>
          <p>for ( int col = 0 ; col&lt;cols; ++col) {</p>
          <p>finalMatrix[row][col] = new</p>
          <p>MatrixTriplet (leftAndBottomMatrix[row][col]. initial ,</p>
          <p>leftAndBottomMatrix[row][col]. left ,</p>
          <p>leftAndBottomMatrix[row][col]. bottom ,</p>
          <p>leftAndBottomMatrix[row][col]. bottomLeft );</p>
          <p>}</p>
          <p>}</p>
          <p>for ( int row = 2 ; row &lt; rows; ++row) {</p>
          <p>for ( int col = 2 ; col &lt; cols; ++col) {</p>
          <p>finalMatrix[row][col]. left = min (finalMatrix[row][col - 1 ])</p>
          <p>+ finalMatrix[row][col]. initial ;</p>
          <p>finalMatrix[row][col]. bottom = min (finalMatrix[row- 1 ][col])</p>
          <p>+ finalMatrix[row][col]. initial ;</p>
          <p>finalMatrix[row][col]. bottomLeft = min (finalMatrix[row - 1 ][col - 1 ])</p>
          <p>+ finalMatrix[row][col]. initial ;</p>
          <p>}</p>
          <p>}</p>
          <p>return finalMatrix;</p>
          <p>}</p>
          <p>private double compute () {</p>
          <p>double [][] distanceMatrix = buildDistanceMatrix ();</p>
          <p>MatrixTriplet [][] leftAndBottomValuesTripletMatrix =</p>
          <p>buildTripleMatrixWithLeftAndBottomValues ( distanceMatrix );</p>
          <p>MatrixTriplet [][] finalMatrix = buildFinalMatrix ( leftAndBottomValuesTripletMatrix );</p>
          <p>return min (finalMatrix[ verticalInput . length ][ horizontalInput . length ]);</p>
          <p>}</p>
          <p>private static class MatrixTriplet {</p>
          <p>double initial = Double.POSITIVE_INFINITY ;</p>
          <p>double left = Double.POSITIVE_INFINITY ;</p>
          <p>double bottom = Double.POSITIVE_INFINITY ;</p>
          <p>double bottomLeft = Double.POSITIVE_INFINITY ;</p>
          <p>MatrixTriplet ( double initial, double left, double bottom, double bottomLeft){</p>
          <p>this . initial = initial;</p>
          <p>this . left = left;</p>
          <p>this . bottom = bottom;</p>
          <p>this . bottomLeft = bottomLeft;</p>
          <p>}</p>
          <p>MatrixTriplet ( double initial){</p>
          <p>this . initial = initial;</p>
          <p>}</p>
          <p>}</p>
          <p>public static void main ( String [] args) {</p>
          <p>
            <i>// double [] horizontalInput1 = {1.0, 1.0, 2.0, 3.0, 2.0, 0.0};</i>
          </p>
          <p>
            <i>// double [] verticalInput1 = {0.0, 1.0, 1.0, 2.0, 3.0, 2.0, 1.0};</i>
          </p>
          <p>
            <i>// DTW similarInputs = new DTW(horizontalInput1, verticalInput1);</i>
          </p>
          <p>
            <i>// double result = similarInputs.compute();</i>
          </p>
          <p>double [] horizontalInput2 = { 0.0 , 1.0 , 1.0 , 2.0 , 3.0 , 2.0 , 1.0 };</p>
          <p>double [] verticalInput2 = { 0.0 , 1.0 , 1.0 , 2.0 , 3.0 , 2.0 , 1.0 };</p>
          <p>DTW sameInputs = new DTW ( horizontalInput2, verticalInput2 );</p>
          <p>double result2 = sameInputs . compute ();</p>
          <p>System . out . println ( "Least cost path of Test 1: " + result2);</p>
          <p>double [] horizontalInput3 = { 1.0 , 1.0 , 2.0 , 3.0 , 2.0 , 0.0 };</p>
          <p>double [] verticalInput3 = { 0.0 , 0.0 , 1.0 , 2.0 , 1.0 , - 1.0 };</p>
          <p>DTW sameInputsOutPhase = new DTW ( horizontalInput3, verticalInput3 );</p>
          <p>double result3 = sameInputsOutPhase . compute ();</p>
          <p>System . out . println ( "Least cost path of Test 2: " + result3);</p>
          <p>
            <i>// double [] horizontalInput4 = {1.0, 2.0, 3.0, 4.0, 2.0, 1.0};</i>
          </p>
          <p>
            <i>// double [] verticalInput4 = {5.0, 0.0, 1.0, 4.0, 2.0, 0.0, 3.0};</i>
          </p>
          <p>
            <i>// DTW differentInputs = new DTW(horizontalInput4, verticalInput4);</i>
          </p>
          <p>
            <i>// double result4 = differentInputs.compute();</i>
          </p>
          <p>
            <i>// System.out.println("Least cost path of Test 4: " + result4);</i>
          </p>
          <p>}</p>
          <p>}</p>
          <p>
            <strong>Dynamic Time Warping PD Object C code:</strong>
          </p>
          <p>#include "m_pd.h"</p>
          <p>#include &lt;math.h&gt;</p>
          <p>#include &lt;stdio.h&gt;</p>
          <p>#include &lt;stdlib.h&gt;</p>
          <p>#include &lt;stdio.h&gt;</p>
          <p>#include &lt;time.h&gt;</p>
          <p>#include &lt;windows.h&gt;</p>
          <p>&nbsp;</p>
          <p>#define SIZE_ARRAY 300</p>
          <p>#define TEST_SIZE 300</p>
          <p>&nbsp;</p>
          <p>static t_class *dynamicTW_class; //handle for the class</p>
          <p>&nbsp;</p>
          <p>float recording_array[SIZE_ARRAY] = {0};</p>
          <p>int arr_position = SIZE_ARRAY - 1;</p>
          <p>float saveValue = 0.0;</p>
          <p>int triggerGlobal = 0;</p>
          <p>float delayTime = 0.0;</p>
          <p>&nbsp;</p>
          <p>/* struct to hold cost of arrival from left, bottom, and diagonal */</p>
          <p>typedef struct _leftbottom{</p>
          <p>float left;</p>
          <p>float bottom;</p>
          <p>float diag;</p>
          <p>}leftBD; //typedef name</p>
          <p>&nbsp;</p>
          <p>typedef struct _dynamicTW{</p>
          <p>t_object x_obj;</p>
          <p>&nbsp;</p>
          <p>int flag; //differentiates if how result of lcp is stored</p>
          <p>int match; //if 0 signal does not match else matches</p>
          <p>float testArray[TEST_SIZE];</p>
          <p>float storedSignalOne[SIZE_ARRAY];</p>
          <p>float storedSignalTwo[SIZE_ARRAY];</p>
          <p>&nbsp;</p>
          <p>t_inlet *in_mod_A, *in_mod_B;</p>
          <p>t_outlet *out_A;</p>
          <p>&nbsp;</p>
          <p>float signal[SIZE_ARRAY];</p>
          <p>float lcpValue;</p>
          <p>float compareValue;</p>
          <p>&nbsp;</p>
          <p>float initMatrix[SIZE_ARRAY][SIZE_ARRAY];</p>
          <p>leftBD costValues[SIZE_ARRAY-1][SIZE_ARRAY-1];</p>
          <p>&nbsp;</p>
          <p>}t_dynamicTW; //typedef name</p>
          <p>&nbsp;</p>
          <p>void checkStorage(t_dynamicTW *x){ //check if values being stored correctly</p>
          <p>int i;</p>
          <p>post("in check storage");</p>
          <p>for(i = 0; i &lt; TEST_SIZE; i++){</p>
          <p>post("Signal 1: %f", x-&gt;storedSignalOne[i]);</p>
          <p>post("Signal 2: %f", x-&gt;storedSignalTwo[i]);</p>
          <p>}</p>
          <p>}</p>
          <p>&nbsp;</p>
          <p>void signalMatch(t_dynamicTW *x){</p>
          <p>float tenup = saveValue + (.05*saveValue);</p>
          <p>float zeroValue = 0.00;</p>
          <p>FILE *fp1;</p>
          <p>FILE *fp2;</p>
          <p>FILE *fp3;</p>
          <p>int j;</p>
          <p>if(x-&gt;compareValue &lt;= tenup &amp;& x-&gt;compareValue &gt;= zeroValue){</p>
          <p>Sleep(delayTime * 1000); //how long to delay bang in seconds;</p>
          <p>outlet_bang(x-&gt;out_A);</p>
          <p>x-&gt;match = 1;</p>
          <p>/* add code to trigger effect */</p>
          <p>
            post("Incoming Signal Matches Stored Signal. compareValue is %f and lcpValue is %f", x-&gt;compareValue,
            saveValue);
          </p>
          <p>post("delay time: %f", delayTime);</p>
          <p>fp1 = fopen("C:\\Users\\Raki\\Documents\\GitHub\\dynamicTW\\TB\\save1.txt", "w");</p>
          <p>fp2 = fopen("C:\\Users\\Raki\\Documents\\GitHub\\dynamicTW\\TB\\save2.txt", "w");</p>
          <p>fp3 = fopen("C:\\Users\\Raki\\Documents\\GitHub\\dynamicTW\\TB\\save3.txt", "w");</p>
          <p>post("saving");</p>
          <p>for(j = 0; j&lt;SIZE_ARRAY; j++){</p>
          <p>fprintf(fp1, "%f\n", x-&gt;storedSignalOne[j]);</p>
          <p>fprintf(fp2, "%f\n", x-&gt;storedSignalTwo[j]);</p>
          <p>fprintf(fp3, "%f\n", x-&gt;initMatrix[0][j]);</p>
          <p>}</p>
          <p>post("finish saving");</p>
          <p>fclose(fp1);</p>
          <p>fclose(fp2);</p>
          <p>fclose(fp3);</p>
          <p>}</p>
          <p>else{</p>
          <p>x-&gt;match = 0;</p>
          <p>post("Signal NO Match. compareVal is %f while lcpVal is %f\n", x-&gt;compareValue, saveValue);</p>
          <p>}</p>
          <p>}</p>
          <p>float findMin(t_dynamicTW *x, int row, int column){</p>
          <p>float temp, min;</p>
          <p>float checkLeft = x-&gt;costValues[row][column].left;</p>
          <p>float checkBottom = x-&gt;costValues[row][column].bottom;</p>
          <p>float checkDiagonal = x-&gt;costValues[row][column].diag;</p>
          <p>&nbsp;</p>
          <p>temp = (checkLeft &lt; checkBottom) ? checkLeft : checkBottom;</p>
          <p>min = (checkDiagonal &lt; temp) ? checkDiagonal : temp;</p>
          <p>return min;</p>
          <p>}</p>
          <p>void reverseArray(t_dynamicTW *x){</p>
          <p>int i, j;</p>
          <p>i = SIZE_ARRAY - 1;</p>
          <p>j = 0;</p>
          <p>while(i &gt; j){</p>
          <p>float temp = x-&gt;storedSignalTwo[i];</p>
          <p>x-&gt;storedSignalTwo[i] = x-&gt;storedSignalTwo[j];</p>
          <p>x-&gt;storedSignalTwo[j] = temp;</p>
          <p>i--;</p>
          <p>j++;</p>
          <p>}</p>
          <p>}</p>
          <p>&nbsp;</p>
          <p>void fileReader1(t_dynamicTW *x, char *path){</p>
          <p>
            //char const* const fileName = "C:\\Users\\Raki\\Documents\\GitHub\\dynamicTW\\TB\\input.txt" ;/* should
            check that
            argc &gt; 1 */
          </p>
          <p>FILE* file = fopen(path, "r"); /* should check the result */</p>
          <p>char line[256];</p>
          <p>int i = 0;</p>
          <p>while (fgets(line, sizeof(line), file)) {</p>
          <p>//post("file1: value at line %d is %s", i, line);</p>
          <p>x-&gt;storedSignalOne[i] = atof(line); // !!!!!!!!!!!!!!!!!!!!! REMOVE 1000</p>
          <p>i++;</p>
          <p>}</p>
          <p>fclose(file);</p>
          <p>}</p>
          <p>void fileReader2(t_dynamicTW *x, char *path){</p>
          <p>
            //char const* const fileName = "C:\\Users\\Raki\\Documents\\GitHub\\dynamicTW\\TB\\input.txt" ;/* should
            check that
            argc &gt; 1 */
          </p>
          <p>FILE* file = fopen(path, "r"); /* should check the result */</p>
          <p>char line[256];</p>
          <p>int i = 0;</p>
          <p>while (fgets(line, sizeof(line), file)) {</p>
          <p>//post("file2: value at line %d is %s", i, line);</p>
          <p>x-&gt;storedSignalTwo[i] = atof(line); // !!!!!!!!!!!!!!!!!!!!!!!!!!! REMOVE 1000</p>
          <p>i++;</p>
          <p>}</p>
          <p>fclose(file);</p>
          <p>}</p>
          <p>&nbsp;</p>
          <p>void replaceSignal2(t_dynamicTW *x){</p>
          <p>int i;</p>
          <p>for(i = 0; i &lt; SIZE_ARRAY; i++){</p>
          <p>x-&gt;storedSignalTwo[i] = x-&gt;signal[i];</p>
          <p>}</p>
          <p>}</p>
          <p>&nbsp;</p>
          <p>/*</p>
          <p>1. Create a 2d array for our matrix</p>
          <p>2. fill in the left column and bottom row with our 2 signals</p>
          <p>3. Populate the rest of the matrix</p>
          <p>4. calculate least cost path</p>
          <p>*/</p>
          <p>&nbsp;</p>
          <p>void leastCostPath(t_dynamicTW *x){</p>
          <p>float temp, min;</p>
          <p>float result = 0;</p>
          <p>int i = SIZE_ARRAY - 2;</p>
          <p>int j = SIZE_ARRAY - 2;</p>
          <p>&nbsp;</p>
          <p>// post("starting point value left is %f", x-&gt;costValues[i][j].left);</p>
          <p>// post("starting point value bottom is %f", x-&gt;costValues[i][j].bottom);</p>
          <p>// post("starting point value diag is %f", x-&gt;costValues[i][j].diag);</p>
          <p>&nbsp;</p>
          <p>while(i &gt;= 0 &amp;& j &gt;= 0){</p>
          <p>float checkLeft = x-&gt;costValues[i][j].left;</p>
          <p>float checkBottom = x-&gt;costValues[i][j].bottom;</p>
          <p>float checkDiagonal = x-&gt;costValues[i][j].diag;</p>
          <p>&nbsp;</p>
          <p>temp = (checkLeft &lt; checkBottom) ? checkLeft : checkBottom;</p>
          <p>min = (checkDiagonal &lt; temp) ? checkDiagonal : temp;</p>
          <p>&nbsp;</p>
          <p>result += min;</p>
          <p>&nbsp;</p>
          <p>/* Changes cell location after finding min */</p>
          <p>if(min == checkDiagonal){</p>
          <p>if (i-1 &lt; 0 &amp;& j-1 &lt; 0){</p>
          <p>break;</p>
          <p>}</p>
          <p>else if (i-1 &lt; 0){</p>
          <p>j--;</p>
          <p>}</p>
          <p>else if (j-1 &lt; 0){</p>
          <p>i--;</p>
          <p>}</p>
          <p>else{</p>
          <p>i--;</p>
          <p>j--;</p>
          <p>}</p>
          <p>}</p>
          <p>else if (min == checkLeft){</p>
          <p>if(j-1 &lt; 0){</p>
          <p>break;</p>
          <p>}</p>
          <p>else{</p>
          <p>j--;</p>
          <p>}</p>
          <p>}</p>
          <p>else{</p>
          <p>if(i-1 &lt; 0){</p>
          <p>break;</p>
          <p>}</p>
          <p>else{</p>
          <p>i--;</p>
          <p>}</p>
          <p>}</p>
          <p>&nbsp;</p>
          <p>}</p>
          <p>if(x-&gt;flag == 0){</p>
          <p>saveValue += result;</p>
          <p>post("storing to saveValue: current saveValue is %f", saveValue);</p>
          <p>}</p>
          <p>else if (x-&gt;flag == 1){</p>
          <p>x-&gt;compareValue = result;</p>
          <p>post("compareValue: least cost path is %f", x-&gt;compareValue);</p>
          <p>}</p>
          <p>}</p>
          <p>&nbsp;</p>
          <p>void dtw_genMatrix(t_dynamicTW *x){</p>
          <p>int i;</p>
          <p>for(i = 0; i&lt;SIZE_ARRAY; i++){</p>
          <p>x-&gt;initMatrix[i][0] = x-&gt;storedSignalOne[i]; //populate the first column with signal 1 data points
          </p>
          <p>x-&gt;initMatrix[0][i] = x-&gt;storedSignalTwo[i]; //populate the last row with signal 2 data points</p>
          <p>}</p>
          <p>&nbsp;</p>
          <p>/* Calculates the Symmetrical distance for each matrix cell */</p>
          <p>int z, y;</p>
          <p>for(z = 1; z&lt; SIZE_ARRAY; z++){</p>
          <p>for(y = 1; y&lt;SIZE_ARRAY; y++){</p>
          <p>float difference = x-&gt;storedSignalOne[z] - x-&gt;storedSignalTwo[y];</p>
          <p>x-&gt;initMatrix[z][y] = (float)pow(difference, 2); //finding the symmetrical distance</p>
          <p>}</p>
          <p>}</p>
          <p>&nbsp;</p>
          <p>//initializing the costValues matrix</p>
          <p>int ci, cj;</p>
          <p>for(ci = 0; ci&lt;SIZE_ARRAY-1; ci++){</p>
          <p>for(cj = 0; cj&lt;SIZE_ARRAY-1; cj++){</p>
          <p>x-&gt;costValues[ci][cj].left = 0;</p>
          <p>x-&gt;costValues[ci][cj].bottom = 0;</p>
          <p>x-&gt;costValues[ci][cj].diag = 0;</p>
          <p>}</p>
          <p>}</p>
          <p>/* Calculates the cost of arrival from left, bottom, and diagonal */</p>
          <p>int q, r;</p>
          <p>for(q = 0; q&lt; SIZE_ARRAY-1; q++){</p>
          <p>for(r = 0; r&lt;SIZE_ARRAY-1; r++){</p>
          <p>//no left, bottom, or diagonal values //========READ ME!!!!!==============change to init matrix + 1?</p>
          <p>if (q == 0 &amp;& r ==0){</p>
          <p>x-&gt;costValues[q][r].left = x-&gt;initMatrix[q+1][r+1];</p>
          <p>x-&gt;costValues[q][r].bottom = x-&gt;initMatrix[q+1][r+1];</p>
          <p>x-&gt;costValues[q][r].diag = x-&gt;initMatrix[q+1][r+1];</p>
          <p>}</p>
          <p>//if row is bottom there cant be any bottom values or diagonal so set left values only</p>
          <p>else if (q == 0){</p>
          <p>if (r == 0){ //======READ | change to init matrix + 1 again</p>
          <p>x-&gt;costValues[q][r].left = x-&gt;initMatrix[q+1][r+1]; //no possible left values</p>
          <p>}</p>
          <p>else{</p>
          <p>
            x-&gt;costValues[q][r].left = x-&gt;initMatrix[q+1][r+1] + findMin(x,q,(r-1)); //=========change to cost of
            current
            cell init matrix + min of cost values of left cell
          </p>
          <p>}</p>
          <p>x-&gt;costValues[q][r].bottom = 1000 * 1000;</p>
          <p>x-&gt;costValues[q][r].diag = 1000 * 1000;</p>
          <p>}</p>
          <p>&nbsp;</p>
          <p>//if column is left there cant be any left values or diagonal so set bottom values only</p>
          <p>else if (r == 0){</p>
          <p>if (q == 0){</p>
          <p>x-&gt;costValues[q][r].bottom = x-&gt;initMatrix[q+1][r+1]; //======READ | change to init matrix + 1 again
          </p>
          <p>}</p>
          <p>else{</p>
          <p>
            x-&gt;costValues[q][r].bottom = x-&gt;initMatrix[q+1][r+1] + findMin(x,(q-1),r);//=========change to cost of
            current cell init matrix + min of cost values of left cell
          </p>
          <p>}</p>
          <p>x-&gt;costValues[q][r].left = 1000 * 1000;</p>
          <p>x-&gt;costValues[q][r].diag = 1000 * 1000;</p>
          <p>}</p>
          <p>&nbsp;</p>
          <p>//must have left, bottom, and diagonal values</p>
          <p>else{</p>
          <p>
            x-&gt;costValues[q][r].left = x-&gt;initMatrix[q+1][r+1] + findMin(x,q,(r-1)); //do current initMatrix value
            + min
          </p>
          <p>x-&gt;costValues[q][r].bottom = x-&gt;initMatrix[q+1][r+1] + findMin(x,(q-1),r);</p>
          <p>
            x-&gt;costValues[q][r].diag = (.5*x-&gt;initMatrix[q+1][r+1]) + findMin(x,(q-1),(r-1));//diagonal movement
            needs to
            be favored
          </p>
          <p>&nbsp;</p>
          <p>}</p>
          <p>&nbsp;</p>
          <p>}</p>
          <p>}</p>
          <p>&nbsp;</p>
          <p>// int qq, rr;</p>
          <p>// for(qq = 0; qq&lt;SIZE_ARRAY-1; qq++){</p>
          <p>// for(rr= 0; rr&lt;SIZE_ARRAY-1; rr++){</p>
          <p>// post("index q:%d and r:%d", qq, rr);</p>
          <p>// post("left: %f", x-&gt;costValues[qq][rr].left);</p>
          <p>// post("bottom: %f", x-&gt;costValues[qq][rr].bottom);</p>
          <p>// post("bottomLeft: %f\n", x-&gt;costValues[qq][rr].diag);</p>
          <p>// }</p>
          <p>// }</p>
          <p>&nbsp;</p>
          <p>leastCostPath(x); //finds least cost path</p>
          <p>}</p>
          <p>&nbsp;</p>
          <p>/* Function for when a bang is received</p>
          <p>* - Calculates the least cost path between input 1 and againts the other 3 signals</p>
          <p>* - It is then averaged together and changes the flag value */</p>
          <p>void dtw_onBangMsg(t_dynamicTW *x){</p>
          <p>x-&gt;match = 0;</p>
          <p>x-&gt;flag = 0; //makes so that lcp value gets stored in lcpValue</p>
          <p>saveValue = 0.0;</p>
          <p>arr_position = SIZE_ARRAY - 1;</p>
          <p>fileReader1(x, "C:\\Users\\Raki\\Documents\\GitHub\\dynamicTW\\TB\\input1.txt"); // read signal 1</p>
          <p>fileReader2(x, "C:\\Users\\Raki\\Documents\\GitHub\\dynamicTW\\TB\\input2.txt"); // read signal 2</p>
          <p>dtw_genMatrix(x); //perform DTW</p>
          <p>fileReader2(x, "C:\\Users\\Raki\\Documents\\GitHub\\dynamicTW\\TB\\input3.txt");</p>
          <p>dtw_genMatrix(x);</p>
          <p>fileReader2(x, "C:\\Users\\Raki\\Documents\\GitHub\\dynamicTW\\TB\\input4.txt");</p>
          <p>dtw_genMatrix(x);</p>
          <p>saveValue = saveValue / 3;</p>
          <p>post("saveValue: Least Cost Path is %f", saveValue);</p>
          <p>triggerGlobal = 1;</p>
          <p>&nbsp;</p>
          <p>}</p>
          <p>&nbsp;</p>
          <p>void dtw_free(t_dynamicTW *x){</p>
          <p>inlet_free(x-&gt;in_mod_A);</p>
          <p>inlet_free(x-&gt;in_mod_B);</p>
          <p>outlet_free(x-&gt;out_A);</p>
          <p>}</p>
          <p>&nbsp;</p>
          <p>void dtw_onSet_A(t_dynamicTW *x, t_floatarg f){ /*function that gets called when an input is received */
          </p>
          <p>clock_t t;</p>
          <p>if(triggerGlobal == 0){</p>
          <p>/*do nothing*/</p>
          <p>}</p>
          <p>//Sleep(2);</p>
          <p>post("Number A: %f sending to array. Arr_position is %d",f, arr_position);</p>
          <p>post("Delay Time: %f", delayTime);</p>
          <p>&nbsp;</p>
          <p>if(x-&gt;match == 1){</p>
          <p>post("Match has been detected. Freezing Program!");</p>
          <p>}</p>
          <p>else if(x-&gt;match == 0){</p>
          <p>if (arr_position &gt;= 0){ //checks if array is filled. If not then store incoming value to next index</p>
          <p>x-&gt;signal[arr_position] = f;</p>
          <p>arr_position--;</p>
          <p>}</p>
          <p>&nbsp;</p>
          <p>else{ //If array is filled shift all values by 1 index and store at beginning of array</p>
          <p>t = clock();</p>
          <p>&nbsp;</p>
          <p>int i;</p>
          <p>x-&gt;flag = 1; //makes it so that LCP result is stored in compared Value;</p>
          <p>for (i = SIZE_ARRAY - 1; i &gt; 0; i--){</p>
          <p>x-&gt;signal[i]=x-&gt;signal[i-1];</p>
          <p>}</p>
          <p>x-&gt;signal[0] = f;</p>
          <p>replaceSignal2(x); //replaces the value in signal 2</p>
          <p>reverseArray(x);</p>
          <p>dtw_genMatrix(x); //performs dtw</p>
          <p>&nbsp;</p>
          <p>t = clock() - t;</p>
          <p>double time_taken = ((double)t)/CLOCKS_PER_SEC; // in seconds</p>
          <p>post("DTW took %f seconds to execute", time_taken);</p>
          <p>signalMatch(x); //checks is the signal is correct if it is trigger effect</p>
          <p>&nbsp;</p>
          <p>// if(time_taken == .002){</p>
          <p>// Sleep(8);</p>
          <p>// }</p>
          <p>// else if (time_taken == .001){</p>
          <p>// Sleep(9);</p>
          <p>// }</p>
          <p>}</p>
          <p>}</p>
          <p>}</p>
          <p>&nbsp;</p>
          <p>void dtw_onSet_B(t_dynamicTW *x, t_floatarg f){</p>
          <p>delayTime = f;</p>
          <p>}</p>
          <p>//initializer for the class</p>
          <p>
            void *dynamicTW_new(t_floatarg f1, t_floatarg f2){ //parenth contains creation arg. temp stuff will replaced
            with
            arrays
          </p>
          <p>t_dynamicTW *x = (t_dynamicTW *)pd_new(dynamicTW_class); //initialize struct of type dtw</p>
          <p>x-&gt;in_mod_A = inlet_new(&amp;x-&gt;x_obj, &amp;x-&gt;x_obj.ob_pd, &amp;s_float, gensym("ratio_A"));</p>
          <p>x-&gt;in_mod_B = inlet_new(&amp;x-&gt;x_obj, &amp;x-&gt;x_obj.ob_pd, &amp;s_float, gensym("ratio_B"));</p>
          <p>x-&gt;out_A = outlet_new(&amp;x-&gt;x_obj, &amp;s_bang);</p>
          <p>return (void *)x;</p>
          <p>}</p>
          <p>&nbsp;</p>
          <p>&nbsp;</p>
          <p>//function to set up the class and call initializer</p>
          <p>void dynamicTW_setup(void){</p>
          <p>/*class_new(t_symbol *name, t_newmethod newmethod,</p>
          <p>t_method freemethod, size_t size, int flags, t_atomtype arg1, ...); */</p>
          <p>dynamicTW_class = class_new(gensym("dynamicTW"), //defines the symbol in puredata</p>
          <p>(t_newmethod)dynamicTW_new, //inializing method</p>
          <p>(t_method)dtw_free,</p>
          <p>sizeof(t_dynamicTW),</p>
          <p>CLASS_DEFAULT,//makes the box</p>
          <p>A_DEFFLOAT,</p>
          <p>A_DEFFLOAT,</p>
          <p>0);</p>
          <p>class_addbang(dynamicTW_class, (t_method)dtw_onBangMsg);</p>
          <p>class_addmethod(dynamicTW_class,</p>
          <p>(t_method)dtw_onSet_A,</p>
          <p>gensym("ratio_A"),</p>
          <p>A_DEFFLOAT,</p>
          <p>0);</p>
          <p>class_addmethod(dynamicTW_class,</p>
          <p>(t_method)dtw_onSet_B,</p>
          <p>gensym("ratio_B"),</p>
          <p>A_DEFFLOAT,</p>
          <p>0);</p>
          <p>}</p>
          <p>
            <strong>Pure Data Header File:</strong>
          </p>
          <p>&nbsp;</p>
          <p>
            /* Copyright (c) 1997-1999 Miller Puckette. * For information on usage and redistribution, and for a
            DISCLAIMER OF
            ALL * WARRANTIES, see the file, "LICENSE.txt," in this distribution. */ #ifndef __m_pd_h_ #if
            defined(_LANGUAGE_C_PLUS_PLUS) || defined(__cplusplus) extern "C" { #endif #define PD_MAJOR_VERSION 0
            #define
            PD_MINOR_VERSION 48 #define PD_BUGFIX_VERSION 1 #define PD_TEST_VERSION "" extern int pd_compatibilitylevel;
            /*
            e.g., 43 for pd 0.43 compatibility */ /* old name for "MSW" flag -- we have to take it for the sake of many
            old
            "nmakefiles" for externs, which will define NT and not MSW */ #if defined(NT) &amp;& !defined(MSW) #define
            MSW
            #endif /* These pragmas are only used for MSVC, not MinGW or Cygwin &lt;hans@at.or.at&gt; */ #ifdef _MSC_VER
            /*
            #pragma warning( disable : 4091 ) */ #pragma warning( disable : 4305 ) /* uncast const double to float */
            #pragma
            warning( disable : 4244 ) /* uncast float/int conversion etc. */ #pragma warning( disable : 4101 ) /* unused
            automatic variables */ #endif /* _MSC_VER */ /* the external storage class is "extern" in UNIX; in MSW it's
            ugly. */
            #ifdef _WIN32 #ifdef PD_INTERNAL #define EXTERN __declspec(dllexport) extern #else #define EXTERN
            __declspec(dllimport) extern #endif /* PD_INTERNAL */ #else #define EXTERN extern #endif /* _WIN32 */ /* On
            most c
            compilers, you can just say "struct foo;" to declare a structure whose elements are defined elsewhere. On
            MSVC, when
            compiling C (but not C++) code, you have to say "extern struct foo;". So we make a stupid macro: */ #if
            defined(_MSC_VER) &amp;& !defined(_LANGUAGE_C_PLUS_PLUS) \ &amp;& !defined(__cplusplus) #define
            EXTERN_STRUCT extern
            struct #else #define EXTERN_STRUCT struct #endif /* Define some attributes, specific to the compiler */ #if
            defined(__GNUC__) #define ATTRIBUTE_FORMAT_PRINTF(a, b) __attribute__ ((format (printf, a, b))) #else
            #define
            ATTRIBUTE_FORMAT_PRINTF(a, b) #endif #if !defined(_SIZE_T) &amp;& !defined(_SIZE_T_) #include
            &lt;stddef.h&gt; /*
            just for size_t -- how lame! */ #endif /* Microsoft Visual Studio is not C99, it does not provide stdint.h
            */ #ifdef
            _MSC_VER typedef signed __int8 int8_t; typedef signed __int16 int16_t; typedef signed __int32 int32_t;
            typedef
            signed __int64 int64_t; typedef unsigned __int8 uint8_t; typedef unsigned __int16 uint16_t; typedef unsigned
            __int32
            uint32_t; typedef unsigned __int64 uint64_t; #else # include &lt;stdint.h&gt; #endif /* for FILE, needed by
            sys_fopen() and sys_fclose() only */ #include &lt;stdio.h&gt; #define MAXPDSTRING 1000 /* use this for
            anything you
            want */ #define MAXPDARG 5 /* max number of args we can typecheck today */ /* signed and unsigned integer
            types the
            size of a pointer: */ #if !defined(PD_LONGINTTYPE) #define PD_LONGINTTYPE long #endif #if
            !defined(PD_FLOATSIZE) /*
            normally, our floats (t_float, t_sample,...) are 32bit */ # define PD_FLOATSIZE 32 #endif #if PD_FLOATSIZE
            == 32 #
            define PD_FLOATTYPE float /* an unsigned int of the same size as FLOATTYPE: */ # define PD_FLOATUINTTYPE
            unsigned
            int #elif PD_FLOATSIZE == 64 # define PD_FLOATTYPE double # define PD_FLOATUINTTYPE unsigned long #else #
            error
            invalid FLOATSIZE: must be 32 or 64 #endif typedef PD_LONGINTTYPE t_int; /* pointer-size integer */ typedef
            PD_FLOATTYPE t_float; /* a float type at most the same size */ typedef PD_FLOATTYPE t_floatarg; /* float
            type for
            function calls */ typedef struct _symbol { char *s_name; struct _class **s_thing; struct _symbol *s_next; }
            t_symbol; EXTERN_STRUCT _array; #define t_array struct _array /* g_canvas.h */ /* pointers to glist and
            array
            elements go through a "stub" which sticks around after the glist or array is freed. The stub itself is
            deleted when
            both the glist/array is gone and the refcount is zero, ensuring that no gpointers are pointing here. */
            #define
            GP_NONE 0 /* the stub points nowhere (has been cut off) */ #define GP_GLIST 1 /* the stub points to a glist
            element
            */ #define GP_ARRAY 2 /* ... or array */ typedef struct _gstub { union { struct _glist *gs_glist; /* glist
            we're in
            */ struct _array *gs_array; /* array we're in */ } gs_un; int gs_which; /* GP_GLIST/GP_ARRAY */ int
            gs_refcount; /*
            number of gpointers pointing here */ } t_gstub; typedef struct _gpointer /* pointer to a gobj in a glist */
            { union
            { struct _scalar *gp_scalar; /* scalar we're in (if glist) */ union word *gp_w; /* raw data (if array) */ }
            gp_un;
            int gp_valid; /* number which must match gpointee */ t_gstub *gp_stub; /* stub which points to glist/array
            */ }
            t_gpointer; typedef union word { t_float w_float; t_symbol *w_symbol; t_gpointer *w_gpointer; t_array
            *w_array;
            struct _binbuf *w_binbuf; int w_index; } t_word; typedef enum { A_NULL, A_FLOAT, A_SYMBOL, A_POINTER,
            A_SEMI,
            A_COMMA, A_DEFFLOAT, A_DEFSYM, A_DOLLAR, A_DOLLSYM, A_GIMME, A_CANT } t_atomtype; #define A_DEFSYMBOL
            A_DEFSYM /*
            better name for this */ typedef struct _atom { t_atomtype a_type; union word a_w; } t_atom; EXTERN_STRUCT
            _class;
            #define t_class struct _class EXTERN_STRUCT _outlet; #define t_outlet struct _outlet EXTERN_STRUCT _inlet;
            #define
            t_inlet struct _inlet EXTERN_STRUCT _binbuf; #define t_binbuf struct _binbuf EXTERN_STRUCT _clock; #define
            t_clock
            struct _clock EXTERN_STRUCT _outconnect; #define t_outconnect struct _outconnect EXTERN_STRUCT _glist;
            #define
            t_glist struct _glist #define t_canvas struct _glist /* LATER lose this */ typedef t_class *t_pd; /* pure
            datum:
            nothing but a class pointer */ typedef struct _gobj /* a graphical object */ { t_pd g_pd; /* pure datum
            header
            (class) */ struct _gobj *g_next; /* next in list */ } t_gobj; typedef struct _scalar /* a graphical object
            holding
            data */ { t_gobj sc_gobj; /* header for graphical object */ t_symbol *sc_template; /* template name (LATER
            replace
            with pointer) */ t_word sc_vec[1]; /* indeterminate-length array of words */ } t_scalar; typedef struct
            _text /*
            patchable object - graphical, with text */ { t_gobj te_g; /* header for graphical object */ t_binbuf
            *te_binbuf; /*
            holder for the text */ t_outlet *te_outlet; /* linked list of outlets */ t_inlet *te_inlet; /* linked list
            of inlets
            */ short te_xpix; /* x&amp;y location (within the toplevel) */ short te_ypix; short te_width; /* requested
            width in
            chars, 0 if auto */ unsigned int te_type:2; /* from defs below */ } t_text; #define T_TEXT 0 /* just a
            textual
            comment */ #define T_OBJECT 1 /* a MAX style patchable object */ #define T_MESSAGE 2 /* a MAX type message
            */
            #define T_ATOM 3 /* a cell to display a number or symbol */ #define te_pd te_g.g_pd /* t_object is synonym
            for
            t_text (LATER unify them) */ typedef struct _text t_object; #define ob_outlet te_outlet #define ob_inlet
            te_inlet
            #define ob_binbuf te_binbuf #define ob_pd te_g.g_pd #define ob_g te_g typedef void (*t_method)(void);
            typedef void
            *(*t_newmethod)( void); /* in ARM 64 a varargs prototype generates a different function call sequence from a
            fixed
            one, so in that special case we make a more restrictive definition for t_gotfn. This will break some code in
            the
            "chaos" package in Pd extended. (that code will run incorrectly anyhow so why not catch it at compile time
            anyhow.)
            */ #if defined(__APPLE__) &amp;& defined(__aarch64__) typedef void (*t_gotfn)(void *x); #else typedef void
            (*t_gotfn)(void *x, ...); #endif /* ---------------- pre-defined objects and symbols --------------*/ EXTERN
            t_pd
            pd_objectmaker; /* factory for creating "object" boxes */ EXTERN t_pd pd_canvasmaker; /* factory for
            creating
            canvases */ /* --------- prototypes from the central message system ----------- */ EXTERN void
            pd_typedmess(t_pd *x,
            t_symbol *s, int argc, t_atom *argv); EXTERN void pd_forwardmess(t_pd *x, int argc, t_atom *argv); EXTERN
            t_symbol
            *gensym(const char *s); EXTERN t_gotfn getfn(t_pd *x, t_symbol *s); EXTERN t_gotfn zgetfn(t_pd *x, t_symbol
            *s);
            EXTERN void nullfn(void); EXTERN void pd_vmess(t_pd *x, t_symbol *s, char *fmt, ...); /* the following
            macros are
            for sending non-type-checkable messages, i.e., using function lookup but circumventing type checking on
            arguments.
            Only use for internal messaging protected by A_CANT so that the message can't be generated at patch level.
            */
            #define mess0(x, s) ((*getfn((x), (s)))((x))) typedef void (*t_gotfn1)(void *x, void *arg1); #define
            mess1(x, s, a)
            ((*(t_gotfn1)getfn((x), (s)))((x), (a))) typedef void (*t_gotfn2)(void *x, void *arg1, void *arg2); #define
            mess2(x,
            s, a,b) ((*(t_gotfn2)getfn((x), (s)))((x), (a),(b))) typedef void (*t_gotfn3)(void *x, void *arg1, void
            *arg2, void
            *arg3); #define mess3(x, s, a,b,c) ((*(t_gotfn3)getfn((x), (s)))((x), (a),(b),(c))) typedef void
            (*t_gotfn4)(void
            *x, void *arg1, void *arg2, void *arg3, void *arg4); #define mess4(x, s, a,b,c,d) \ ((*(t_gotfn4)getfn((x),
            (s)))((x), (a),(b),(c),(d))) typedef void (*t_gotfn5)(void *x, void *arg1, void *arg2, void *arg3, void
            *arg4, void
            *arg5); #define mess5(x, s, a,b,c,d,e) \ ((*(t_gotfn5)getfn((x), (s)))((x), (a),(b),(c),(d),(e))) EXTERN
            void
            obj_list(t_object *x, t_symbol *s, int argc, t_atom *argv); EXTERN t_pd *pd_newest(void); /* ---------------
            memory
            management -------------------- */ EXTERN void *getbytes(size_t nbytes); EXTERN void *getzbytes(size_t
            nbytes);
            EXTERN void *copybytes(void *src, size_t nbytes); EXTERN void freebytes(void *x, size_t nbytes); EXTERN void
            *resizebytes(void *x, size_t oldsize, size_t newsize); /* -------------------- atoms
            -----------------------------
            */ #define SETSEMI(atom) ((atom)-&gt;a_type = A_SEMI, (atom)-&gt;a_w.w_index = 0) #define SETCOMMA(atom)
            ((atom)-&gt;a_type = A_COMMA, (atom)-&gt;a_w.w_index = 0) #define SETPOINTER(atom, gp) ((atom)-&gt;a_type =
            A_POINTER, \ (atom)-&gt;a_w.w_gpointer = (gp)) #define SETFLOAT(atom, f) ((atom)-&gt;a_type = A_FLOAT,
            (atom)-&gt;a_w.w_float = (f)) #define SETSYMBOL(atom, s) ((atom)-&gt;a_type = A_SYMBOL, \
            (atom)-&gt;a_w.w_symbol =
            (s)) #define SETDOLLAR(atom, n) ((atom)-&gt;a_type = A_DOLLAR, \ (atom)-&gt;a_w.w_index = (n)) #define
            SETDOLLSYM(atom, s) ((atom)-&gt;a_type = A_DOLLSYM, \ (atom)-&gt;a_w.w_symbol= (s)) EXTERN t_float
            atom_getfloat(t_atom *a); EXTERN t_int atom_getint(t_atom *a); EXTERN t_symbol *atom_getsymbol(t_atom *a);
            EXTERN
            t_symbol *atom_gensym(t_atom *a); EXTERN t_float atom_getfloatarg(int which, int argc, t_atom *argv); EXTERN
            t_int
            atom_getintarg(int which, int argc, t_atom *argv); EXTERN t_symbol *atom_getsymbolarg(int which, int argc,
            t_atom
            *argv); EXTERN void atom_string(t_atom *a, char *buf, unsigned int bufsize); /* ------------------ binbufs
            --------------- */ EXTERN t_binbuf *binbuf_new(void); EXTERN void binbuf_free(t_binbuf *x); EXTERN t_binbuf
            *binbuf_duplicate(t_binbuf *y); EXTERN void binbuf_text(t_binbuf *x, const char *text, size_t size); EXTERN
            void
            binbuf_gettext(t_binbuf *x, char **bufp, int *lengthp); EXTERN void binbuf_clear(t_binbuf *x); EXTERN void
            binbuf_add(t_binbuf *x, int argc, t_atom *argv); EXTERN void binbuf_addv(t_binbuf *x, char *fmt, ...);
            EXTERN void
            binbuf_addbinbuf(t_binbuf *x, t_binbuf *y); EXTERN void binbuf_addsemi(t_binbuf *x); EXTERN void
            binbuf_restore(t_binbuf *x, int argc, t_atom *argv); EXTERN void binbuf_print(t_binbuf *x); EXTERN int
            binbuf_getnatom(t_binbuf *x); EXTERN t_atom *binbuf_getvec(t_binbuf *x); EXTERN int binbuf_resize(t_binbuf
            *x, int
            newsize); EXTERN void binbuf_eval(t_binbuf *x, t_pd *target, int argc, t_atom *argv); EXTERN int
            binbuf_read(t_binbuf *b, char *filename, char *dirname, int crflag); EXTERN int
            binbuf_read_via_canvas(t_binbuf *b,
            char *filename, t_canvas *canvas, int crflag); EXTERN int binbuf_read_via_path(t_binbuf *b, char *filename,
            char
            *dirname, int crflag); EXTERN int binbuf_write(t_binbuf *x, char *filename, char *dir, int crflag); EXTERN
            void
            binbuf_evalfile(t_symbol *name, t_symbol *dir); EXTERN t_symbol *binbuf_realizedollsym(t_symbol *s, int ac,
            t_atom
            *av, int tonew); /* ------------------ clocks --------------- */ EXTERN t_clock *clock_new(void *owner,
            t_method
            fn); EXTERN void clock_set(t_clock *x, double systime); EXTERN void clock_delay(t_clock *x, double
            delaytime);
            EXTERN void clock_unset(t_clock *x); EXTERN void clock_setunit(t_clock *x, double timeunit, int sampflag);
            EXTERN
            double clock_getlogicaltime(void); EXTERN double clock_getsystime(void); /* OBSOLETE; use
            clock_getlogicaltime() */
            EXTERN double clock_gettimesince(double prevsystime); EXTERN double clock_gettimesincewithunits(double
            prevsystime,
            double units, int sampflag); EXTERN double clock_getsystimeafter(double delaytime); EXTERN void
            clock_free(t_clock
            *x); /* ----------------- pure data ---------------- */ EXTERN t_pd *pd_new(t_class *cls); EXTERN void
            pd_free(t_pd
            *x); EXTERN void pd_bind(t_pd *x, t_symbol *s); EXTERN void pd_unbind(t_pd *x, t_symbol *s); EXTERN t_pd
            *pd_findbyclass(t_symbol *s, t_class *c); EXTERN void pd_pushsym(t_pd *x); EXTERN void pd_popsym(t_pd *x);
            EXTERN
            t_symbol *pd_getfilename(void); EXTERN t_symbol *pd_getdirname(void); EXTERN void pd_bang(t_pd *x); EXTERN
            void
            pd_pointer(t_pd *x, t_gpointer *gp); EXTERN void pd_float(t_pd *x, t_float f); EXTERN void pd_symbol(t_pd
            *x,
            t_symbol *s); EXTERN void pd_list(t_pd *x, t_symbol *s, int argc, t_atom *argv); EXTERN void
            pd_anything(t_pd *x,
            t_symbol *s, int argc, t_atom *argv); #define pd_class(x) (*(x)) /* ----------------- pointers
            ---------------- */
            EXTERN void gpointer_init(t_gpointer *gp); EXTERN void gpointer_copy(const t_gpointer *gpfrom, t_gpointer
            *gpto);
            EXTERN void gpointer_unset(t_gpointer *gp); EXTERN int gpointer_check(const t_gpointer *gp, int headok); /*
            ----------------- patchable "objects" -------------- */ EXTERN t_inlet *inlet_new(t_object *owner, t_pd
            *dest,
            t_symbol *s1, t_symbol *s2); EXTERN t_inlet *pointerinlet_new(t_object *owner, t_gpointer *gp); EXTERN
            t_inlet
            *floatinlet_new(t_object *owner, t_float *fp); EXTERN t_inlet *symbolinlet_new(t_object *owner, t_symbol
            **sp);
            EXTERN t_inlet *signalinlet_new(t_object *owner, t_float f); EXTERN void inlet_free(t_inlet *x); EXTERN
            t_outlet
            *outlet_new(t_object *owner, t_symbol *s); EXTERN void outlet_bang(t_outlet *x); EXTERN void
            outlet_pointer(t_outlet
            *x, t_gpointer *gp); EXTERN void outlet_float(t_outlet *x, t_float f); EXTERN void outlet_symbol(t_outlet
            *x,
            t_symbol *s); EXTERN void outlet_list(t_outlet *x, t_symbol *s, int argc, t_atom *argv); EXTERN void
            outlet_anything(t_outlet *x, t_symbol *s, int argc, t_atom *argv); EXTERN t_symbol
            *outlet_getsymbol(t_outlet *x);
            EXTERN void outlet_free(t_outlet *x); EXTERN t_object *pd_checkobject(t_pd *x); /* --------------------
            canvases
            -------------- */ EXTERN void glob_setfilename(void *dummy, t_symbol *name, t_symbol *dir); EXTERN void
            canvas_setargs(int argc, t_atom *argv); EXTERN void canvas_getargs(int *argcp, t_atom **argvp); EXTERN
            t_symbol
            *canvas_getcurrentdir(void); EXTERN t_glist *canvas_getcurrent(void); EXTERN void
            canvas_makefilename(t_glist *c,
            char *file, char *result,int resultsize); EXTERN t_symbol *canvas_getdir(t_glist *x); EXTERN char
            sys_font[]; /*
            default typeface set in s_main.c */ EXTERN char sys_fontweight[]; /* default font weight set in s_main.c */
            EXTERN
            int sys_hostfontsize(int fontsize, int zoom); EXTERN int sys_zoomfontwidth(int fontsize, int zoom, int
            worstcase);
            EXTERN int sys_zoomfontheight(int fontsize, int zoom, int worstcase); EXTERN int sys_fontwidth(int
            fontsize); EXTERN
            int sys_fontheight(int fontsize); EXTERN void canvas_dataproperties(t_glist *x, t_scalar *sc, t_binbuf *b);
            EXTERN
            int canvas_open(t_canvas *x, const char *name, const char *ext, char *dirresult, char **nameresult, unsigned
            int
            size, int bin); /* ---------------- widget behaviors ---------------------- */ EXTERN_STRUCT
            _widgetbehavior;
            #define t_widgetbehavior struct _widgetbehavior EXTERN_STRUCT _parentwidgetbehavior; #define
            t_parentwidgetbehavior
            struct _parentwidgetbehavior EXTERN const t_parentwidgetbehavior *pd_getparentwidget(t_pd *x); /*
            -------------------- classes -------------- */ #define CLASS_DEFAULT 0 /* flags for new classes below */
            #define
            CLASS_PD 1 #define CLASS_GOBJ 2 #define CLASS_PATCHABLE 3 #define CLASS_NOINLET 8 #define CLASS_TYPEMASK 3
            EXTERN
            t_class *class_new(t_symbol *name, t_newmethod newmethod, t_method freemethod, size_t size, int flags,
            t_atomtype
            arg1, ...); EXTERN void class_addcreator(t_newmethod newmethod, t_symbol *s, t_atomtype type1, ...); EXTERN
            void
            class_addmethod(t_class *c, t_method fn, t_symbol *sel, t_atomtype arg1, ...); EXTERN void
            class_addbang(t_class *c,
            t_method fn); EXTERN void class_addpointer(t_class *c, t_method fn); EXTERN void class_doaddfloat(t_class
            *c,
            t_method fn); EXTERN void class_addsymbol(t_class *c, t_method fn); EXTERN void class_addlist(t_class *c,
            t_method
            fn); EXTERN void class_addanything(t_class *c, t_method fn); EXTERN void class_sethelpsymbol(t_class *c,
            t_symbol
            *s); EXTERN void class_setwidget(t_class *c, const t_widgetbehavior *w); EXTERN void
            class_setparentwidget(t_class
            *c, const t_parentwidgetbehavior *w); EXTERN const t_parentwidgetbehavior *class_parentwidget(t_class *c);
            EXTERN
            char *class_getname(t_class *c); EXTERN char *class_gethelpname(t_class *c); EXTERN char
            *class_gethelpdir(t_class
            *c); EXTERN void class_setdrawcommand(t_class *c); EXTERN int class_isdrawcommand(t_class *c); EXTERN void
            class_domainsignalin(t_class *c, int onset); EXTERN void class_set_extern_dir(t_symbol *s); #define
            CLASS_MAINSIGNALIN(c, type, field) \ class_domainsignalin(c, (char *)(&amp;((type *)0)-&gt;field) - (char
            *)0) /*
            prototype for functions to save Pd's to a binbuf */ typedef void (*t_savefn)(t_gobj *x, t_binbuf *b); EXTERN
            void
            class_setsavefn(t_class *c, t_savefn f); EXTERN t_savefn class_getsavefn(t_class *c); EXTERN void
            obj_saveformat(t_object *x, t_binbuf *bb); /* add format to bb */ /* prototype for functions to open
            properties
            dialogs */ typedef void (*t_propertiesfn)(t_gobj *x, struct _glist *glist); EXTERN void
            class_setpropertiesfn(t_class *c, t_propertiesfn f); EXTERN t_propertiesfn class_getpropertiesfn(t_class
            *c);
            #ifndef PD_CLASS_DEF #define class_addbang(x, y) class_addbang((x), (t_method)(y)) #define
            class_addpointer(x, y)
            class_addpointer((x), (t_method)(y)) #define class_addfloat(x, y) class_doaddfloat((x), (t_method)(y))
            #define
            class_addsymbol(x, y) class_addsymbol((x), (t_method)(y)) #define class_addlist(x, y) class_addlist((x),
            (t_method)(y)) #define class_addanything(x, y) class_addanything((x), (t_method)(y)) #endif /* ------------
            printing
            --------------------------------- */ EXTERN void post(const char *fmt, ...); EXTERN void startpost(const
            char *fmt,
            ...); EXTERN void poststring(const char *s); EXTERN void postfloat(t_floatarg f); EXTERN void postatom(int
            argc,
            t_atom *argv); EXTERN void endpost(void); EXTERN void error(const char *fmt, ...) ATTRIBUTE_FORMAT_PRINTF(1,
            2);
            EXTERN void verbose(int level, const char *fmt, ...) ATTRIBUTE_FORMAT_PRINTF(2, 3); EXTERN void bug(const
            char *fmt,
            ...) ATTRIBUTE_FORMAT_PRINTF(1, 2); EXTERN void pd_error(void *object, const char *fmt, ...)
            ATTRIBUTE_FORMAT_PRINTF(2, 3); EXTERN void logpost(const void *object, const int level, const char *fmt,
            ...)
            ATTRIBUTE_FORMAT_PRINTF(3, 4); EXTERN void sys_logerror(const char *object, const char *s); EXTERN void
            sys_unixerror(const char *object); EXTERN void sys_ouch(void); /* ------------ system interface routines
            ------------------- */ EXTERN int sys_isreadablefile(const char *name); EXTERN int sys_isabsolutepath(const
            char
            *dir); EXTERN void sys_bashfilename(const char *from, char *to); EXTERN void sys_unbashfilename(const char
            *from,
            char *to); EXTERN int open_via_path(const char *dir, const char *name, const char *ext, char *dirresult,
            char
            **nameresult, unsigned int size, int bin); EXTERN int sched_geteventno(void); EXTERN double
            sys_getrealtime(void);
            EXTERN int (*sys_idlehook)(void); /* hook to add idle time computation */ /* Win32's open()/fopen() do not
            handle
            UTF-8 filenames so we need * these internal versions that handle UTF-8 filenames the same across * all
            platforms.
            They are recommended for use in external * objectclasses as well so they work with Unicode filenames on
            Windows */
            EXTERN int sys_open(const char *path, int oflag, ...); EXTERN int sys_close(int fd); EXTERN FILE
            *sys_fopen(const
            char *filename, const char *mode); EXTERN int sys_fclose(FILE *stream); /* ------------ threading
            ------------------- */ EXTERN void sys_lock(void); EXTERN void sys_unlock(void); EXTERN int
            sys_trylock(void); /*
            --------------- signals ----------------------------------- */ typedef PD_FLOATTYPE t_sample; typedef union
            _sampleint_union { t_sample f; PD_FLOATUINTTYPE i; } t_sampleint_union; #define MAXLOGSIG 32 #define
            MAXSIGSIZE (1
            &lt;&lt; MAXLOGSIG) typedef struct _signal { int s_n; /* number of points in the array */ t_sample *s_vec;
            /* the
            array */ t_float s_sr; /* sample rate */ int s_refcount; /* number of times used */ int s_isborrowed; /*
            whether
            we're going to borrow our array */ struct _signal *s_borrowedfrom; /* signal to borrow it from */ struct
            _signal
            *s_nextfree; /* next in freelist */ struct _signal *s_nextused; /* next in used list */ int s_vecsize; /*
            allocated
            size of array in points */ } t_signal; typedef t_int *(*t_perfroutine)(t_int *args); EXTERN t_int
            *plus_perform(t_int *args); EXTERN t_int *zero_perform(t_int *args); EXTERN t_int *copy_perform(t_int
            *args); EXTERN
            void dsp_add_plus(t_sample *in1, t_sample *in2, t_sample *out, int n); EXTERN void dsp_add_copy(t_sample
            *in,
            t_sample *out, int n); EXTERN void dsp_add_scalarcopy(t_float *in, t_sample *out, int n); EXTERN void
            dsp_add_zero(t_sample *out, int n); EXTERN int sys_getblksize(void); EXTERN t_float sys_getsr(void); EXTERN
            int
            sys_get_inchannels(void); EXTERN int sys_get_outchannels(void); EXTERN void dsp_add(t_perfroutine f, int n,
            ...);
            EXTERN void dsp_addv(t_perfroutine f, int n, t_int *vec); EXTERN void pd_fft(t_float *buf, int npoints, int
            inverse); EXTERN int ilog2(int n); EXTERN void mayer_fht(t_sample *fz, int n); EXTERN void mayer_fft(int n,
            t_sample
            *real, t_sample *imag); EXTERN void mayer_ifft(int n, t_sample *real, t_sample *imag); EXTERN void
            mayer_realfft(int
            n, t_sample *real); EXTERN void mayer_realifft(int n, t_sample *real); EXTERN float *cos_table; #define
            LOGCOSTABSIZE 9 #define COSTABSIZE (1&lt;&lt;LOGCOSTABSIZE) EXTERN int canvas_suspend_dsp(void); EXTERN void
            canvas_resume_dsp(int oldstate); EXTERN void canvas_update_dsp(void); EXTERN int canvas_dspstate; /*
            up/downsampling
            */ typedef struct _resample { int method; /* up/downsampling method ID */ int downsample; /* downsampling
            factor */
            int upsample; /* upsampling factor */ t_sample *s_vec; /* here we hold the resampled data */ int s_n;
            t_sample
            *coeffs; /* coefficients for filtering... */ int coefsize; t_sample *buffer; /* buffer for filtering */ int
            bufsize;
            } t_resample; EXTERN void resample_init(t_resample *x); EXTERN void resample_free(t_resample *x); EXTERN
            void
            resample_dsp(t_resample *x, t_sample *in, int insize, t_sample *out, int outsize, int method); EXTERN void
            resamplefrom_dsp(t_resample *x, t_sample *in, int insize, int outsize, int method); EXTERN void
            resampleto_dsp(t_resample *x, t_sample *out, int insize, int outsize, int method); /*
            -----------------------
            utility functions for signals -------------- */ EXTERN t_float mtof(t_float); EXTERN t_float ftom(t_float);
            EXTERN
            t_float rmstodb(t_float); EXTERN t_float powtodb(t_float); EXTERN t_float dbtorms(t_float); EXTERN t_float
            dbtopow(t_float); EXTERN t_float q8_sqrt(t_float); EXTERN t_float q8_rsqrt(t_float); #ifndef N32 EXTERN
            t_float
            qsqrt(t_float); /* old names kept for extern compatibility */ EXTERN t_float qrsqrt(t_float); #endif /*
            --------------------- data --------------------------------- */ /* graphical arrays */ EXTERN_STRUCT
            _garray;
            #define t_garray struct _garray EXTERN t_class *garray_class; EXTERN int garray_getfloatarray(t_garray *x,
            int
            *size, t_float **vec); EXTERN int garray_getfloatwords(t_garray *x, int *size, t_word **vec); EXTERN void
            garray_redraw(t_garray *x); EXTERN int garray_npoints(t_garray *x); EXTERN char *garray_vec(t_garray *x);
            EXTERN
            void garray_resize(t_garray *x, t_floatarg f); /* avoid; use this: */ EXTERN void
            garray_resize_long(t_garray *x,
            long n); /* better version */ EXTERN void garray_usedindsp(t_garray *x); EXTERN void
            garray_setsaveit(t_garray *x,
            int saveit); EXTERN t_glist *garray_getglist(t_garray *x); EXTERN t_array *garray_getarray(t_garray *x);
            EXTERN
            t_class *scalar_class; EXTERN t_float *value_get(t_symbol *s); EXTERN void value_release(t_symbol *s);
            EXTERN int
            value_getfloat(t_symbol *s, t_float *f); EXTERN int value_setfloat(t_symbol *s, t_float f); /* ------- GUI
            interface
            - functions to send strings to TK --------- */ typedef void (*t_guicallbackfn)(t_gobj *client, t_glist
            *glist);
            EXTERN void sys_vgui(char *fmt, ...); EXTERN void sys_gui(char *s); EXTERN void sys_pretendguibytes(int n);
            EXTERN
            void sys_queuegui(void *client, t_glist *glist, t_guicallbackfn f); EXTERN void sys_unqueuegui(void
            *client); /*
            dialog window creation and destruction */ EXTERN void gfxstub_new(t_pd *owner, void *key, const char *cmd);
            EXTERN
            void gfxstub_deleteforkey(void *key); extern t_class *glob_pdobject; /* object to send "pd" messages */
            /*------------- Max 0.26 compatibility --------------------*/ /* the following reflects the new way classes
            are laid
            out, with the class pointing to the messlist and not vice versa. Externs shouldn't feel it. */ typedef
            t_class
            *t_externclass; EXTERN void c_extern(t_externclass *cls, t_newmethod newroutine, t_method freeroutine,
            t_symbol
            *name, size_t size, int tiny, \ t_atomtype arg1, ...); EXTERN void c_addmess(t_method fn, t_symbol *sel,
            t_atomtype
            arg1, ...); #define t_getbytes getbytes #define t_freebytes freebytes #define t_resizebytes resizebytes
            #define
            typedmess pd_typedmess #define vmess pd_vmess /* A definition to help gui objects straddle 0.34-0.35
            changes. If
            this is defined, there is a "te_xpix" field in objects, not a "te_xpos" as before: */ #define PD_USE_TE_XPIX
            #ifndef
            _MSC_VER /* Microoft compiler can't handle "inline" function/macros */ #if defined(__i386__) ||
            defined(__x86_64__)
            || defined(__arm__) /* a test for NANs and denormals. Should only be necessary on i386. */ #if PD_FLOATSIZE
            == 32
            typedef union { t_float f; unsigned int ui; }t_bigorsmall32; static inline int PD_BADFLOAT(t_float f) /*
            malformed
            float */ { t_bigorsmall32 pun; pun.f = f; pun.ui &amp;= 0x7f800000; return((pun.ui == 0) | (pun.ui ==
            0x7f800000));
            } static inline int PD_BIGORSMALL(t_float f) /* exponent outside (-64,64) */ { t_bigorsmall32 pun; pun.f =
            f;
            return((pun.ui & 0x20000000) == ((pun.ui &gt;&gt; 1) & 0x20000000)); } #elif PD_FLOATSIZE == 64 typedef
            union {
            t_float f; unsigned int ui[2]; }t_bigorsmall64; static inline int PD_BADFLOAT(t_float f) /* malformed double
            */ {
            t_bigorsmall64 pun; pun.f = f; pun.ui[1] &amp;= 0x7ff00000; return((pun.ui[1] == 0) | (pun.ui[1] ==
            0x7ff00000)); }
            static inline int PD_BIGORSMALL(t_float f) /* exponent outside (-512,512) */ { t_bigorsmall64 pun; pun.f =
            f;
            return((pun.ui[1] & 0x20000000) == ((pun.ui[1] &gt;&gt; 1) & 0x20000000)); } #endif /* PD_FLOATSIZE */ #else
            /* not
            INTEL or ARM */ #define PD_BADFLOAT(f) 0 #define PD_BIGORSMALL(f) 0 #endif #else /* _MSC_VER */ #if
            PD_FLOATSIZE ==
            32 #define PD_BADFLOAT(f) ((((*(unsigned int*)&amp;(f))&amp;0x7f800000)==0) || \ (((*(unsigned
            int*)&amp;(f))&amp;0x7f800000)==0x7f800000)) /* more stringent test: anything not between 1e-19 and 1e19 in
            absolute
            val */ #define PD_BIGORSMALL(f) ((((*(unsigned int*)&amp;(f))&amp;0x60000000)==0) || \ (((*(unsigned
            int*)&amp;(f))&amp;0x60000000)==0x60000000)) #else /* 64 bits... don't know what to do here */ #define
            PD_BADFLOAT(f) (!(((f) &gt;= 0) || ((f) &lt;= 0))) #define PD_BIGORSMALL(f) ((f) &gt; 1e150 || (f) &lt;
            -1e150 \ ||
            (f) &gt; -1e-150 &amp;& (f) &lt; 1e-150 ) #endif #endif /* _MSC_VER */ /* get version number at run time */
            EXTERN
            void sys_getversion(int *major, int *minor, int *bugfix); EXTERN_STRUCT _instancemidi; #define
            t_instancemidi struct
            _instancemidi EXTERN_STRUCT _instanceinter; #define t_instanceinter struct _instanceinter EXTERN_STRUCT
            _instancecanvas; #define t_instancecanvas struct _instancecanvas EXTERN_STRUCT _instanceugen; #define
            t_instanceugen
            struct _instanceugen EXTERN_STRUCT _instancestuff; #define t_instancestuff struct _instancestuff #ifndef
            PDTHREADS
            #define PDTHREADS 1 #endif struct _pdinstance { double pd_systime; /* global time in Pd ticks */ t_clock
            *pd_clock_setlist; /* list of set clocks */ t_canvas *pd_canvaslist; /* list of all root canvases */ int
            pd_instanceno; /* ordinal number of this instance */ t_symbol **pd_symhash; /* symbol table hash table */
            t_instancemidi *pd_midi; /* private stuff for x_midi.c */ t_instanceinter *pd_inter; /* private stuff for
            s_inter.c
            */ t_instanceugen *pd_ugen; /* private stuff for d_ugen.c */ t_instancecanvas *pd_gui; /* semi-private stuff
            in
            g_canvas.h */ t_instancestuff *pd_stuff; /* semi-private stuff in s_stuff.h */ t_pd *pd_newest; /* most
            recently
            created object */ #ifdef PDINSTANCE t_symbol pd_s_pointer; t_symbol pd_s_float; t_symbol pd_s_symbol;
            t_symbol
            pd_s_bang; t_symbol pd_s_list; t_symbol pd_s_anything; t_symbol pd_s_signal; t_symbol pd_s__N; t_symbol
            pd_s__X;
            t_symbol pd_s_x; t_symbol pd_s_y; t_symbol pd_s_; #endif #if PDTHREADS int pd_islocked; #endif }; #define
            t_pdinstance struct _pdinstance EXTERN t_pdinstance pd_maininstance; /* m_pd.c */ #ifdef PDINSTANCE EXTERN
            t_pdinstance *pdinstance_new( void); EXTERN void pd_setinstance(t_pdinstance *x); EXTERN void
            pdinstance_free(t_pdinstance *x); #endif /* PDINSTANCE */ #if defined(PDTHREADS) &amp;& defined(PDINSTANCE)
            #define
            PERTHREAD __thread #else #define PERTHREAD #endif #ifdef PDINSTANCE EXTERN PERTHREAD t_pdinstance *pd_this;
            EXTERN
            t_pdinstance **pd_instances; EXTERN int pd_ninstances; #else #define pd_this (&amp;pd_maininstance) #endif
            /*
            PDINSTANCE */ #ifdef PDINSTANCE #define s_pointer (pd_this-&gt;pd_s_pointer) #define s_float
            (pd_this-&gt;pd_s_float) #define s_symbol (pd_this-&gt;pd_s_symbol) #define s_bang (pd_this-&gt;pd_s_bang)
            #define
            s_list (pd_this-&gt;pd_s_list) #define s_anything (pd_this-&gt;pd_s_anything) #define s_signal
            (pd_this-&gt;pd_s_signal) #define s__N (pd_this-&gt;pd_s__N) #define s__X (pd_this-&gt;pd_s__X) #define s_x
            (pd_this-&gt;pd_s_x) #define s_y (pd_this-&gt;pd_s_y) #define s_ (pd_this-&gt;pd_s_) #else EXTERN t_symbol
            s_pointer, s_float, s_symbol, s_bang, s_list, s_anything, s_signal, s__N, s__X, s_x, s_y, s_; #endif EXTERN
            t_canvas
            *pd_getcanvaslist(void); EXTERN int pd_getdspstate(void); #if defined(_LANGUAGE_C_PLUS_PLUS) ||
            defined(__cplusplus)
            } #endif #define __m_pd_h_ #endif /* __m_pd_h_ */
          </p>
          <p>&nbsp;</p>
</body>

</html>
